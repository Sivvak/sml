{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Let's start by loading the data and checking how it looks like\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "y_train = pd.read_csv(\"y_train.csv\")\n",
    "\n",
    "X_test = pd.read_csv(\"X_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing_values(df: pd.DataFrame, df_name: str) -> None:\n",
    "    if df.isnull().values.any():\n",
    "        print(f\"There are some missing values in {df_name} dataframe.\")\n",
    "    else:\n",
    "        print(f\"There aren't any missing values in {df_name} dataframe\")\n",
    "\n",
    "\n",
    "def check_types(df: pd.DataFrame, df_name: str) -> None:\n",
    "    filtered = df.select_dtypes(exclude=[\"float64\"])\n",
    "    print(\n",
    "        f\"Columns of {df_name} dataframe with non-float type: {list(filtered.columns)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3794 entries, 0 to 3793\n",
      "Columns: 9000 entries, LINC01409 to AC007325.4\n",
      "dtypes: float64(9000)\n",
      "memory usage: 260.5 MB\n",
      "\n",
      "Columns of X_train dataframe with non-float type: []\n",
      "\n",
      "There aren't any missing values in X_train dataframe\n"
     ]
    }
   ],
   "source": [
    "X_train.info()\n",
    "\n",
    "print()\n",
    "check_types(X_train, \"X_train\")\n",
    "print()\n",
    "check_missing_values(X_train, \"X_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3794 entries, 0 to 3793\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Id        3794 non-null   int64  \n",
      " 1   Expected  3794 non-null   float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 59.4 KB\n",
      "\n",
      "Columns of y_train dataframe with non-float type: ['Id']\n",
      "\n",
      "There aren't any missing values in y_train dataframe\n"
     ]
    }
   ],
   "source": [
    "y_train.info()\n",
    "\n",
    "print()\n",
    "check_types(y_train, \"y_train\")\n",
    "print()\n",
    "check_missing_values(y_train, \"y_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 670 entries, 0 to 669\n",
      "Columns: 9000 entries, LINC01409 to AC007325.4\n",
      "dtypes: float64(9000)\n",
      "memory usage: 46.0 MB\n",
      "\n",
      "Columns of X_test dataframe with non-float type: []\n",
      "\n",
      "There aren't any missing values in X_test dataframe\n"
     ]
    }
   ],
   "source": [
    "X_test.info()\n",
    "\n",
    "print()\n",
    "check_types(X_test, \"X_test\")\n",
    "print()\n",
    "check_missing_values(X_test, \"X_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can notice that:\n",
    "\n",
    "- There are 9000 independent variables in both train and test X dataframes\n",
    "- There are 3794 observations in the training set (both X and y), and 670 observations in the test set\n",
    "- All relevant variables have float type, there's no need to convert them. Only `Id` in the y_train dataframe has int type, but as it's just an identifier of the observation, we don't need to worry about it\n",
    "- There is no missing data in any dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Now let's investigate the empirical distribution of the response variable, we'll do it in two steps:\n",
    "\n",
    "1. Calculate some basic statistics\n",
    "2. Present a histogram + density estimator plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    3794.000000\n",
      "mean        0.791096\n",
      "std         0.860856\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.311748\n",
      "75%         1.662514\n",
      "max         2.860416\n",
      "Name: Expected, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "stats = y_train[\"Expected\"].describe()\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV coefficient: 1.0882\n"
     ]
    }
   ],
   "source": [
    "print(f\"CV coefficient: {stats['std'] / stats['mean']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(y_train[\"Expected\"], kde=True, bins=30)\n",
    "plt.title(\"Histogram and Density Estimator Plot of the Response Variable\")\n",
    "plt.xlabel(\"Response Variable\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of observations with response variable equal to 0: 0.4014\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Fraction of observations with response variable equal to 0: {(y_train['Expected'] == 0).sum() / y_train['Expected'].count():.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(y_train[\"Expected\"][y_train[\"Expected\"] > 0.6], kde=True, bins=30)\n",
    "plt.title(\n",
    "    \"Histogram and Density Estimator Plot of the Response Variable for values > 0.6\"\n",
    ")\n",
    "plt.xlabel(\"Response Variable\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key notes:\n",
    "\n",
    "- Values range from 0 to around 2.86\n",
    "- Mean value is much higher than the median value, which suggests that the distribution is heavily right-skewed (which is also confirmed by the above histogram)\n",
    "- CV coefficient equal to around 1.0882 can be considered as a high variability of data, as the standard deviation is higher than the mean value\n",
    "- There's a huge part of observations for which the response variable is equal to 0, it's around 40%\n",
    "- If we take a look only at values > 0.6, we can see they're more normally distributed (however we can't say it's a perfect normal distribution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Finally let's analyze the correlation coefficients, looking for potentially significant variables and multicolinearity amongst them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "correlations = X_train.corrwith(y_train[\"Expected\"])\n",
    "\n",
    "sns.violinplot(correlations)\n",
    "plt.title(\n",
    "    f\"Violin plot of correlation coefficients between the predictors and the response variable\"\n",
    ")\n",
    "plt.ylabel(\"Correlation Coefficient\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result we got is quite predictable - amongst all the 9000 variables only a small part of them is potentially significant. The correlation coefficient for majority of them is around 0, which suggests no significant association.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now search for multicolinearity amongst the most correlated variables:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCN1        0.623565\n",
      "VCAN        0.618140\n",
      "S100A9      0.598952\n",
      "CD36        0.597179\n",
      "FTH1        0.581045\n",
      "              ...   \n",
      "TMEM176B    0.376995\n",
      "PLAUR       0.376783\n",
      "GNLY        0.376133\n",
      "CD3G        0.375530\n",
      "TGFBI       0.374922\n",
      "Length: 100, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted_correlations = correlations.abs().sort_values(ascending=False)\n",
    "top_correlations = sorted_correlations.head(100)\n",
    "print(top_correlations)\n",
    "\n",
    "X_train_filtered = X_train[top_correlations.index]\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(X_train_filtered.corr(), cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "plt.title(\n",
    "    \"Correlation Matrix Heatmap for 100 the most correlated features with the response variable\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "\n",
    "- There are some highly correlated features, especially amongst the top 16 (with regard to the correlation with response variable) ones\n",
    "- There are also some noticeable positive correlations for single pairs in the bottom part of the heatmap, e.g. for the `CA1` variable\n",
    "- For the same variables as in the previous observation, we can spot some higher (in terms of absolute value) negative correlation values, although these aren't as high and as numerous as the positive ones\n",
    "- In general there's some multicolinearity between the features, which we will need to take into consideration in the further parts of this project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ElasticNet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ElasticNet is a linear regression model that combines the properties of both Ridge and Lasso regression, and therefore aims to improve the limitations of both by balancing their penalties. Model estimates the linear coefficients/weights, denoted by $\\beta$. The estimator can be defined as:\n",
    "\n",
    "$$ \\hat{\\beta} = \\text{argmin}_{\\beta}(\\|y - X\\beta\\|^2_2 + \\lambda_{2} \\|\\beta\\|^2_2 + \\lambda_1\\|\\beta\\|_1)$$\n",
    "where:\\\n",
    "$y$ - vector of response variable\\\n",
    "$X$ - matrix of dependent variables\\\n",
    "$\\lambda_{2}$ - Ridge coefficient\\\n",
    "$\\lambda_{1}$ - LASSO coefficient\n",
    "\n",
    "Considering the above and the sklearn documentation, the optimization function can be written as:\n",
    "\n",
    "$$ L(\\beta) = \\frac{1}{2n} \\|y - X\\beta\\|^2_2 + \\alpha \\cdot \\text{l1\\_ratio} \\cdot \\|\\beta\\|_1 + \\frac{1}{2} \\alpha \\cdot (1 - \\text{l1\\_ratio}) \\cdot ||\\beta||^2_2 $$\n",
    "where:\\\n",
    "$n$ - number of observations\\\n",
    "$\\alpha$ - hyperparameter controlling the overall strength of the regularization, when equal to 0 the model effectively becomes the OLS\\\n",
    "l1_ratio - hyperparameter balancing the LASSO and Ridge penalties, when equal to 0 the model reduces to the Ridge regression, and for value equal to 1 it reduces to the LASSO regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 49 candidates, totalling 245 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.604e+00, tolerance: 2.247e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.0001, l1_ratio=0.5;, score=(train=-0.000, test=-0.299) total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.214e+01, tolerance: 2.270e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.0001, l1_ratio=0.7;, score=(train=-0.001, test=-0.296) total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.008e+01, tolerance: 2.242e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.202e+01, tolerance: 2.265e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.0001, l1_ratio=0.5;, score=(train=-0.000, test=-0.289) total time= 1.1min\n",
      "[CV 2/5] END alpha=0.0001, l1_ratio=0.7;, score=(train=-0.001, test=-0.275) total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.922e+00, tolerance: 2.219e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.0001, l1_ratio=0.5;, score=(train=-0.000, test=-0.273) total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.580e+00, tolerance: 2.270e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.944e+00, tolerance: 2.265e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.0001, l1_ratio=0.5;, score=(train=-0.000, test=-0.297) total time= 1.1min\n",
      "[CV 2/5] END alpha=0.0001, l1_ratio=0.5;, score=(train=-0.000, test=-0.288) total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+00, tolerance: 2.270e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.789e+00, tolerance: 2.242e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.0001, l1_ratio=0.1;, score=(train=-0.000, test=-0.324) total time= 1.2min\n",
      "[CV 1/5] END alpha=0.0001, l1_ratio=0.1;, score=(train=-0.000, test=-0.315) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+00, tolerance: 2.247e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.0001, l1_ratio=0.1;, score=(train=-0.000, test=-0.321) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.805e+00, tolerance: 2.219e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.0001, l1_ratio=0.1;, score=(train=-0.000, test=-0.321) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.761e+00, tolerance: 2.265e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.0001, l1_ratio=0.1;, score=(train=-0.000, test=-0.331) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.259e+01, tolerance: 2.219e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.0001, l1_ratio=0.7;, score=(train=-0.001, test=-0.268) total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.284e+01, tolerance: 2.242e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.0001, l1_ratio=0.7;, score=(train=-0.001, test=-0.281) total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.325e+01, tolerance: 2.265e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.217e+01, tolerance: 2.247e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.0001, l1_ratio=0.9;, score=(train=-0.001, test=-0.270) total time= 1.1min\n",
      "[CV 4/5] END alpha=0.0001, l1_ratio=0.7;, score=(train=-0.001, test=-0.289) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.366e+01, tolerance: 2.242e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.0001, l1_ratio=0.9;, score=(train=-0.001, test=-0.275) total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.303e+01, tolerance: 2.270e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.0001, l1_ratio=0.9;, score=(train=-0.001, test=-0.289) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.405e+01, tolerance: 2.219e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.0001, l1_ratio=0.9;, score=(train=-0.001, test=-0.260) total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.376e+01, tolerance: 2.270e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.0001, l1_ratio=0.95;, score=(train=-0.001, test=-0.288) total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.339e+01, tolerance: 2.247e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.389e+01, tolerance: 2.219e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.0001, l1_ratio=0.9;, score=(train=-0.001, test=-0.277) total time= 1.2min\n",
      "[CV 3/5] END alpha=0.0001, l1_ratio=0.95;, score=(train=-0.001, test=-0.258) total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.379e+01, tolerance: 2.265e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.0001, l1_ratio=0.95;, score=(train=-0.001, test=-0.268) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.385e+01, tolerance: 2.247e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.0001, l1_ratio=0.95;, score=(train=-0.001, test=-0.275) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.429e+01, tolerance: 2.265e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.0001, l1_ratio=0.99;, score=(train=-0.001, test=-0.267) total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.436e+01, tolerance: 2.242e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.0001, l1_ratio=0.95;, score=(train=-0.001, test=-0.273) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.423e+01, tolerance: 2.270e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.0001, l1_ratio=0.99;, score=(train=-0.001, test=-0.288) total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.416e+01, tolerance: 2.219e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.0001, l1_ratio=0.99;, score=(train=-0.001, test=-0.257) total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.412e+01, tolerance: 2.247e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.488e+01, tolerance: 2.242e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.0001, l1_ratio=0.99;, score=(train=-0.001, test=-0.273) total time= 1.2min\n",
      "[CV 5/5] END alpha=0.0001, l1_ratio=0.99;, score=(train=-0.001, test=-0.272) total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.433e+01, tolerance: 2.270e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.0001, l1_ratio=1;, score=(train=-0.001, test=-0.287) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.445e+01, tolerance: 2.265e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.0001, l1_ratio=1;, score=(train=-0.001, test=-0.267) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.412e+01, tolerance: 2.247e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.0001, l1_ratio=1;, score=(train=-0.001, test=-0.272) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.426e+01, tolerance: 2.219e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.0001, l1_ratio=1;, score=(train=-0.001, test=-0.256) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.499e+01, tolerance: 2.242e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.0001, l1_ratio=1;, score=(train=-0.001, test=-0.272) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.642e+01, tolerance: 2.270e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.001, l1_ratio=0.1;, score=(train=-0.001, test=-0.250) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.742e+01, tolerance: 2.247e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.001, l1_ratio=0.1;, score=(train=-0.001, test=-0.241) total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.842e+01, tolerance: 2.242e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.001, l1_ratio=0.1;, score=(train=-0.002, test=-0.243) total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.785e+01, tolerance: 2.219e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.001, l1_ratio=0.1;, score=(train=-0.002, test=-0.232) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.501e+01, tolerance: 2.219e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-0.016, test=-0.170) total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.773e+01, tolerance: 2.270e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.828e+01, tolerance: 2.265e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-0.015, test=-0.180) total time= 1.1min\n",
      "[CV 2/5] END alpha=0.001, l1_ratio=0.1;, score=(train=-0.001, test=-0.248) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.859e+01, tolerance: 2.265e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-0.016, test=-0.175) total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.433e+01, tolerance: 2.247e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-0.016, test=-0.164) total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.010e+01, tolerance: 2.270e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.001, l1_ratio=0.7;, score=(train=-0.023, test=-0.164) total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.903e+01, tolerance: 2.242e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.001, l1_ratio=0.5;, score=(train=-0.016, test=-0.169) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.035e+01, tolerance: 2.265e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.001, l1_ratio=0.7;, score=(train=-0.024, test=-0.154) total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.486e+01, tolerance: 2.219e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.001, l1_ratio=0.7;, score=(train=-0.025, test=-0.153) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.404e+01, tolerance: 2.242e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.001, l1_ratio=0.7;, score=(train=-0.025, test=-0.152) total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.264e+01, tolerance: 2.247e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.001, l1_ratio=0.7;, score=(train=-0.024, test=-0.145) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.682e+01, tolerance: 2.270e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.001, l1_ratio=0.9;, score=(train=-0.031, test=-0.152) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.461e+01, tolerance: 2.219e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.001, l1_ratio=0.9;, score=(train=-0.033, test=-0.143) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.320e+01, tolerance: 2.265e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.001, l1_ratio=0.9;, score=(train=-0.032, test=-0.145) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.083e+01, tolerance: 2.247e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.001, l1_ratio=0.9;, score=(train=-0.032, test=-0.131) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.645e+01, tolerance: 2.270e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.001, l1_ratio=0.95;, score=(train=-0.033, test=-0.149) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.333e+01, tolerance: 2.242e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.001, l1_ratio=0.9;, score=(train=-0.033, test=-0.141) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.853e+01, tolerance: 2.265e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.363e+01, tolerance: 2.247e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.001, l1_ratio=0.95;, score=(train=-0.034, test=-0.143) total time= 1.2min\n",
      "[CV 4/5] END alpha=0.001, l1_ratio=0.95;, score=(train=-0.034, test=-0.129) total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.413e+01, tolerance: 2.219e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.001, l1_ratio=0.95;, score=(train=-0.035, test=-0.141) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.255e+01, tolerance: 2.242e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.001, l1_ratio=0.95;, score=(train=-0.035, test=-0.139) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.303e+01, tolerance: 2.270e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.051e+01, tolerance: 2.265e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.001, l1_ratio=0.99;, score=(train=-0.034, test=-0.148) total time= 1.2min\n",
      "[CV 2/5] END alpha=0.001, l1_ratio=0.99;, score=(train=-0.035, test=-0.141) total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.102e+01, tolerance: 2.219e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.001, l1_ratio=0.99;, score=(train=-0.036, test=-0.140) total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.162e+01, tolerance: 2.270e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.001, l1_ratio=1;, score=(train=-0.035, test=-0.147) total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.252e+01, tolerance: 2.247e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.001, l1_ratio=0.99;, score=(train=-0.035, test=-0.127) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.218e+01, tolerance: 2.242e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.001, l1_ratio=0.99;, score=(train=-0.036, test=-0.138) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.135e+01, tolerance: 2.247e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.001, l1_ratio=1;, score=(train=-0.036, test=-0.126) total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.047e+01, tolerance: 2.219e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.001, l1_ratio=1;, score=(train=-0.037, test=-0.140) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.965e+01, tolerance: 2.265e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.712e+00, tolerance: 2.242e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.001, l1_ratio=1;, score=(train=-0.036, test=-0.141) total time= 1.2min\n",
      "[CV 5/5] END alpha=0.001, l1_ratio=1;, score=(train=-0.037, test=-0.137) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.748e+01, tolerance: 2.270e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.01, l1_ratio=0.1;, score=(train=-0.039, test=-0.138) total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.542e+01, tolerance: 2.265e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.01, l1_ratio=0.1;, score=(train=-0.040, test=-0.134) total time= 1.2min\n",
      "[CV 2/5] END alpha=0.01, l1_ratio=0.7;, score=(train=-0.107, test=-0.117) total time=  16.7s\n",
      "[CV 5/5] END alpha=0.01, l1_ratio=0.5;, score=(train=-0.100, test=-0.125) total time=  20.2s\n",
      "[CV 2/5] END alpha=0.01, l1_ratio=0.5;, score=(train=-0.099, test=-0.116) total time=  25.3s\n",
      "[CV 1/5] END alpha=0.01, l1_ratio=0.7;, score=(train=-0.108, test=-0.118) total time=  20.9s\n",
      "[CV 1/5] END alpha=0.01, l1_ratio=0.5;, score=(train=-0.098, test=-0.116) total time=  28.2s\n",
      "[CV 3/5] END alpha=0.01, l1_ratio=0.7;, score=(train=-0.108, test=-0.118) total time=  19.7s\n",
      "[CV 4/5] END alpha=0.01, l1_ratio=0.5;, score=(train=-0.103, test=-0.107) total time=  25.0s\n",
      "[CV 3/5] END alpha=0.01, l1_ratio=0.5;, score=(train=-0.100, test=-0.116) total time=  26.7s\n",
      "[CV 4/5] END alpha=0.01, l1_ratio=0.7;, score=(train=-0.111, test=-0.110) total time=  19.4s\n",
      "[CV 1/5] END alpha=0.01, l1_ratio=0.9;, score=(train=-0.113, test=-0.121) total time=  15.6s\n",
      "[CV 3/5] END alpha=0.01, l1_ratio=0.9;, score=(train=-0.113, test=-0.120) total time=  14.8s\n",
      "[CV 5/5] END alpha=0.01, l1_ratio=0.7;, score=(train=-0.107, test=-0.130) total time=  20.4s\n",
      "[CV 2/5] END alpha=0.01, l1_ratio=0.9;, score=(train=-0.113, test=-0.119) total time=  17.8s\n",
      "[CV 1/5] END alpha=0.01, l1_ratio=0.95;, score=(train=-0.114, test=-0.121) total time=  14.9s\n",
      "[CV 2/5] END alpha=0.01, l1_ratio=0.95;, score=(train=-0.114, test=-0.119) total time=  14.2s\n",
      "[CV 4/5] END alpha=0.01, l1_ratio=0.9;, score=(train=-0.116, test=-0.112) total time=  17.9s\n",
      "[CV 5/5] END alpha=0.01, l1_ratio=0.9;, score=(train=-0.111, test=-0.132) total time=  18.9s\n",
      "[CV 3/5] END alpha=0.01, l1_ratio=0.95;, score=(train=-0.114, test=-0.120) total time=  16.0s\n",
      "[CV 4/5] END alpha=0.01, l1_ratio=0.95;, score=(train=-0.117, test=-0.113) total time=  17.3s\n",
      "[CV 5/5] END alpha=0.01, l1_ratio=0.95;, score=(train=-0.112, test=-0.133) total time=  17.3s\n",
      "[CV 2/5] END alpha=0.01, l1_ratio=0.99;, score=(train=-0.115, test=-0.120) total time=  15.3s\n",
      "[CV 1/5] END alpha=0.01, l1_ratio=0.99;, score=(train=-0.115, test=-0.122) total time=  16.3s\n",
      "[CV 3/5] END alpha=0.01, l1_ratio=0.99;, score=(train=-0.115, test=-0.120) total time=  15.4s\n",
      "[CV 4/5] END alpha=0.01, l1_ratio=0.99;, score=(train=-0.117, test=-0.114) total time=  17.3s\n",
      "[CV 1/5] END alpha=0.01, l1_ratio=1;, score=(train=-0.115, test=-0.122) total time=  14.9s\n",
      "[CV 5/5] END alpha=0.01, l1_ratio=0.99;, score=(train=-0.113, test=-0.134) total time=  18.5s\n",
      "[CV 2/5] END alpha=0.01, l1_ratio=1;, score=(train=-0.115, test=-0.120) total time=  16.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.304e+01, tolerance: 2.242e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.01, l1_ratio=0.1;, score=(train=-0.041, test=-0.131) total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.462e+01, tolerance: 2.219e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.01, l1_ratio=0.1;, score=(train=-0.041, test=-0.134) total time= 1.3min\n",
      "[CV 4/5] END alpha=0.01, l1_ratio=1;, score=(train=-0.118, test=-0.114) total time=  14.0s\n",
      "[CV 2/5] END alpha=0.1, l1_ratio=0.1;, score=(train=-0.117, test=-0.121) total time=  13.3s\n",
      "[CV 1/5] END alpha=0.1, l1_ratio=0.1;, score=(train=-0.117, test=-0.123) total time=  14.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.253e+01, tolerance: 2.247e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.1, l1_ratio=0.5;, score=(train=-0.162, test=-0.162) total time=   5.3s\n",
      "[CV 4/5] END alpha=0.01, l1_ratio=0.1;, score=(train=-0.040, test=-0.119) total time= 1.3min\n",
      "[CV 2/5] END alpha=0.1, l1_ratio=0.5;, score=(train=-0.162, test=-0.161) total time=   4.9s\n",
      "[CV 3/5] END alpha=0.01, l1_ratio=1;, score=(train=-0.115, test=-0.121) total time=  16.5s\n",
      "[CV 3/5] END alpha=0.1, l1_ratio=0.1;, score=(train=-0.117, test=-0.124) total time=  15.5s\n",
      "[CV 5/5] END alpha=0.01, l1_ratio=1;, score=(train=-0.113, test=-0.134) total time=  18.4s\n",
      "[CV 3/5] END alpha=0.1, l1_ratio=0.5;, score=(train=-0.163, test=-0.162) total time=   5.3s\n",
      "[CV 5/5] END alpha=0.1, l1_ratio=0.1;, score=(train=-0.115, test=-0.133) total time=  14.1s\n",
      "[CV 4/5] END alpha=0.1, l1_ratio=0.1;, score=(train=-0.119, test=-0.115) total time=  15.3s\n",
      "[CV 4/5] END alpha=0.1, l1_ratio=0.5;, score=(train=-0.163, test=-0.158) total time=   5.8s\n",
      "[CV 1/5] END alpha=0.1, l1_ratio=0.7;, score=(train=-0.175, test=-0.174) total time=   5.3s\n",
      "[CV 5/5] END alpha=0.1, l1_ratio=0.5;, score=(train=-0.159, test=-0.177) total time=   6.3s\n",
      "[CV 3/5] END alpha=0.1, l1_ratio=0.7;, score=(train=-0.178, test=-0.178) total time=   5.6s\n",
      "[CV 4/5] END alpha=0.1, l1_ratio=0.7;, score=(train=-0.176, test=-0.171) total time=   5.7s\n",
      "[CV 2/5] END alpha=0.1, l1_ratio=0.7;, score=(train=-0.176, test=-0.173) total time=   6.1s\n",
      "[CV 5/5] END alpha=0.1, l1_ratio=0.7;, score=(train=-0.173, test=-0.191) total time=   5.3s\n",
      "[CV 1/5] END alpha=0.1, l1_ratio=0.9;, score=(train=-0.192, test=-0.189) total time=   5.9s\n",
      "[CV 4/5] END alpha=0.1, l1_ratio=0.9;, score=(train=-0.193, test=-0.187) total time=   5.6s\n",
      "[CV 3/5] END alpha=0.1, l1_ratio=0.9;, score=(train=-0.195, test=-0.198) total time=   5.8s\n",
      "[CV 2/5] END alpha=0.1, l1_ratio=0.9;, score=(train=-0.193, test=-0.189) total time=   6.2s\n",
      "[CV 5/5] END alpha=0.1, l1_ratio=0.9;, score=(train=-0.189, test=-0.207) total time=   6.6s\n",
      "[CV 3/5] END alpha=0.1, l1_ratio=0.95;, score=(train=-0.201, test=-0.204) total time=   5.5s\n",
      "[CV 1/5] END alpha=0.1, l1_ratio=0.95;, score=(train=-0.197, test=-0.194) total time=   6.8s\n",
      "[CV 2/5] END alpha=0.1, l1_ratio=0.95;, score=(train=-0.198, test=-0.194) total time=   6.7s\n",
      "[CV 4/5] END alpha=0.1, l1_ratio=0.95;, score=(train=-0.198, test=-0.192) total time=   6.2s\n",
      "[CV 1/5] END alpha=0.1, l1_ratio=0.99;, score=(train=-0.201, test=-0.198) total time=   6.1s\n",
      "[CV 5/5] END alpha=0.1, l1_ratio=0.95;, score=(train=-0.194, test=-0.212) total time=   6.5s\n",
      "[CV 2/5] END alpha=0.1, l1_ratio=0.99;, score=(train=-0.202, test=-0.198) total time=   6.2s\n",
      "[CV 4/5] END alpha=0.1, l1_ratio=0.99;, score=(train=-0.201, test=-0.195) total time=   6.0s\n",
      "[CV 3/5] END alpha=0.1, l1_ratio=0.99;, score=(train=-0.204, test=-0.208) total time=   6.4s\n",
      "[CV 5/5] END alpha=0.1, l1_ratio=0.99;, score=(train=-0.197, test=-0.216) total time=   6.1s\n",
      "[CV 1/5] END alpha=0.1, l1_ratio=1;, score=(train=-0.202, test=-0.199) total time=   6.1s\n",
      "[CV 2/5] END alpha=0.1, l1_ratio=1;, score=(train=-0.203, test=-0.199) total time=   6.0s\n",
      "[CV 1/5] END alpha=1, l1_ratio=0.1;, score=(train=-0.219, test=-0.215) total time=   4.2s\n",
      "[CV 3/5] END alpha=0.1, l1_ratio=1;, score=(train=-0.205, test=-0.209) total time=   5.8s\n",
      "[CV 4/5] END alpha=0.1, l1_ratio=1;, score=(train=-0.202, test=-0.196) total time=   6.0s\n",
      "[CV 4/5] END alpha=1, l1_ratio=0.1;, score=(train=-0.221, test=-0.211) total time=   5.1s\n",
      "[CV 5/5] END alpha=0.1, l1_ratio=1;, score=(train=-0.198, test=-0.216) total time=   6.2s\n",
      "[CV 2/5] END alpha=1, l1_ratio=0.1;, score=(train=-0.220, test=-0.215) total time=   5.6s\n",
      "[CV 2/5] END alpha=1, l1_ratio=0.5;, score=(train=-0.434, test=-0.421) total time=   2.8s\n",
      "[CV 1/5] END alpha=1, l1_ratio=0.5;, score=(train=-0.432, test=-0.414) total time=   3.0s\n",
      "[CV 3/5] END alpha=1, l1_ratio=0.1;, score=(train=-0.220, test=-0.227) total time=   5.8s\n",
      "[CV 3/5] END alpha=1, l1_ratio=0.5;, score=(train=-0.432, test=-0.459) total time=   3.1s\n",
      "[CV 1/5] END alpha=1, l1_ratio=0.7;, score=(train=-0.551, test=-0.522) total time=   1.9s\n",
      "[CV 2/5] END alpha=1, l1_ratio=0.7;, score=(train=-0.548, test=-0.532) total time=   1.6s\n",
      "[CV 4/5] END alpha=1, l1_ratio=0.5;, score=(train=-0.438, test=-0.431) total time=   3.0s\n",
      "[CV 5/5] END alpha=1, l1_ratio=0.5;, score=(train=-0.428, test=-0.444) total time=   2.7s\n",
      "[CV 3/5] END alpha=1, l1_ratio=0.7;, score=(train=-0.548, test=-0.583) total time=   1.5s\n",
      "[CV 5/5] END alpha=1, l1_ratio=0.1;, score=(train=-0.216, test=-0.235) total time=   4.7s\n",
      "[CV 4/5] END alpha=1, l1_ratio=0.7;, score=(train=-0.554, test=-0.554) total time=   1.7s\n",
      "[CV 1/5] END alpha=1, l1_ratio=0.9;, score=(train=-0.692, test=-0.658) total time=   1.4s\n",
      "[CV 2/5] END alpha=1, l1_ratio=0.9;, score=(train=-0.688, test=-0.664) total time=   1.6s\n",
      "[CV 5/5] END alpha=1, l1_ratio=0.7;, score=(train=-0.544, test=-0.558) total time=   2.0s\n",
      "[CV 3/5] END alpha=1, l1_ratio=0.9;, score=(train=-0.689, test=-0.733) total time=   1.6s\n",
      "[CV 4/5] END alpha=1, l1_ratio=0.9;, score=(train=-0.683, test=-0.688) total time=   1.5s\n",
      "[CV 5/5] END alpha=1, l1_ratio=0.9;, score=(train=-0.685, test=-0.697) total time=   1.5s\n",
      "[CV 1/5] END alpha=1, l1_ratio=0.95;, score=(train=-0.715, test=-0.681) total time=   1.7s\n",
      "[CV 2/5] END alpha=1, l1_ratio=0.99;, score=(train=-0.730, test=-0.705) total time=   1.3s\n",
      "[CV 2/5] END alpha=1, l1_ratio=0.95;, score=(train=-0.710, test=-0.686) total time=   1.8s\n",
      "[CV 3/5] END alpha=1, l1_ratio=0.95;, score=(train=-0.713, test=-0.759) total time=   1.7s\n",
      "[CV 4/5] END alpha=1, l1_ratio=0.95;, score=(train=-0.707, test=-0.710) total time=   1.8s\n",
      "[CV 5/5] END alpha=1, l1_ratio=0.95;, score=(train=-0.708, test=-0.720) total time=   1.6s\n",
      "[CV 5/5] END alpha=1, l1_ratio=0.99;, score=(train=-0.728, test=-0.740) total time=   1.3s\n",
      "[CV 1/5] END alpha=1, l1_ratio=0.99;, score=(train=-0.735, test=-0.700) total time=   1.8s\n",
      "[CV 3/5] END alpha=1, l1_ratio=0.99;, score=(train=-0.731, test=-0.780) total time=   1.6s\n",
      "[CV 1/5] END alpha=1, l1_ratio=1;, score=(train=-0.740, test=-0.705) total time=   1.5s\n",
      "[CV 4/5] END alpha=1, l1_ratio=0.99;, score=(train=-0.726, test=-0.729) total time=   1.7s\n",
      "[CV 2/5] END alpha=1, l1_ratio=1;, score=(train=-0.735, test=-0.709) total time=   1.8s\n",
      "[CV 3/5] END alpha=1, l1_ratio=1;, score=(train=-0.731, test=-0.780) total time=   1.4s\n",
      "[CV 1/5] END alpha=100.0, l1_ratio=0.1;, score=(train=-0.748, test=-0.713) total time=   1.2s\n",
      "[CV 2/5] END alpha=100.0, l1_ratio=0.1;, score=(train=-0.746, test=-0.720) total time=   1.4s\n",
      "[CV 4/5] END alpha=1, l1_ratio=1;, score=(train=-0.731, test=-0.734) total time=   1.7s\n",
      "[CV 4/5] END alpha=100.0, l1_ratio=0.1;, score=(train=-0.740, test=-0.743) total time=   1.5s\n",
      "[CV 1/5] END alpha=100.0, l1_ratio=0.5;, score=(train=-0.748, test=-0.713) total time=   1.4s\n",
      "[CV 3/5] END alpha=100.0, l1_ratio=0.1;, score=(train=-0.731, test=-0.780) total time=   1.4s\n",
      "[CV 5/5] END alpha=1, l1_ratio=1;, score=(train=-0.733, test=-0.745) total time=   1.9s\n",
      "[CV 2/5] END alpha=100.0, l1_ratio=0.5;, score=(train=-0.746, test=-0.720) total time=   1.4s\n",
      "[CV 5/5] END alpha=100.0, l1_ratio=0.1;, score=(train=-0.739, test=-0.750) total time=   1.7s\n",
      "[CV 3/5] END alpha=100.0, l1_ratio=0.5;, score=(train=-0.731, test=-0.780) total time=   1.7s\n",
      "[CV 1/5] END alpha=100.0, l1_ratio=0.7;, score=(train=-0.748, test=-0.713) total time=   1.4s\n",
      "[CV 4/5] END alpha=100.0, l1_ratio=0.5;, score=(train=-0.740, test=-0.743) total time=   1.8s\n",
      "[CV 2/5] END alpha=100.0, l1_ratio=0.7;, score=(train=-0.746, test=-0.720) total time=   1.3s\n",
      "[CV 5/5] END alpha=100.0, l1_ratio=0.5;, score=(train=-0.739, test=-0.750) total time=   1.6s\n",
      "[CV 3/5] END alpha=100.0, l1_ratio=0.7;, score=(train=-0.731, test=-0.780) total time=   1.6s\n",
      "[CV 5/5] END alpha=100.0, l1_ratio=0.7;, score=(train=-0.739, test=-0.750) total time=   1.4s\n",
      "[CV 3/5] END alpha=100.0, l1_ratio=0.9;, score=(train=-0.731, test=-0.780) total time=   1.4s\n",
      "[CV 4/5] END alpha=100.0, l1_ratio=0.7;, score=(train=-0.740, test=-0.743) total time=   1.7s\n",
      "[CV 1/5] END alpha=100.0, l1_ratio=0.9;, score=(train=-0.748, test=-0.713) total time=   1.5s\n",
      "[CV 4/5] END alpha=100.0, l1_ratio=0.9;, score=(train=-0.740, test=-0.743) total time=   1.5s\n",
      "[CV 2/5] END alpha=100.0, l1_ratio=0.9;, score=(train=-0.746, test=-0.720) total time=   1.6s\n",
      "[CV 5/5] END alpha=100.0, l1_ratio=0.9;, score=(train=-0.739, test=-0.750) total time=   1.9s\n",
      "[CV 1/5] END alpha=100.0, l1_ratio=0.95;, score=(train=-0.748, test=-0.713) total time=   1.4s\n",
      "[CV 3/5] END alpha=100.0, l1_ratio=0.95;, score=(train=-0.731, test=-0.780) total time=   1.4s\n",
      "[CV 2/5] END alpha=100.0, l1_ratio=0.95;, score=(train=-0.746, test=-0.720) total time=   1.5s\n",
      "[CV 4/5] END alpha=100.0, l1_ratio=0.95;, score=(train=-0.740, test=-0.743) total time=   1.4s\n",
      "[CV 5/5] END alpha=100.0, l1_ratio=0.95;, score=(train=-0.739, test=-0.750) total time=   1.6s\n",
      "[CV 5/5] END alpha=100.0, l1_ratio=0.99;, score=(train=-0.739, test=-0.750) total time=   1.3s\n",
      "[CV 1/5] END alpha=100.0, l1_ratio=0.99;, score=(train=-0.748, test=-0.713) total time=   1.6s\n",
      "[CV 3/5] END alpha=100.0, l1_ratio=0.99;, score=(train=-0.731, test=-0.780) total time=   1.6s\n",
      "[CV 2/5] END alpha=100.0, l1_ratio=0.99;, score=(train=-0.746, test=-0.720) total time=   1.7s\n",
      "[CV 4/5] END alpha=100.0, l1_ratio=0.99;, score=(train=-0.740, test=-0.743) total time=   1.6s\n",
      "[CV 1/5] END alpha=100.0, l1_ratio=1;, score=(train=-0.748, test=-0.713) total time=   1.6s\n",
      "[CV 2/5] END alpha=100.0, l1_ratio=1;, score=(train=-0.746, test=-0.720) total time=   1.5s\n",
      "[CV 3/5] END alpha=100.0, l1_ratio=1;, score=(train=-0.731, test=-0.780) total time=   1.5s\n",
      "[CV 4/5] END alpha=100.0, l1_ratio=1;, score=(train=-0.740, test=-0.743) total time=   1.5s\n",
      "[CV 5/5] END alpha=100.0, l1_ratio=1;, score=(train=-0.739, test=-0.750) total time=   1.6s\n",
      "[CV 1/5] END alpha=1000.0, l1_ratio=0.1;, score=(train=-0.748, test=-0.713) total time=   1.6s\n",
      "[CV 4/5] END alpha=1000.0, l1_ratio=0.1;, score=(train=-0.740, test=-0.743) total time=   1.4s\n",
      "[CV 1/5] END alpha=1000.0, l1_ratio=0.5;, score=(train=-0.748, test=-0.713) total time=   1.4s\n",
      "[CV 3/5] END alpha=1000.0, l1_ratio=0.1;, score=(train=-0.731, test=-0.780) total time=   1.6s\n",
      "[CV 3/5] END alpha=1000.0, l1_ratio=0.5;, score=(train=-0.731, test=-0.780) total time=   1.5s[CV 2/5] END alpha=1000.0, l1_ratio=0.1;, score=(train=-0.746, test=-0.720) total time=   1.8s\n",
      "\n",
      "[CV 5/5] END alpha=1000.0, l1_ratio=0.1;, score=(train=-0.739, test=-0.750) total time=   1.8s\n",
      "[CV 2/5] END alpha=1000.0, l1_ratio=0.5;, score=(train=-0.746, test=-0.720) total time=   1.7s\n",
      "[CV 4/5] END alpha=1000.0, l1_ratio=0.5;, score=(train=-0.740, test=-0.743) total time=   1.3s\n",
      "[CV 5/5] END alpha=1000.0, l1_ratio=0.5;, score=(train=-0.739, test=-0.750) total time=   1.6s\n",
      "[CV 1/5] END alpha=1000.0, l1_ratio=0.7;, score=(train=-0.748, test=-0.713) total time=   1.5s\n",
      "[CV 3/5] END alpha=1000.0, l1_ratio=0.7;, score=(train=-0.731, test=-0.780) total time=   1.5s\n",
      "[CV 2/5] END alpha=1000.0, l1_ratio=0.7;, score=(train=-0.746, test=-0.720) total time=   1.7s\n",
      "[CV 4/5] END alpha=1000.0, l1_ratio=0.7;, score=(train=-0.740, test=-0.743) total time=   1.4s\n",
      "[CV 5/5] END alpha=1000.0, l1_ratio=0.7;, score=(train=-0.739, test=-0.750) total time=   1.3s\n",
      "[CV 1/5] END alpha=1000.0, l1_ratio=0.9;, score=(train=-0.748, test=-0.713) total time=   1.4s\n",
      "[CV 4/5] END alpha=1000.0, l1_ratio=0.9;, score=(train=-0.740, test=-0.743) total time=   1.4s\n",
      "[CV 2/5] END alpha=1000.0, l1_ratio=0.9;, score=(train=-0.746, test=-0.720) total time=   1.5s\n",
      "[CV 3/5] END alpha=1000.0, l1_ratio=0.9;, score=(train=-0.731, test=-0.780) total time=   1.6s\n",
      "[CV 5/5] END alpha=1000.0, l1_ratio=0.9;, score=(train=-0.739, test=-0.750) total time=   1.7s\n",
      "[CV 1/5] END alpha=1000.0, l1_ratio=0.95;, score=(train=-0.748, test=-0.713) total time=   1.7s\n",
      "[CV 2/5] END alpha=1000.0, l1_ratio=0.95;, score=(train=-0.746, test=-0.720) total time=   1.4s\n",
      "[CV 4/5] END alpha=1000.0, l1_ratio=0.95;, score=(train=-0.740, test=-0.743) total time=   1.4s\n",
      "[CV 3/5] END alpha=1000.0, l1_ratio=0.95;, score=(train=-0.731, test=-0.780) total time=   1.6s\n",
      "[CV 1/5] END alpha=1000.0, l1_ratio=0.99;, score=(train=-0.748, test=-0.713) total time=   1.6s\n",
      "[CV 2/5] END alpha=1000.0, l1_ratio=0.99;, score=(train=-0.746, test=-0.720) total time=   1.6s\n",
      "[CV 5/5] END alpha=1000.0, l1_ratio=0.95;, score=(train=-0.739, test=-0.750) total time=   1.6s\n",
      "[CV 3/5] END alpha=1000.0, l1_ratio=0.99;, score=(train=-0.731, test=-0.780) total time=   1.6s\n",
      "[CV 1/5] END alpha=1000.0, l1_ratio=1;, score=(train=-0.748, test=-0.713) total time=   1.2s\n",
      "[CV 5/5] END alpha=1000.0, l1_ratio=0.99;, score=(train=-0.739, test=-0.750) total time=   1.3s\n",
      "[CV 4/5] END alpha=1000.0, l1_ratio=0.99;, score=(train=-0.740, test=-0.743) total time=   1.6s\n",
      "[CV 3/5] END alpha=1000.0, l1_ratio=1;, score=(train=-0.731, test=-0.780) total time=   1.1s\n",
      "[CV 2/5] END alpha=1000.0, l1_ratio=1;, score=(train=-0.746, test=-0.720) total time=   1.3s\n",
      "[CV 4/5] END alpha=1000.0, l1_ratio=1;, score=(train=-0.740, test=-0.743) total time=   1.2s\n",
      "[CV 5/5] END alpha=1000.0, l1_ratio=1;, score=(train=-0.739, test=-0.750) total time=   0.9s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=ElasticNet(), n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1, 1, 100.0, 1000.0],\n",
       "                         &#x27;l1_ratio&#x27;: [0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1]},\n",
       "             return_train_score=True, scoring=&#x27;neg_mean_squared_error&#x27;,\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=ElasticNet(), n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1, 1, 100.0, 1000.0],\n",
       "                         &#x27;l1_ratio&#x27;: [0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1]},\n",
       "             return_train_score=True, scoring=&#x27;neg_mean_squared_error&#x27;,\n",
       "             verbose=3)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: ElasticNet</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>ElasticNet(alpha=0.01)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>ElasticNet</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.ElasticNet.html\">?<span>Documentation for ElasticNet</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>ElasticNet(alpha=0.01)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=ElasticNet(), n_jobs=-1,\n",
       "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 100.0, 1000.0],\n",
       "                         'l1_ratio': [0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1]},\n",
       "             return_train_score=True, scoring='neg_mean_squared_error',\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "hyperparameters_to_test = {\n",
    "    \"alpha\": [1e-4, 1e-3, 1e-2, 1e-1, 1, 1e2, 1e3],\n",
    "    \"l1_ratio\": [\n",
    "        0.1,\n",
    "        0.5,\n",
    "        0.7,\n",
    "        0.9,\n",
    "        0.95,\n",
    "        0.99,\n",
    "        1,\n",
    "    ],  # testing more values near 1 as suggested by the sklearn documentation\n",
    "}\n",
    "\n",
    "elastic_net = ElasticNet()\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search_en = GridSearchCV(\n",
    "    estimator=elastic_net,\n",
    "    param_grid=hyperparameters_to_test,\n",
    "    cv=kfold,\n",
    "    return_train_score=True,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    n_jobs=-1,\n",
    "    verbose=3,\n",
    ")\n",
    "\n",
    "X = X_train\n",
    "y = y_train[\"Expected\"]\n",
    "\n",
    "grid_search_en.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters of the best model obtained: {'alpha': 0.01, 'l1_ratio': 0.5}\n",
      "Mean train error of the best model obtained: 0.10011185944375278\n",
      "Mean validation error of the best model obtained: 0.1162091941485709\n"
     ]
    }
   ],
   "source": [
    "print(f\"Hyperparameters of the best model obtained: {grid_search_en.best_params_}\")\n",
    "\n",
    "cv_results_en = grid_search_en.cv_results_\n",
    "best_index_en = grid_search_en.best_index_\n",
    "\n",
    "train_err_en = -cv_results_en[\"mean_train_score\"][best_index_en]\n",
    "val_err_en = -cv_results_en[\"mean_test_score\"][best_index_en]\n",
    "\n",
    "print(f\"Mean train error of the best model obtained: {train_err_en}\")\n",
    "print(f\"Mean validation error of the best model obtained: {val_err_en}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search was performed for various values of hyperparameters `alpha` and `l1_ratio`.\n",
    "\n",
    "`alpha` was tested for different orders of magnitude, i.e. from 1e-4 to 1e3\n",
    "\n",
    "`l1_ratio` was tested in range [0, 1], with more emphasis on the values closer to 1 (as suggested by the sklearn documentation [here](https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.ElasticNetCV.html))\n",
    "\n",
    "The `KFold` object was declared separately from the `GridSearchCV` in order to be reused later, assuring the reasonable comparison of ElasticNet and RandomForest models. The cross-validation was performed using 5 folds, i.e. the validation set size is 20% of the whole dataset size (~759 observations), which should be enough for our case. It's a little more than the size of the test set, which is 670. Using more folds might be beneficial (as there would be more data for training), but it would reduce size of the validation set and could therefore provide less meaningful results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try a different, tree-based approach. We'll feet a `RandomForestRegressor` using the same cross-validation + grid search approach, but this time tuning different hyperparameters. As the mentioned model has many such parameters and we only want to tune 3 of them, I decided to choose those considered in the literature as impactful ones, i.e.:\n",
    "- `n_estimators` - numbers of trees in the forest\n",
    "- `max_features` - number of features to consider when looking for the best split\n",
    "- `min_samples_split` - minimum number of samples required to split an internal node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "[CV 4/5] END max_features=sqrt, min_samples_split=2, n_estimators=10;, score=(train=-0.030, test=-0.135) total time=   1.5s\n",
      "[CV 1/5] END max_features=sqrt, min_samples_split=2, n_estimators=10;, score=(train=-0.028, test=-0.157) total time=   1.7s\n",
      "[CV 3/5] END max_features=sqrt, min_samples_split=2, n_estimators=10;, score=(train=-0.031, test=-0.152) total time=   1.8s\n",
      "[CV 5/5] END max_features=sqrt, min_samples_split=2, n_estimators=10;, score=(train=-0.031, test=-0.151) total time=   1.9s\n",
      "[CV 2/5] END max_features=sqrt, min_samples_split=2, n_estimators=10;, score=(train=-0.028, test=-0.145) total time=   2.3s\n",
      "[CV 5/5] END max_features=sqrt, min_samples_split=2, n_estimators=20;, score=(train=-0.022, test=-0.144) total time=   2.9s\n",
      "[CV 4/5] END max_features=sqrt, min_samples_split=2, n_estimators=20;, score=(train=-0.023, test=-0.123) total time=   2.9s\n",
      "[CV 2/5] END max_features=sqrt, min_samples_split=2, n_estimators=20;, score=(train=-0.023, test=-0.134) total time=   2.9s\n",
      "[CV 3/5] END max_features=sqrt, min_samples_split=2, n_estimators=20;, score=(train=-0.022, test=-0.138) total time=   3.2s\n",
      "[CV 1/5] END max_features=sqrt, min_samples_split=2, n_estimators=20;, score=(train=-0.023, test=-0.139) total time=   3.2s\n",
      "[CV 1/5] END max_features=sqrt, min_samples_split=5, n_estimators=10;, score=(train=-0.033, test=-0.154) total time=   1.4s\n",
      "[CV 2/5] END max_features=sqrt, min_samples_split=5, n_estimators=10;, score=(train=-0.034, test=-0.147) total time=   1.5s\n",
      "[CV 3/5] END max_features=sqrt, min_samples_split=5, n_estimators=10;, score=(train=-0.033, test=-0.147) total time=   1.2s\n",
      "[CV 4/5] END max_features=sqrt, min_samples_split=5, n_estimators=10;, score=(train=-0.036, test=-0.132) total time=   1.3s\n",
      "[CV 1/5] END max_features=sqrt, min_samples_split=2, n_estimators=50;, score=(train=-0.018, test=-0.137) total time=   6.7s\n",
      "[CV 2/5] END max_features=sqrt, min_samples_split=2, n_estimators=50;, score=(train=-0.019, test=-0.124) total time=   6.8s\n",
      "[CV 5/5] END max_features=sqrt, min_samples_split=5, n_estimators=10;, score=(train=-0.033, test=-0.152) total time=   1.2s\n",
      "[CV 4/5] END max_features=sqrt, min_samples_split=2, n_estimators=50;, score=(train=-0.019, test=-0.114) total time=   5.7s\n",
      "[CV 3/5] END max_features=sqrt, min_samples_split=2, n_estimators=50;, score=(train=-0.019, test=-0.124) total time=   6.2s\n",
      "[CV 5/5] END max_features=sqrt, min_samples_split=2, n_estimators=50;, score=(train=-0.019, test=-0.135) total time=   6.2s\n",
      "[CV 1/5] END max_features=sqrt, min_samples_split=5, n_estimators=20;, score=(train=-0.027, test=-0.135) total time=   2.2s\n",
      "[CV 2/5] END max_features=sqrt, min_samples_split=5, n_estimators=20;, score=(train=-0.028, test=-0.132) total time=   2.2s\n",
      "[CV 3/5] END max_features=sqrt, min_samples_split=5, n_estimators=20;, score=(train=-0.028, test=-0.140) total time=   2.2s\n",
      "[CV 4/5] END max_features=sqrt, min_samples_split=5, n_estimators=20;, score=(train=-0.030, test=-0.120) total time=   2.3s\n",
      "[CV 5/5] END max_features=sqrt, min_samples_split=5, n_estimators=20;, score=(train=-0.028, test=-0.148) total time=   2.4s\n",
      "[CV 2/5] END max_features=sqrt, min_samples_split=5, n_estimators=50;, score=(train=-0.024, test=-0.122) total time=   4.9s\n",
      "[CV 1/5] END max_features=sqrt, min_samples_split=2, n_estimators=100;, score=(train=-0.017, test=-0.127) total time=  11.0s\n",
      "[CV 1/5] END max_features=sqrt, min_samples_split=5, n_estimators=50;, score=(train=-0.023, test=-0.128) total time=   5.7s\n",
      "[CV 3/5] END max_features=sqrt, min_samples_split=5, n_estimators=50;, score=(train=-0.023, test=-0.133) total time=   5.6s\n",
      "[CV 4/5] END max_features=sqrt, min_samples_split=5, n_estimators=50;, score=(train=-0.025, test=-0.119) total time=   5.2s\n",
      "[CV 5/5] END max_features=sqrt, min_samples_split=5, n_estimators=50;, score=(train=-0.024, test=-0.133) total time=   5.2s\n",
      "[CV 2/5] END max_features=sqrt, min_samples_split=2, n_estimators=100;, score=(train=-0.017, test=-0.122) total time=  12.2s\n",
      "[CV 3/5] END max_features=sqrt, min_samples_split=2, n_estimators=100;, score=(train=-0.018, test=-0.127) total time=  11.9s\n",
      "[CV 5/5] END max_features=sqrt, min_samples_split=2, n_estimators=100;, score=(train=-0.018, test=-0.131) total time=  12.1s\n",
      "[CV 2/5] END max_features=sqrt, min_samples_split=8, n_estimators=10;, score=(train=-0.041, test=-0.149) total time=   1.3s\n",
      "[CV 1/5] END max_features=sqrt, min_samples_split=8, n_estimators=10;, score=(train=-0.038, test=-0.142) total time=   1.4s\n",
      "[CV 4/5] END max_features=sqrt, min_samples_split=2, n_estimators=100;, score=(train=-0.018, test=-0.114) total time=  12.7s\n",
      "[CV 3/5] END max_features=sqrt, min_samples_split=8, n_estimators=10;, score=(train=-0.040, test=-0.154) total time=   1.4s\n",
      "[CV 4/5] END max_features=sqrt, min_samples_split=8, n_estimators=10;, score=(train=-0.044, test=-0.140) total time=   1.3s\n",
      "[CV 5/5] END max_features=sqrt, min_samples_split=8, n_estimators=10;, score=(train=-0.037, test=-0.154) total time=   1.4s\n",
      "[CV 3/5] END max_features=sqrt, min_samples_split=8, n_estimators=20;, score=(train=-0.034, test=-0.141) total time=   2.0s\n",
      "[CV 4/5] END max_features=sqrt, min_samples_split=8, n_estimators=20;, score=(train=-0.034, test=-0.121) total time=   2.1s\n",
      "[CV 1/5] END max_features=sqrt, min_samples_split=8, n_estimators=20;, score=(train=-0.032, test=-0.140) total time=   2.9s\n",
      "[CV 5/5] END max_features=sqrt, min_samples_split=8, n_estimators=20;, score=(train=-0.032, test=-0.143) total time=   2.1s\n",
      "[CV 2/5] END max_features=sqrt, min_samples_split=8, n_estimators=20;, score=(train=-0.034, test=-0.135) total time=   2.4s\n",
      "[CV 1/5] END max_features=sqrt, min_samples_split=5, n_estimators=100;, score=(train=-0.022, test=-0.131) total time=  10.2s\n",
      "[CV 2/5] END max_features=sqrt, min_samples_split=5, n_estimators=100;, score=(train=-0.023, test=-0.125) total time=  10.5s\n",
      "[CV 1/5] END max_features=sqrt, min_samples_split=8, n_estimators=50;, score=(train=-0.030, test=-0.137) total time=   4.9s\n",
      "[CV 2/5] END max_features=sqrt, min_samples_split=8, n_estimators=50;, score=(train=-0.030, test=-0.126) total time=   5.0s\n",
      "[CV 3/5] END max_features=sqrt, min_samples_split=8, n_estimators=50;, score=(train=-0.030, test=-0.132) total time=   5.1s\n",
      "[CV 1/5] END max_features=sqrt, min_samples_split=11, n_estimators=10;, score=(train=-0.043, test=-0.143) total time=   1.5s\n",
      "[CV 4/5] END max_features=sqrt, min_samples_split=8, n_estimators=50;, score=(train=-0.031, test=-0.122) total time=   4.9s\n",
      "[CV 5/5] END max_features=sqrt, min_samples_split=8, n_estimators=50;, score=(train=-0.030, test=-0.137) total time=   5.5s\n",
      "[CV 3/5] END max_features=sqrt, min_samples_split=5, n_estimators=100;, score=(train=-0.022, test=-0.125) total time=  10.8s\n",
      "[CV 5/5] END max_features=sqrt, min_samples_split=5, n_estimators=100;, score=(train=-0.022, test=-0.133) total time=  10.7s\n",
      "[CV 4/5] END max_features=sqrt, min_samples_split=11, n_estimators=10;, score=(train=-0.044, test=-0.122) total time=   1.3s\n",
      "[CV 3/5] END max_features=sqrt, min_samples_split=11, n_estimators=10;, score=(train=-0.044, test=-0.152) total time=   1.4s\n",
      "[CV 4/5] END max_features=sqrt, min_samples_split=5, n_estimators=100;, score=(train=-0.023, test=-0.115) total time=  11.4s\n",
      "[CV 2/5] END max_features=sqrt, min_samples_split=11, n_estimators=10;, score=(train=-0.044, test=-0.146) total time=   1.7s\n",
      "[CV 5/5] END max_features=sqrt, min_samples_split=11, n_estimators=10;, score=(train=-0.045, test=-0.147) total time=   1.4s\n",
      "[CV 1/5] END max_features=sqrt, min_samples_split=11, n_estimators=20;, score=(train=-0.038, test=-0.142) total time=   2.1s\n",
      "[CV 3/5] END max_features=sqrt, min_samples_split=11, n_estimators=20;, score=(train=-0.040, test=-0.134) total time=   2.1s\n",
      "[CV 2/5] END max_features=sqrt, min_samples_split=11, n_estimators=20;, score=(train=-0.039, test=-0.134) total time=   2.3s\n",
      "[CV 5/5] END max_features=sqrt, min_samples_split=11, n_estimators=20;, score=(train=-0.038, test=-0.148) total time=   2.2s\n",
      "[CV 4/5] END max_features=sqrt, min_samples_split=11, n_estimators=20;, score=(train=-0.042, test=-0.124) total time=   2.7s\n",
      "[CV 1/5] END max_features=sqrt, min_samples_split=8, n_estimators=100;, score=(train=-0.028, test=-0.133) total time=   9.7s\n",
      "[CV 2/5] END max_features=sqrt, min_samples_split=8, n_estimators=100;, score=(train=-0.029, test=-0.128) total time=   9.8s\n",
      "[CV 3/5] END max_features=sqrt, min_samples_split=8, n_estimators=100;, score=(train=-0.028, test=-0.130) total time=   9.6s\n",
      "[CV 2/5] END max_features=sqrt, min_samples_split=11, n_estimators=50;, score=(train=-0.036, test=-0.131) total time=   4.4s\n",
      "[CV 1/5] END max_features=sqrt, min_samples_split=11, n_estimators=50;, score=(train=-0.035, test=-0.133) total time=   4.9s\n",
      "[CV 4/5] END max_features=sqrt, min_samples_split=8, n_estimators=100;, score=(train=-0.031, test=-0.119) total time=   9.7s\n",
      "[CV 3/5] END max_features=sqrt, min_samples_split=11, n_estimators=50;, score=(train=-0.035, test=-0.130) total time=   4.7s\n",
      "[CV 5/5] END max_features=sqrt, min_samples_split=8, n_estimators=100;, score=(train=-0.029, test=-0.130) total time=  10.6s\n",
      "[CV 5/5] END max_features=sqrt, min_samples_split=11, n_estimators=50;, score=(train=-0.035, test=-0.137) total time=   4.9s\n",
      "[CV 4/5] END max_features=sqrt, min_samples_split=11, n_estimators=50;, score=(train=-0.037, test=-0.118) total time=   5.5s\n",
      "[CV 1/5] END max_features=sqrt, min_samples_split=11, n_estimators=100;, score=(train=-0.034, test=-0.130) total time=   9.5s\n",
      "[CV 4/5] END max_features=sqrt, min_samples_split=11, n_estimators=100;, score=(train=-0.035, test=-0.115) total time=   8.6s\n",
      "[CV 2/5] END max_features=sqrt, min_samples_split=11, n_estimators=100;, score=(train=-0.034, test=-0.124) total time=  10.1s[CV 3/5] END max_features=sqrt, min_samples_split=11, n_estimators=100;, score=(train=-0.035, test=-0.133) total time=   9.5s\n",
      "\n",
      "[CV 5/5] END max_features=sqrt, min_samples_split=11, n_estimators=100;, score=(train=-0.034, test=-0.131) total time=   9.0s\n",
      "[CV 1/5] END max_features=0.1, min_samples_split=2, n_estimators=10;, score=(train=-0.024, test=-0.129) total time=  10.1s\n",
      "[CV 3/5] END max_features=0.1, min_samples_split=2, n_estimators=10;, score=(train=-0.023, test=-0.118) total time=  10.3s\n",
      "[CV 2/5] END max_features=0.1, min_samples_split=2, n_estimators=10;, score=(train=-0.022, test=-0.118) total time=  11.5s\n",
      "[CV 4/5] END max_features=0.1, min_samples_split=2, n_estimators=10;, score=(train=-0.024, test=-0.109) total time=  11.4s\n",
      "[CV 5/5] END max_features=0.1, min_samples_split=2, n_estimators=10;, score=(train=-0.023, test=-0.128) total time=  11.0s\n",
      "[CV 1/5] END max_features=0.1, min_samples_split=2, n_estimators=20;, score=(train=-0.018, test=-0.119) total time=  21.5s\n",
      "[CV 2/5] END max_features=0.1, min_samples_split=2, n_estimators=20;, score=(train=-0.019, test=-0.116) total time=  23.2s\n",
      "[CV 4/5] END max_features=0.1, min_samples_split=2, n_estimators=20;, score=(train=-0.018, test=-0.104) total time=  21.5s\n",
      "[CV 3/5] END max_features=0.1, min_samples_split=2, n_estimators=20;, score=(train=-0.018, test=-0.115) total time=  22.8s\n",
      "[CV 5/5] END max_features=0.1, min_samples_split=2, n_estimators=20;, score=(train=-0.019, test=-0.120) total time=  22.4s\n",
      "[CV 1/5] END max_features=0.1, min_samples_split=5, n_estimators=10;, score=(train=-0.025, test=-0.130) total time=   9.0s\n",
      "[CV 2/5] END max_features=0.1, min_samples_split=5, n_estimators=10;, score=(train=-0.024, test=-0.115) total time=  10.5s\n",
      "[CV 3/5] END max_features=0.1, min_samples_split=5, n_estimators=10;, score=(train=-0.027, test=-0.126) total time=   9.8s\n",
      "[CV 4/5] END max_features=0.1, min_samples_split=5, n_estimators=10;, score=(train=-0.027, test=-0.118) total time=  10.1s\n",
      "[CV 5/5] END max_features=0.1, min_samples_split=5, n_estimators=10;, score=(train=-0.027, test=-0.131) total time=  10.2s\n",
      "[CV 1/5] END max_features=0.1, min_samples_split=2, n_estimators=50;, score=(train=-0.016, test=-0.115) total time=  52.0s\n",
      "[CV 2/5] END max_features=0.1, min_samples_split=2, n_estimators=50;, score=(train=-0.016, test=-0.106) total time=  50.9s\n",
      "[CV 3/5] END max_features=0.1, min_samples_split=2, n_estimators=50;, score=(train=-0.016, test=-0.107) total time=  51.5s\n",
      "[CV 4/5] END max_features=0.1, min_samples_split=2, n_estimators=50;, score=(train=-0.016, test=-0.097) total time=  52.1s\n",
      "[CV 5/5] END max_features=0.1, min_samples_split=2, n_estimators=50;, score=(train=-0.015, test=-0.112) total time=  52.6s\n",
      "[CV 1/5] END max_features=0.1, min_samples_split=5, n_estimators=20;, score=(train=-0.021, test=-0.115) total time=  18.4s\n",
      "[CV 3/5] END max_features=0.1, min_samples_split=5, n_estimators=20;, score=(train=-0.022, test=-0.111) total time=  19.4s\n",
      "[CV 2/5] END max_features=0.1, min_samples_split=5, n_estimators=20;, score=(train=-0.022, test=-0.108) total time=  20.2s\n",
      "[CV 4/5] END max_features=0.1, min_samples_split=5, n_estimators=20;, score=(train=-0.022, test=-0.100) total time=  20.6s\n",
      "[CV 5/5] END max_features=0.1, min_samples_split=5, n_estimators=20;, score=(train=-0.021, test=-0.116) total time=  20.1s\n",
      "[CV 1/5] END max_features=0.1, min_samples_split=5, n_estimators=50;, score=(train=-0.018, test=-0.115) total time=  45.8s\n",
      "[CV 2/5] END max_features=0.1, min_samples_split=5, n_estimators=50;, score=(train=-0.018, test=-0.102) total time=  48.4s\n",
      "[CV 3/5] END max_features=0.1, min_samples_split=5, n_estimators=50;, score=(train=-0.019, test=-0.107) total time=  45.3s\n",
      "[CV 2/5] END max_features=0.1, min_samples_split=2, n_estimators=100;, score=(train=-0.015, test=-0.105) total time= 1.8min\n",
      "[CV 1/5] END max_features=0.1, min_samples_split=2, n_estimators=100;, score=(train=-0.015, test=-0.114) total time= 1.8min\n",
      "[CV 3/5] END max_features=0.1, min_samples_split=2, n_estimators=100;, score=(train=-0.015, test=-0.106) total time= 1.7min\n",
      "[CV 4/5] END max_features=0.1, min_samples_split=5, n_estimators=50;, score=(train=-0.020, test=-0.096) total time=  48.1s\n",
      "[CV 1/5] END max_features=0.1, min_samples_split=8, n_estimators=10;, score=(train=-0.028, test=-0.128) total time=   9.5s\n",
      "[CV 2/5] END max_features=0.1, min_samples_split=8, n_estimators=10;, score=(train=-0.030, test=-0.111) total time=  10.3s\n",
      "[CV 5/5] END max_features=0.1, min_samples_split=5, n_estimators=50;, score=(train=-0.019, test=-0.118) total time=  50.7s\n",
      "[CV 4/5] END max_features=0.1, min_samples_split=2, n_estimators=100;, score=(train=-0.015, test=-0.097) total time= 1.8min\n",
      "[CV 3/5] END max_features=0.1, min_samples_split=8, n_estimators=10;, score=(train=-0.031, test=-0.123) total time=   9.2s\n",
      "[CV 5/5] END max_features=0.1, min_samples_split=2, n_estimators=100;, score=(train=-0.014, test=-0.109) total time= 1.8min\n",
      "[CV 4/5] END max_features=0.1, min_samples_split=8, n_estimators=10;, score=(train=-0.028, test=-0.105) total time=   9.3s\n",
      "[CV 5/5] END max_features=0.1, min_samples_split=8, n_estimators=10;, score=(train=-0.029, test=-0.129) total time=   9.2s\n",
      "[CV 2/5] END max_features=0.1, min_samples_split=8, n_estimators=20;, score=(train=-0.025, test=-0.106) total time=  18.2s\n",
      "[CV 1/5] END max_features=0.1, min_samples_split=8, n_estimators=20;, score=(train=-0.025, test=-0.122) total time=  19.4s\n",
      "[CV 3/5] END max_features=0.1, min_samples_split=8, n_estimators=20;, score=(train=-0.024, test=-0.108) total time=  18.5s\n",
      "[CV 5/5] END max_features=0.1, min_samples_split=8, n_estimators=20;, score=(train=-0.025, test=-0.121) total time=  20.1s\n",
      "[CV 4/5] END max_features=0.1, min_samples_split=8, n_estimators=20;, score=(train=-0.025, test=-0.101) total time=  21.3s\n",
      "[CV 1/5] END max_features=0.1, min_samples_split=5, n_estimators=100;, score=(train=-0.018, test=-0.112) total time= 1.6min\n",
      "[CV 2/5] END max_features=0.1, min_samples_split=5, n_estimators=100;, score=(train=-0.018, test=-0.103) total time= 1.6min\n",
      "[CV 1/5] END max_features=0.1, min_samples_split=8, n_estimators=50;, score=(train=-0.022, test=-0.110) total time=  45.1s\n",
      "[CV 2/5] END max_features=0.1, min_samples_split=8, n_estimators=50;, score=(train=-0.023, test=-0.103) total time=  47.3s\n",
      "[CV 1/5] END max_features=0.1, min_samples_split=11, n_estimators=10;, score=(train=-0.033, test=-0.126) total time=   9.2s\n",
      "[CV 3/5] END max_features=0.1, min_samples_split=8, n_estimators=50;, score=(train=-0.022, test=-0.107) total time=  48.1s\n",
      "[CV 5/5] END max_features=0.1, min_samples_split=8, n_estimators=50;, score=(train=-0.022, test=-0.111) total time=  47.2s\n",
      "[CV 4/5] END max_features=0.1, min_samples_split=8, n_estimators=50;, score=(train=-0.024, test=-0.097) total time=  49.3s\n",
      "[CV 3/5] END max_features=0.1, min_samples_split=5, n_estimators=100;, score=(train=-0.018, test=-0.107) total time= 1.5min\n",
      "[CV 2/5] END max_features=0.1, min_samples_split=11, n_estimators=10;, score=(train=-0.031, test=-0.117) total time=   9.1s\n",
      "[CV 4/5] END max_features=0.1, min_samples_split=11, n_estimators=10;, score=(train=-0.033, test=-0.106) total time=   9.5s\n",
      "[CV 3/5] END max_features=0.1, min_samples_split=11, n_estimators=10;, score=(train=-0.033, test=-0.116) total time=  10.2s\n",
      "[CV 5/5] END max_features=0.1, min_samples_split=11, n_estimators=10;, score=(train=-0.033, test=-0.126) total time=   9.6s\n",
      "[CV 4/5] END max_features=0.1, min_samples_split=5, n_estimators=100;, score=(train=-0.018, test=-0.094) total time= 1.6min\n",
      "[CV 5/5] END max_features=0.1, min_samples_split=5, n_estimators=100;, score=(train=-0.018, test=-0.110) total time= 1.6min\n",
      "[CV 1/5] END max_features=0.1, min_samples_split=11, n_estimators=20;, score=(train=-0.027, test=-0.116) total time=  19.0s\n",
      "[CV 2/5] END max_features=0.1, min_samples_split=11, n_estimators=20;, score=(train=-0.028, test=-0.108) total time=  18.4s\n",
      "[CV 3/5] END max_features=0.1, min_samples_split=11, n_estimators=20;, score=(train=-0.029, test=-0.115) total time=  18.3s\n",
      "[CV 5/5] END max_features=0.1, min_samples_split=11, n_estimators=20;, score=(train=-0.028, test=-0.118) total time=  19.1s\n",
      "[CV 4/5] END max_features=0.1, min_samples_split=11, n_estimators=20;, score=(train=-0.029, test=-0.102) total time=  20.0s\n",
      "[CV 2/5] END max_features=0.1, min_samples_split=8, n_estimators=100;, score=(train=-0.022, test=-0.104) total time= 1.5min\n",
      "[CV 1/5] END max_features=0.1, min_samples_split=8, n_estimators=100;, score=(train=-0.022, test=-0.112) total time= 1.5min\n",
      "[CV 2/5] END max_features=0.1, min_samples_split=11, n_estimators=50;, score=(train=-0.026, test=-0.107) total time=  46.5s\n",
      "[CV 1/5] END max_features=0.1, min_samples_split=11, n_estimators=50;, score=(train=-0.026, test=-0.114) total time=  47.6s\n",
      "[CV 3/5] END max_features=0.1, min_samples_split=8, n_estimators=100;, score=(train=-0.022, test=-0.108) total time= 1.5min\n",
      "[CV 3/5] END max_features=0.1, min_samples_split=11, n_estimators=50;, score=(train=-0.027, test=-0.108) total time=  46.2s\n",
      "[CV 4/5] END max_features=0.1, min_samples_split=11, n_estimators=50;, score=(train=-0.027, test=-0.094) total time=  47.2s\n",
      "[CV 5/5] END max_features=0.1, min_samples_split=11, n_estimators=50;, score=(train=-0.027, test=-0.111) total time=  45.6s\n",
      "[CV 4/5] END max_features=0.1, min_samples_split=8, n_estimators=100;, score=(train=-0.022, test=-0.095) total time= 1.6min\n",
      "[CV 5/5] END max_features=0.1, min_samples_split=8, n_estimators=100;, score=(train=-0.022, test=-0.114) total time= 1.6min\n",
      "[CV 1/5] END max_features=0.25, min_samples_split=2, n_estimators=10;, score=(train=-0.021, test=-0.124) total time=  25.9s\n",
      "[CV 2/5] END max_features=0.25, min_samples_split=2, n_estimators=10;, score=(train=-0.023, test=-0.115) total time=  28.3s\n",
      "[CV 3/5] END max_features=0.25, min_samples_split=2, n_estimators=10;, score=(train=-0.022, test=-0.120) total time=  26.2s\n",
      "[CV 4/5] END max_features=0.25, min_samples_split=2, n_estimators=10;, score=(train=-0.022, test=-0.103) total time=  27.3s\n",
      "[CV 5/5] END max_features=0.25, min_samples_split=2, n_estimators=10;, score=(train=-0.022, test=-0.118) total time=  26.6s\n",
      "[CV 1/5] END max_features=0.1, min_samples_split=11, n_estimators=100;, score=(train=-0.025, test=-0.113) total time= 1.6min\n",
      "[CV 2/5] END max_features=0.1, min_samples_split=11, n_estimators=100;, score=(train=-0.025, test=-0.103) total time= 1.6min\n",
      "[CV 1/5] END max_features=0.25, min_samples_split=2, n_estimators=20;, score=(train=-0.017, test=-0.122) total time=  52.0s\n",
      "[CV 2/5] END max_features=0.25, min_samples_split=2, n_estimators=20;, score=(train=-0.018, test=-0.110) total time=  52.4s\n",
      "[CV 3/5] END max_features=0.25, min_samples_split=2, n_estimators=20;, score=(train=-0.018, test=-0.109) total time=  51.3s\n",
      "[CV 3/5] END max_features=0.1, min_samples_split=11, n_estimators=100;, score=(train=-0.025, test=-0.107) total time= 1.5min\n",
      "[CV 4/5] END max_features=0.1, min_samples_split=11, n_estimators=100;, score=(train=-0.026, test=-0.094) total time= 1.6min\n",
      "[CV 4/5] END max_features=0.25, min_samples_split=2, n_estimators=20;, score=(train=-0.017, test=-0.098) total time=  54.2s\n",
      "[CV 5/5] END max_features=0.25, min_samples_split=2, n_estimators=20;, score=(train=-0.017, test=-0.116) total time=  54.4s\n",
      "[CV 5/5] END max_features=0.1, min_samples_split=11, n_estimators=100;, score=(train=-0.025, test=-0.115) total time= 1.6min\n",
      "[CV 1/5] END max_features=0.25, min_samples_split=5, n_estimators=10;, score=(train=-0.025, test=-0.124) total time=  24.3s\n",
      "[CV 2/5] END max_features=0.25, min_samples_split=5, n_estimators=10;, score=(train=-0.024, test=-0.123) total time=  24.1s\n",
      "[CV 3/5] END max_features=0.25, min_samples_split=5, n_estimators=10;, score=(train=-0.025, test=-0.112) total time=  24.1s\n",
      "[CV 4/5] END max_features=0.25, min_samples_split=5, n_estimators=10;, score=(train=-0.026, test=-0.102) total time=  22.4s\n",
      "[CV 5/5] END max_features=0.25, min_samples_split=5, n_estimators=10;, score=(train=-0.024, test=-0.123) total time=  23.9s\n",
      "[CV 2/5] END max_features=0.25, min_samples_split=2, n_estimators=50;, score=(train=-0.016, test=-0.103) total time= 2.2min\n",
      "[CV 1/5] END max_features=0.25, min_samples_split=2, n_estimators=50;, score=(train=-0.015, test=-0.116) total time= 2.3min\n",
      "[CV 1/5] END max_features=0.25, min_samples_split=5, n_estimators=20;, score=(train=-0.021, test=-0.118) total time=  49.3s\n",
      "[CV 4/5] END max_features=0.25, min_samples_split=2, n_estimators=50;, score=(train=-0.016, test=-0.092) total time= 2.2min\n",
      "[CV 3/5] END max_features=0.25, min_samples_split=2, n_estimators=50;, score=(train=-0.016, test=-0.104) total time= 2.3min\n",
      "[CV 5/5] END max_features=0.25, min_samples_split=2, n_estimators=50;, score=(train=-0.016, test=-0.113) total time= 2.3min\n",
      "[CV 2/5] END max_features=0.25, min_samples_split=5, n_estimators=20;, score=(train=-0.020, test=-0.107) total time=  47.1s\n",
      "[CV 3/5] END max_features=0.25, min_samples_split=5, n_estimators=20;, score=(train=-0.020, test=-0.108) total time=  48.8s\n",
      "[CV 4/5] END max_features=0.25, min_samples_split=5, n_estimators=20;, score=(train=-0.021, test=-0.097) total time=  47.0s\n",
      "[CV 5/5] END max_features=0.25, min_samples_split=5, n_estimators=20;, score=(train=-0.020, test=-0.120) total time=  48.6s\n",
      "[CV 1/5] END max_features=0.25, min_samples_split=5, n_estimators=50;, score=(train=-0.018, test=-0.117) total time= 2.0min\n",
      "[CV 2/5] END max_features=0.25, min_samples_split=5, n_estimators=50;, score=(train=-0.019, test=-0.103) total time= 2.0min\n",
      "[CV 3/5] END max_features=0.25, min_samples_split=5, n_estimators=50;, score=(train=-0.018, test=-0.105) total time= 2.0min\n",
      "[CV 4/5] END max_features=0.25, min_samples_split=5, n_estimators=50;, score=(train=-0.019, test=-0.095) total time= 2.0min\n",
      "[CV 1/5] END max_features=0.25, min_samples_split=2, n_estimators=100;, score=(train=-0.014, test=-0.113) total time= 4.4min\n",
      "[CV 2/5] END max_features=0.25, min_samples_split=2, n_estimators=100;, score=(train=-0.015, test=-0.101) total time= 4.3min\n",
      "[CV 5/5] END max_features=0.25, min_samples_split=5, n_estimators=50;, score=(train=-0.017, test=-0.110) total time= 2.0min\n",
      "[CV 3/5] END max_features=0.25, min_samples_split=2, n_estimators=100;, score=(train=-0.015, test=-0.104) total time= 4.4min\n",
      "[CV 4/5] END max_features=0.25, min_samples_split=2, n_estimators=100;, score=(train=-0.015, test=-0.093) total time= 4.4min\n",
      "[CV 1/5] END max_features=0.25, min_samples_split=8, n_estimators=10;, score=(train=-0.027, test=-0.131) total time=  25.0s\n",
      "[CV 5/5] END max_features=0.25, min_samples_split=2, n_estimators=100;, score=(train=-0.014, test=-0.108) total time= 4.5min\n",
      "[CV 2/5] END max_features=0.25, min_samples_split=8, n_estimators=10;, score=(train=-0.028, test=-0.121) total time=  26.1s\n",
      "[CV 3/5] END max_features=0.25, min_samples_split=8, n_estimators=10;, score=(train=-0.026, test=-0.111) total time=  24.5s\n",
      "[CV 4/5] END max_features=0.25, min_samples_split=8, n_estimators=10;, score=(train=-0.029, test=-0.098) total time=  25.8s\n",
      "[CV 5/5] END max_features=0.25, min_samples_split=8, n_estimators=10;, score=(train=-0.028, test=-0.123) total time=  24.6s\n",
      "[CV 1/5] END max_features=0.25, min_samples_split=8, n_estimators=20;, score=(train=-0.024, test=-0.124) total time=  46.8s\n",
      "[CV 2/5] END max_features=0.25, min_samples_split=8, n_estimators=20;, score=(train=-0.024, test=-0.112) total time=  46.9s\n",
      "[CV 3/5] END max_features=0.25, min_samples_split=8, n_estimators=20;, score=(train=-0.024, test=-0.108) total time=  44.4s\n",
      "[CV 4/5] END max_features=0.25, min_samples_split=8, n_estimators=20;, score=(train=-0.025, test=-0.098) total time=  46.3s\n",
      "[CV 5/5] END max_features=0.25, min_samples_split=8, n_estimators=20;, score=(train=-0.025, test=-0.114) total time=  46.9s\n",
      "[CV 1/5] END max_features=0.25, min_samples_split=5, n_estimators=100;, score=(train=-0.017, test=-0.111) total time= 4.0min\n",
      "[CV 2/5] END max_features=0.25, min_samples_split=8, n_estimators=50;, score=(train=-0.021, test=-0.103) total time= 1.9min\n",
      "[CV 1/5] END max_features=0.25, min_samples_split=8, n_estimators=50;, score=(train=-0.021, test=-0.115) total time= 2.0min\n",
      "[CV 2/5] END max_features=0.25, min_samples_split=5, n_estimators=100;, score=(train=-0.018, test=-0.102) total time= 4.1min\n",
      "[CV 1/5] END max_features=0.25, min_samples_split=11, n_estimators=10;, score=(train=-0.030, test=-0.119) total time=  21.7s\n",
      "[CV 3/5] END max_features=0.25, min_samples_split=8, n_estimators=50;, score=(train=-0.022, test=-0.105) total time= 1.9min\n",
      "[CV 4/5] END max_features=0.25, min_samples_split=8, n_estimators=50;, score=(train=-0.022, test=-0.096) total time= 2.0min\n",
      "[CV 5/5] END max_features=0.25, min_samples_split=8, n_estimators=50;, score=(train=-0.022, test=-0.110) total time= 2.1min\n",
      "[CV 2/5] END max_features=0.25, min_samples_split=11, n_estimators=10;, score=(train=-0.030, test=-0.109) total time=  25.3s\n",
      "[CV 3/5] END max_features=0.25, min_samples_split=11, n_estimators=10;, score=(train=-0.032, test=-0.116) total time=  23.1s\n",
      "[CV 4/5] END max_features=0.25, min_samples_split=11, n_estimators=10;, score=(train=-0.032, test=-0.106) total time=  24.9s\n",
      "[CV 3/5] END max_features=0.25, min_samples_split=5, n_estimators=100;, score=(train=-0.017, test=-0.105) total time= 3.9min\n",
      "[CV 5/5] END max_features=0.25, min_samples_split=11, n_estimators=10;, score=(train=-0.031, test=-0.119) total time=  25.5s\n",
      "[CV 4/5] END max_features=0.25, min_samples_split=5, n_estimators=100;, score=(train=-0.017, test=-0.092) total time= 4.1min\n",
      "[CV 5/5] END max_features=0.25, min_samples_split=5, n_estimators=100;, score=(train=-0.018, test=-0.111) total time= 4.0min\n",
      "[CV 2/5] END max_features=0.25, min_samples_split=11, n_estimators=20;, score=(train=-0.027, test=-0.107) total time=  42.8s\n",
      "[CV 1/5] END max_features=0.25, min_samples_split=11, n_estimators=20;, score=(train=-0.026, test=-0.121) total time=  44.8s\n",
      "[CV 3/5] END max_features=0.25, min_samples_split=11, n_estimators=20;, score=(train=-0.027, test=-0.103) total time=  42.4s\n",
      "[CV 4/5] END max_features=0.25, min_samples_split=11, n_estimators=20;, score=(train=-0.028, test=-0.097) total time=  45.0s\n",
      "[CV 5/5] END max_features=0.25, min_samples_split=11, n_estimators=20;, score=(train=-0.027, test=-0.118) total time=  45.1s\n",
      "[CV 1/5] END max_features=0.25, min_samples_split=8, n_estimators=100;, score=(train=-0.020, test=-0.114) total time= 3.8min\n",
      "[CV 2/5] END max_features=0.25, min_samples_split=8, n_estimators=100;, score=(train=-0.021, test=-0.102) total time= 3.8min\n",
      "[CV 2/5] END max_features=0.25, min_samples_split=11, n_estimators=50;, score=(train=-0.025, test=-0.104) total time= 1.9min\n",
      "[CV 1/5] END max_features=0.25, min_samples_split=11, n_estimators=50;, score=(train=-0.024, test=-0.117) total time= 2.0min\n",
      "[CV 3/5] END max_features=0.25, min_samples_split=8, n_estimators=100;, score=(train=-0.021, test=-0.105) total time= 3.8min\n",
      "[CV 3/5] END max_features=0.25, min_samples_split=11, n_estimators=50;, score=(train=-0.025, test=-0.104) total time= 1.9min\n",
      "[CV 4/5] END max_features=0.25, min_samples_split=11, n_estimators=50;, score=(train=-0.025, test=-0.094) total time= 2.0min\n",
      "[CV 5/5] END max_features=0.25, min_samples_split=11, n_estimators=50;, score=(train=-0.025, test=-0.109) total time= 2.0min\n",
      "[CV 4/5] END max_features=0.25, min_samples_split=8, n_estimators=100;, score=(train=-0.022, test=-0.093) total time= 4.0min\n",
      "[CV 5/5] END max_features=0.25, min_samples_split=8, n_estimators=100;, score=(train=-0.021, test=-0.109) total time= 3.9min\n",
      "[CV 1/5] END max_features=0.5, min_samples_split=2, n_estimators=10;, score=(train=-0.023, test=-0.132) total time=  46.6s\n",
      "[CV 3/5] END max_features=0.5, min_samples_split=2, n_estimators=10;, score=(train=-0.022, test=-0.112) total time=  45.3s\n",
      "[CV 2/5] END max_features=0.5, min_samples_split=2, n_estimators=10;, score=(train=-0.025, test=-0.120) total time=  50.4s\n",
      "[CV 4/5] END max_features=0.5, min_samples_split=2, n_estimators=10;, score=(train=-0.023, test=-0.107) total time=  53.3s\n",
      "[CV 5/5] END max_features=0.5, min_samples_split=2, n_estimators=10;, score=(train=-0.023, test=-0.117) total time=  51.6s\n",
      "[CV 1/5] END max_features=0.5, min_samples_split=2, n_estimators=20;, score=(train=-0.018, test=-0.123) total time= 1.6min\n",
      "[CV 2/5] END max_features=0.5, min_samples_split=2, n_estimators=20;, score=(train=-0.019, test=-0.108) total time= 1.7min\n",
      "[CV 1/5] END max_features=0.25, min_samples_split=11, n_estimators=100;, score=(train=-0.023, test=-0.112) total time= 3.7min\n",
      "[CV 2/5] END max_features=0.25, min_samples_split=11, n_estimators=100;, score=(train=-0.024, test=-0.101) total time= 3.8min\n",
      "[CV 3/5] END max_features=0.5, min_samples_split=2, n_estimators=20;, score=(train=-0.019, test=-0.111) total time= 1.7min\n",
      "[CV 5/5] END max_features=0.5, min_samples_split=2, n_estimators=20;, score=(train=-0.018, test=-0.120) total time= 1.7min\n",
      "[CV 4/5] END max_features=0.5, min_samples_split=2, n_estimators=20;, score=(train=-0.018, test=-0.104) total time= 1.7min\n",
      "[CV 3/5] END max_features=0.25, min_samples_split=11, n_estimators=100;, score=(train=-0.024, test=-0.104) total time= 3.7min\n",
      "[CV 4/5] END max_features=0.25, min_samples_split=11, n_estimators=100;, score=(train=-0.024, test=-0.095) total time= 3.8min\n",
      "[CV 5/5] END max_features=0.25, min_samples_split=11, n_estimators=100;, score=(train=-0.023, test=-0.110) total time= 3.9min\n",
      "[CV 1/5] END max_features=0.5, min_samples_split=5, n_estimators=10;, score=(train=-0.025, test=-0.124) total time=  53.0s\n",
      "[CV 2/5] END max_features=0.5, min_samples_split=5, n_estimators=10;, score=(train=-0.026, test=-0.121) total time=  47.2s\n",
      "[CV 3/5] END max_features=0.5, min_samples_split=5, n_estimators=10;, score=(train=-0.026, test=-0.120) total time=  47.5s\n",
      "[CV 1/5] END max_features=0.5, min_samples_split=2, n_estimators=50;, score=(train=-0.016, test=-0.122) total time= 4.1min\n",
      "[CV 4/5] END max_features=0.5, min_samples_split=5, n_estimators=10;, score=(train=-0.026, test=-0.103) total time=  47.5s\n",
      "[CV 2/5] END max_features=0.5, min_samples_split=2, n_estimators=50;, score=(train=-0.016, test=-0.107) total time= 4.2min\n",
      "[CV 5/5] END max_features=0.5, min_samples_split=5, n_estimators=10;, score=(train=-0.024, test=-0.120) total time=  45.6s\n",
      "[CV 3/5] END max_features=0.5, min_samples_split=2, n_estimators=50;, score=(train=-0.016, test=-0.105) total time= 4.0min\n",
      "[CV 4/5] END max_features=0.5, min_samples_split=2, n_estimators=50;, score=(train=-0.016, test=-0.096) total time= 4.1min\n",
      "[CV 5/5] END max_features=0.5, min_samples_split=2, n_estimators=50;, score=(train=-0.015, test=-0.108) total time= 4.2min\n",
      "[CV 1/5] END max_features=0.5, min_samples_split=5, n_estimators=20;, score=(train=-0.020, test=-0.121) total time= 1.5min\n",
      "[CV 2/5] END max_features=0.5, min_samples_split=5, n_estimators=20;, score=(train=-0.021, test=-0.110) total time= 1.5min\n",
      "[CV 3/5] END max_features=0.5, min_samples_split=5, n_estimators=20;, score=(train=-0.021, test=-0.110) total time= 1.6min\n",
      "[CV 4/5] END max_features=0.5, min_samples_split=5, n_estimators=20;, score=(train=-0.021, test=-0.098) total time= 1.7min\n",
      "[CV 5/5] END max_features=0.5, min_samples_split=5, n_estimators=20;, score=(train=-0.020, test=-0.116) total time= 1.6min\n",
      "[CV 1/5] END max_features=0.5, min_samples_split=5, n_estimators=50;, score=(train=-0.018, test=-0.116) total time= 3.8min\n",
      "[CV 3/5] END max_features=0.5, min_samples_split=5, n_estimators=50;, score=(train=-0.019, test=-0.106) total time= 3.7min\n",
      "[CV 2/5] END max_features=0.5, min_samples_split=5, n_estimators=50;, score=(train=-0.019, test=-0.109) total time= 3.9min\n",
      "[CV 1/5] END max_features=0.5, min_samples_split=2, n_estimators=100;, score=(train=-0.015, test=-0.114) total time= 8.2min\n",
      "[CV 3/5] END max_features=0.5, min_samples_split=2, n_estimators=100;, score=(train=-0.016, test=-0.104) total time= 8.0min\n",
      "[CV 2/5] END max_features=0.5, min_samples_split=2, n_estimators=100;, score=(train=-0.015, test=-0.103) total time= 8.2min\n",
      "[CV 4/5] END max_features=0.5, min_samples_split=5, n_estimators=50;, score=(train=-0.019, test=-0.095) total time= 4.0min\n",
      "[CV 5/5] END max_features=0.5, min_samples_split=5, n_estimators=50;, score=(train=-0.019, test=-0.113) total time= 4.0min\n",
      "[CV 4/5] END max_features=0.5, min_samples_split=2, n_estimators=100;, score=(train=-0.016, test=-0.096) total time= 8.4min\n",
      "[CV 5/5] END max_features=0.5, min_samples_split=2, n_estimators=100;, score=(train=-0.015, test=-0.115) total time= 8.3min\n",
      "[CV 1/5] END max_features=0.5, min_samples_split=8, n_estimators=10;, score=(train=-0.027, test=-0.127) total time=  45.1s\n",
      "[CV 2/5] END max_features=0.5, min_samples_split=8, n_estimators=10;, score=(train=-0.029, test=-0.118) total time=  46.5s\n",
      "[CV 3/5] END max_features=0.5, min_samples_split=8, n_estimators=10;, score=(train=-0.028, test=-0.118) total time=  44.1s\n",
      "[CV 4/5] END max_features=0.5, min_samples_split=8, n_estimators=10;, score=(train=-0.028, test=-0.106) total time=  46.7s\n",
      "[CV 5/5] END max_features=0.5, min_samples_split=8, n_estimators=10;, score=(train=-0.029, test=-0.125) total time=  45.5s\n",
      "[CV 1/5] END max_features=0.5, min_samples_split=8, n_estimators=20;, score=(train=-0.024, test=-0.121) total time= 1.5min\n",
      "[CV 2/5] END max_features=0.5, min_samples_split=8, n_estimators=20;, score=(train=-0.025, test=-0.107) total time= 1.5min\n",
      "[CV 3/5] END max_features=0.5, min_samples_split=8, n_estimators=20;, score=(train=-0.024, test=-0.110) total time= 1.6min\n",
      "[CV 4/5] END max_features=0.5, min_samples_split=8, n_estimators=20;, score=(train=-0.025, test=-0.105) total time= 1.5min\n",
      "[CV 5/5] END max_features=0.5, min_samples_split=8, n_estimators=20;, score=(train=-0.023, test=-0.117) total time= 1.5min\n",
      "[CV 1/5] END max_features=0.5, min_samples_split=5, n_estimators=100;, score=(train=-0.017, test=-0.115) total time= 7.7min\n",
      "[CV 2/5] END max_features=0.5, min_samples_split=8, n_estimators=50;, score=(train=-0.022, test=-0.104) total time= 3.7min\n",
      "[CV 1/5] END max_features=0.5, min_samples_split=8, n_estimators=50;, score=(train=-0.021, test=-0.116) total time= 3.8min\n",
      "[CV 2/5] END max_features=0.5, min_samples_split=5, n_estimators=100;, score=(train=-0.017, test=-0.108) total time= 7.7min\n",
      "[CV 3/5] END max_features=0.5, min_samples_split=8, n_estimators=50;, score=(train=-0.022, test=-0.108) total time= 3.7min\n",
      "[CV 1/5] END max_features=0.5, min_samples_split=11, n_estimators=10;, score=(train=-0.031, test=-0.125) total time=  44.7s\n",
      "[CV 4/5] END max_features=0.5, min_samples_split=8, n_estimators=50;, score=(train=-0.022, test=-0.099) total time= 3.9min\n",
      "[CV 3/5] END max_features=0.5, min_samples_split=11, n_estimators=10;, score=(train=-0.032, test=-0.116) total time=  42.4s\n",
      "[CV 2/5] END max_features=0.5, min_samples_split=11, n_estimators=10;, score=(train=-0.032, test=-0.116) total time=  44.4s\n",
      "[CV 5/5] END max_features=0.5, min_samples_split=8, n_estimators=50;, score=(train=-0.021, test=-0.115) total time= 4.0min\n",
      "[CV 4/5] END max_features=0.5, min_samples_split=11, n_estimators=10;, score=(train=-0.032, test=-0.106) total time=  42.0s\n",
      "[CV 5/5] END max_features=0.5, min_samples_split=11, n_estimators=10;, score=(train=-0.033, test=-0.128) total time=  45.5s\n",
      "[CV 3/5] END max_features=0.5, min_samples_split=5, n_estimators=100;, score=(train=-0.017, test=-0.106) total time= 7.6min\n",
      "[CV 5/5] END max_features=0.5, min_samples_split=5, n_estimators=100;, score=(train=-0.018, test=-0.111) total time= 7.8min\n",
      "[CV 4/5] END max_features=0.5, min_samples_split=5, n_estimators=100;, score=(train=-0.018, test=-0.096) total time= 7.9min\n",
      "[CV 2/5] END max_features=0.5, min_samples_split=11, n_estimators=20;, score=(train=-0.028, test=-0.114) total time= 1.5min\n",
      "[CV 1/5] END max_features=0.5, min_samples_split=11, n_estimators=20;, score=(train=-0.026, test=-0.122) total time= 1.6min\n",
      "[CV 3/5] END max_features=0.5, min_samples_split=11, n_estimators=20;, score=(train=-0.028, test=-0.110) total time= 1.5min\n",
      "[CV 4/5] END max_features=0.5, min_samples_split=11, n_estimators=20;, score=(train=-0.027, test=-0.101) total time= 1.6min\n",
      "[CV 5/5] END max_features=0.5, min_samples_split=11, n_estimators=20;, score=(train=-0.029, test=-0.117) total time= 1.5min\n",
      "[CV 1/5] END max_features=0.5, min_samples_split=8, n_estimators=100;, score=(train=-0.020, test=-0.116) total time= 7.6min\n",
      "[CV 2/5] END max_features=0.5, min_samples_split=8, n_estimators=100;, score=(train=-0.021, test=-0.104) total time= 7.5min\n",
      "[CV 2/5] END max_features=0.5, min_samples_split=11, n_estimators=50;, score=(train=-0.025, test=-0.105) total time= 3.7min\n",
      "[CV 1/5] END max_features=0.5, min_samples_split=11, n_estimators=50;, score=(train=-0.024, test=-0.115) total time= 3.9min\n",
      "[CV 3/5] END max_features=0.5, min_samples_split=8, n_estimators=100;, score=(train=-0.021, test=-0.106) total time= 7.5min\n",
      "[CV 3/5] END max_features=0.5, min_samples_split=11, n_estimators=50;, score=(train=-0.025, test=-0.109) total time= 3.8min\n",
      "[CV 4/5] END max_features=0.5, min_samples_split=11, n_estimators=50;, score=(train=-0.025, test=-0.095) total time= 4.0min\n",
      "[CV 5/5] END max_features=0.5, min_samples_split=11, n_estimators=50;, score=(train=-0.025, test=-0.113) total time= 4.0min\n",
      "[CV 4/5] END max_features=0.5, min_samples_split=8, n_estimators=100;, score=(train=-0.021, test=-0.093) total time= 7.7min\n",
      "[CV 5/5] END max_features=0.5, min_samples_split=8, n_estimators=100;, score=(train=-0.021, test=-0.112) total time= 7.6min\n",
      "[CV 2/5] END max_features=0.5, min_samples_split=11, n_estimators=100;, score=(train=-0.024, test=-0.106) total time= 6.6min\n",
      "[CV 1/5] END max_features=0.5, min_samples_split=11, n_estimators=100;, score=(train=-0.023, test=-0.116) total time= 6.6min\n",
      "[CV 3/5] END max_features=0.5, min_samples_split=11, n_estimators=100;, score=(train=-0.024, test=-0.105) total time= 6.4min\n",
      "[CV 4/5] END max_features=0.5, min_samples_split=11, n_estimators=100;, score=(train=-0.024, test=-0.095) total time= 6.3min\n",
      "[CV 5/5] END max_features=0.5, min_samples_split=11, n_estimators=100;, score=(train=-0.024, test=-0.113) total time= 6.1min\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;max_features&#x27;: [&#x27;sqrt&#x27;, 0.1, 0.25, 0.5],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 8, 11],\n",
       "                         &#x27;n_estimators&#x27;: [10, 20, 50, 100]},\n",
       "             return_train_score=True, scoring=&#x27;neg_mean_squared_error&#x27;,\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;max_features&#x27;: [&#x27;sqrt&#x27;, 0.1, 0.25, 0.5],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 8, 11],\n",
       "                         &#x27;n_estimators&#x27;: [10, 20, 50, 100]},\n",
       "             return_train_score=True, scoring=&#x27;neg_mean_squared_error&#x27;,\n",
       "             verbose=3)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: RandomForestRegressor</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(max_features=0.25)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(max_features=0.25)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={'max_features': ['sqrt', 0.1, 0.25, 0.5],\n",
       "                         'min_samples_split': [2, 5, 8, 11],\n",
       "                         'n_estimators': [10, 20, 50, 100]},\n",
       "             return_train_score=True, scoring='neg_mean_squared_error',\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "hyperparameters_to_test = {\n",
    "    \"n_estimators\": [10, 20, 50, 100],\n",
    "    \"max_features\": [\"sqrt\", 0.1, 0.25, 0.5],\n",
    "    \"min_samples_split\": [2, 5, 8, 11]\n",
    "}\n",
    "\n",
    "random_forest = RandomForestRegressor()\n",
    "\n",
    "grid_search_rf = GridSearchCV(\n",
    "    estimator=random_forest,\n",
    "    param_grid=hyperparameters_to_test,\n",
    "    cv=kfold,\n",
    "    return_train_score=True,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    n_jobs=-1,\n",
    "    verbose=3,\n",
    ")\n",
    "\n",
    "grid_search_rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters of the best model obtained: {'max_features': 0.25, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Mean train error of the best model obtained: 0.014674299703050528\n",
      "Mean validation error of the best model obtained: 0.10407019944693947\n"
     ]
    }
   ],
   "source": [
    "print(f\"Hyperparameters of the best model obtained: {grid_search_rf.best_params_}\")\n",
    "\n",
    "cv_results_rf = grid_search_rf.cv_results_\n",
    "best_index_rf = grid_search_rf.best_index_\n",
    "\n",
    "train_err_rf = -cv_results_rf[\"mean_train_score\"][best_index_rf]\n",
    "val_err_rf = -cv_results_rf[\"mean_test_score\"][best_index_rf]\n",
    "\n",
    "print(f\"Mean train error of the best model obtained: {train_err_rf}\")\n",
    "print(f\"Mean validation error of the best model obtained: {val_err_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's summarize the above results in a tabular form. For the reference let's use a simple model, which assigns the arithmetic mean of the dependent variable to any independent variable values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................., score=(train=-0.740, test=-0.743) total time=   0.1s\n",
      "[CV] END ................., score=(train=-0.739, test=-0.750) total time=   0.1s\n",
      "[CV] END ................., score=(train=-0.731, test=-0.779) total time=   0.1s\n",
      "[CV] END ................., score=(train=-0.746, test=-0.720) total time=   0.1s\n",
      "[CV] END ................., score=(train=-0.748, test=-0.713) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    1.0s remaining:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean train error of the best model obtained: 0.7408770638799047\n",
      "Mean validation error of the best model obtained: 0.7408793416328249\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "class ReferenceRegressor(RegressorMixin, BaseEstimator):\n",
    "    def __init__(self, mean):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mean = mean\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.full(X.shape[0], self.mean)\n",
    "\n",
    "\n",
    "reference_model = ReferenceRegressor(y.mean())\n",
    "\n",
    "cv_results_ref = cross_validate(\n",
    "    reference_model,\n",
    "    X,\n",
    "    y,\n",
    "    cv=kfold,\n",
    "    return_train_score=True,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    n_jobs=-1,\n",
    "    verbose=3,\n",
    ")\n",
    "\n",
    "train_err_ref = -cv_results_ref[\"train_score\"].mean()\n",
    "val_err_ref = -cv_results_ref[\"test_score\"].mean()\n",
    "\n",
    "print()\n",
    "print(f\"Mean train error of the best model obtained: {train_err_ref}\")\n",
    "print(f\"Mean validation error of the best model obtained: {val_err_ref}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Error</th>\n",
       "      <th>Validation Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ElasticNet</th>\n",
       "      <td>0.100112</td>\n",
       "      <td>0.116209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.014674</td>\n",
       "      <td>0.104070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reference Model</th>\n",
       "      <td>0.740877</td>\n",
       "      <td>0.740879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Train Error  Validation Error\n",
       "ElasticNet          0.100112          0.116209\n",
       "Random Forest       0.014674          0.104070\n",
       "Reference Model     0.740877          0.740879"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(\n",
    "    index=[\"ElasticNet\", \"Random Forest\", \"Reference Model\"],\n",
    "    columns=[\"Train Error\", \"Validation Error\"],\n",
    ")\n",
    "\n",
    "results[\"Train Error\"] = [train_err_en, train_err_rf, train_err_ref]\n",
    "results[\"Validation Error\"] = [val_err_en, val_err_rf, val_err_ref]\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously both tested models work much better than the simple reference model.\n",
    "\n",
    "We can observe significantly lower validation error for the Random Forest than for the ElasticNet, not to mention the train error, where the difference is huge. It's a predictable result, as the Random Forest model is more sophisticated than the ElasticNet and we dedicated (as we needed to) more compute time to the grid search in its case.\n",
    "\n",
    "To answer the question \"Which model is the best?\" we need to ask ourselves what are our priorities. If it's a predictive power, then we should go for the Random Forest. However if we've got a restricted budget and/or resources, it may be a better idea to train the ElasticNet as the results are also great and it's a less resource-heavy model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on a test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the final part of the project we'd like to create a model that minimizes error on the test set.\n",
    "\n",
    "As the number of features in the dataset is enormous and many of them, as we concluded in the first part, aren't significantly correlated with the dependent variable, we'll first focus on reducing the dataset, i.e. feature selection and dimension reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I have _some_ experience with training ML models, I managed to get to know some techniques. One of them, which at first made a huge impression on me, is a Boruta algorithm. It's an all relevant feature selection method, and even though it's just a pretty simple heuristic, it previously gave me outstanding results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Boruta in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from Boruta) (2.2.1)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from Boruta) (1.6.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from Boruta) (1.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from scikit-learn>=0.17.1->Boruta) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from scikit-learn>=0.17.1->Boruta) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X = pd.read_csv(\"X_train.csv\")\n",
    "y = pd.read_csv(\"y_train.csv\")[\"Expected\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t1 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t9000\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t9000\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t9000\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t9000\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t9000\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t9000\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t9000\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 100\n",
      "Confirmed: \t864\n",
      "Tentative: \t990\n",
      "Rejected: \t7146\n",
      "Iteration: \t9 / 100\n",
      "Confirmed: \t864\n",
      "Tentative: \t990\n",
      "Rejected: \t7146\n",
      "Iteration: \t10 / 100\n",
      "Confirmed: \t864\n",
      "Tentative: \t990\n",
      "Rejected: \t7146\n",
      "Iteration: \t11 / 100\n",
      "Confirmed: \t864\n",
      "Tentative: \t990\n",
      "Rejected: \t7146\n",
      "Iteration: \t12 / 100\n",
      "Confirmed: \t868\n",
      "Tentative: \t683\n",
      "Rejected: \t7449\n",
      "Iteration: \t13 / 100\n",
      "Confirmed: \t868\n",
      "Tentative: \t683\n",
      "Rejected: \t7449\n",
      "Iteration: \t14 / 100\n",
      "Confirmed: \t868\n",
      "Tentative: \t683\n",
      "Rejected: \t7449\n",
      "Iteration: \t15 / 100\n",
      "Confirmed: \t868\n",
      "Tentative: \t683\n",
      "Rejected: \t7449\n",
      "Iteration: \t16 / 100\n",
      "Confirmed: \t870\n",
      "Tentative: \t512\n",
      "Rejected: \t7618\n",
      "Iteration: \t17 / 100\n",
      "Confirmed: \t870\n",
      "Tentative: \t512\n",
      "Rejected: \t7618\n",
      "Iteration: \t18 / 100\n",
      "Confirmed: \t870\n",
      "Tentative: \t512\n",
      "Rejected: \t7618\n",
      "Iteration: \t19 / 100\n",
      "Confirmed: \t871\n",
      "Tentative: \t416\n",
      "Rejected: \t7713\n",
      "Iteration: \t20 / 100\n",
      "Confirmed: \t871\n",
      "Tentative: \t416\n",
      "Rejected: \t7713\n",
      "Iteration: \t21 / 100\n",
      "Confirmed: \t871\n",
      "Tentative: \t416\n",
      "Rejected: \t7713\n",
      "Iteration: \t22 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t323\n",
      "Rejected: \t7805\n",
      "Iteration: \t23 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t323\n",
      "Rejected: \t7805\n",
      "Iteration: \t24 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t323\n",
      "Rejected: \t7805\n",
      "Iteration: \t25 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t323\n",
      "Rejected: \t7805\n",
      "Iteration: \t26 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t261\n",
      "Rejected: \t7867\n",
      "Iteration: \t27 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t261\n",
      "Rejected: \t7867\n",
      "Iteration: \t28 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t261\n",
      "Rejected: \t7867\n",
      "Iteration: \t29 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t204\n",
      "Rejected: \t7924\n",
      "Iteration: \t30 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t204\n",
      "Rejected: \t7924\n",
      "Iteration: \t31 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t204\n",
      "Rejected: \t7924\n",
      "Iteration: \t32 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t147\n",
      "Rejected: \t7981\n",
      "Iteration: \t33 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t147\n",
      "Rejected: \t7981\n",
      "Iteration: \t34 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t108\n",
      "Rejected: \t8020\n",
      "Iteration: \t35 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t108\n",
      "Rejected: \t8020\n",
      "Iteration: \t36 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t108\n",
      "Rejected: \t8020\n",
      "Iteration: \t37 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t86\n",
      "Rejected: \t8042\n",
      "Iteration: \t38 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t86\n",
      "Rejected: \t8042\n",
      "Iteration: \t39 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t86\n",
      "Rejected: \t8042\n",
      "Iteration: \t40 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t73\n",
      "Rejected: \t8055\n",
      "Iteration: \t41 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t73\n",
      "Rejected: \t8055\n",
      "Iteration: \t42 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t73\n",
      "Rejected: \t8055\n",
      "Iteration: \t43 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t59\n",
      "Rejected: \t8069\n",
      "Iteration: \t44 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t59\n",
      "Rejected: \t8069\n",
      "Iteration: \t45 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t59\n",
      "Rejected: \t8069\n",
      "Iteration: \t46 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t50\n",
      "Rejected: \t8078\n",
      "Iteration: \t47 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t50\n",
      "Rejected: \t8078\n",
      "Iteration: \t48 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t50\n",
      "Rejected: \t8078\n",
      "Iteration: \t49 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t43\n",
      "Rejected: \t8085\n",
      "Iteration: \t50 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t43\n",
      "Rejected: \t8085\n",
      "Iteration: \t51 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t36\n",
      "Rejected: \t8092\n",
      "Iteration: \t52 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t36\n",
      "Rejected: \t8092\n",
      "Iteration: \t53 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t36\n",
      "Rejected: \t8092\n",
      "Iteration: \t54 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t34\n",
      "Rejected: \t8094\n",
      "Iteration: \t55 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t34\n",
      "Rejected: \t8094\n",
      "Iteration: \t56 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t34\n",
      "Rejected: \t8094\n",
      "Iteration: \t57 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t32\n",
      "Rejected: \t8096\n",
      "Iteration: \t58 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t32\n",
      "Rejected: \t8096\n",
      "Iteration: \t59 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t29\n",
      "Rejected: \t8099\n",
      "Iteration: \t60 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t29\n",
      "Rejected: \t8099\n",
      "Iteration: \t61 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t29\n",
      "Rejected: \t8099\n",
      "Iteration: \t62 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t28\n",
      "Rejected: \t8100\n",
      "Iteration: \t63 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t28\n",
      "Rejected: \t8100\n",
      "Iteration: \t64 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t28\n",
      "Rejected: \t8100\n",
      "Iteration: \t65 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t28\n",
      "Rejected: \t8100\n",
      "Iteration: \t66 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t28\n",
      "Rejected: \t8100\n",
      "Iteration: \t67 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t28\n",
      "Rejected: \t8100\n",
      "Iteration: \t68 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t28\n",
      "Rejected: \t8100\n",
      "Iteration: \t69 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t28\n",
      "Rejected: \t8100\n",
      "Iteration: \t70 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t27\n",
      "Rejected: \t8101\n",
      "Iteration: \t71 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t27\n",
      "Rejected: \t8101\n",
      "Iteration: \t72 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t25\n",
      "Rejected: \t8103\n",
      "Iteration: \t73 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t25\n",
      "Rejected: \t8103\n",
      "Iteration: \t74 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t25\n",
      "Rejected: \t8103\n",
      "Iteration: \t75 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t24\n",
      "Rejected: \t8104\n",
      "Iteration: \t76 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t24\n",
      "Rejected: \t8104\n",
      "Iteration: \t77 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t20\n",
      "Rejected: \t8108\n",
      "Iteration: \t78 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t20\n",
      "Rejected: \t8108\n",
      "Iteration: \t79 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t20\n",
      "Rejected: \t8108\n",
      "Iteration: \t80 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t20\n",
      "Rejected: \t8108\n",
      "Iteration: \t81 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t20\n",
      "Rejected: \t8108\n",
      "Iteration: \t82 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t20\n",
      "Rejected: \t8108\n",
      "Iteration: \t83 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t20\n",
      "Rejected: \t8108\n",
      "Iteration: \t84 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t20\n",
      "Rejected: \t8108\n",
      "Iteration: \t85 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t20\n",
      "Rejected: \t8108\n",
      "Iteration: \t86 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t20\n",
      "Rejected: \t8108\n",
      "Iteration: \t87 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t20\n",
      "Rejected: \t8108\n",
      "Iteration: \t88 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t20\n",
      "Rejected: \t8108\n",
      "Iteration: \t89 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t20\n",
      "Rejected: \t8108\n",
      "Iteration: \t90 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t20\n",
      "Rejected: \t8108\n",
      "Iteration: \t91 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t20\n",
      "Rejected: \t8108\n",
      "Iteration: \t92 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t20\n",
      "Rejected: \t8108\n",
      "Iteration: \t93 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t19\n",
      "Rejected: \t8109\n",
      "Iteration: \t94 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t19\n",
      "Rejected: \t8109\n",
      "Iteration: \t95 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t19\n",
      "Rejected: \t8109\n",
      "Iteration: \t96 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t19\n",
      "Rejected: \t8109\n",
      "Iteration: \t97 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t19\n",
      "Rejected: \t8109\n",
      "Iteration: \t98 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t19\n",
      "Rejected: \t8109\n",
      "Iteration: \t99 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t19\n",
      "Rejected: \t8109\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t100 / 100\n",
      "Confirmed: \t872\n",
      "Tentative: \t7\n",
      "Rejected: \t8121\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BorutaPy(estimator=RandomForestRegressor(max_depth=5, max_features=&#x27;sqrt&#x27;,\n",
       "                                         n_estimators=844, n_jobs=-1,\n",
       "                                         random_state=RandomState(MT19937) at 0x7E7F6103C740),\n",
       "         n_estimators=&#x27;auto&#x27;,\n",
       "         random_state=RandomState(MT19937) at 0x7E7F6103C740, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;BorutaPy<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>BorutaPy(estimator=RandomForestRegressor(max_depth=5, max_features=&#x27;sqrt&#x27;,\n",
       "                                         n_estimators=844, n_jobs=-1,\n",
       "                                         random_state=RandomState(MT19937) at 0x7E7F6103C740),\n",
       "         n_estimators=&#x27;auto&#x27;,\n",
       "         random_state=RandomState(MT19937) at 0x7E7F6103C740, verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(max_depth=5, max_features=&#x27;sqrt&#x27;, n_estimators=844,\n",
       "                      n_jobs=-1,\n",
       "                      random_state=RandomState(MT19937) at 0x7E7F6103C740)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(max_depth=5, max_features=&#x27;sqrt&#x27;, n_estimators=844,\n",
       "                      n_jobs=-1,\n",
       "                      random_state=RandomState(MT19937) at 0x7E7F6103C740)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BorutaPy(estimator=RandomForestRegressor(max_depth=5, max_features='sqrt',\n",
       "                                         n_estimators=844, n_jobs=-1,\n",
       "                                         random_state=RandomState(MT19937) at 0x7E7F6103C740),\n",
       "         n_estimators='auto',\n",
       "         random_state=RandomState(MT19937) at 0x7E7F6103C740, verbose=2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from boruta import BorutaPy\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "\n",
    "boruta = BorutaPy(\n",
    "    RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=5,\n",
    "        max_features=\"sqrt\",\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1,\n",
    "    ),\n",
    "    n_estimators=\"auto\",\n",
    "    verbose=2,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "boruta.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3794, 872)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sel = boruta.transform(X.values)\n",
    "X_sel.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, after we significantly reduced number of features, let's use another method to shrink our dataset and extract only the most important parts from it - the PCA dimension reduction algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=0.44) # I did a GridSearch over many values and thus concluded that 0.44 or 0.47 seem to work the best, however this isn't present in the final version of the notebook\n",
    "\n",
    "X_final = pca.fit_transform(scaler.fit_transform(X_sel, y), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test our preprocessing on the RF regressor using a GridSearch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 360 candidates, totalling 1800 fits\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=(train=-0.198, test=-0.312) total time=  46.7s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=(train=-0.195, test=-0.332) total time=  46.9s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=(train=-0.197, test=-0.306) total time=  47.4s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=(train=-0.198, test=-0.293) total time=  48.8s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=(train=-0.197, test=-0.315) total time=  49.9s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=(train=-0.198, test=-0.305) total time=  57.1s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=(train=-0.196, test=-0.315) total time=  57.6s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=(train=-0.195, test=-0.332) total time=  58.4s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=(train=-0.197, test=-0.311) total time= 1.0min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=(train=-0.198, test=-0.292) total time= 1.0min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=1400;, score=(train=-0.195, test=-0.333) total time= 1.1min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=1400;, score=(train=-0.197, test=-0.312) total time= 1.2min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=1400;, score=(train=-0.196, test=-0.315) total time= 1.1min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=1400;, score=(train=-0.197, test=-0.292) total time= 1.1min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=1400;, score=(train=-0.197, test=-0.306) total time= 1.1min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=1600;, score=(train=-0.197, test=-0.312) total time= 1.3min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=1600;, score=(train=-0.195, test=-0.332) total time= 1.3min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=1600;, score=(train=-0.197, test=-0.315) total time= 1.3min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=1600;, score=(train=-0.198, test=-0.306) total time= 1.3min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=1600;, score=(train=-0.198, test=-0.293) total time= 1.4min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=1800;, score=(train=-0.198, test=-0.312) total time= 1.5min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=1800;, score=(train=-0.195, test=-0.332) total time= 1.5min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=1800;, score=(train=-0.196, test=-0.315) total time= 1.5min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=1800;, score=(train=-0.198, test=-0.294) total time= 1.5min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=1000;, score=(train=-0.201, test=-0.334) total time=  45.7s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=1000;, score=(train=-0.202, test=-0.312) total time=  48.7s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=1000;, score=(train=-0.202, test=-0.316) total time=  46.4s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=1000;, score=(train=-0.204, test=-0.293) total time=  46.6s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=1800;, score=(train=-0.197, test=-0.306) total time= 1.5min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=1000;, score=(train=-0.203, test=-0.306) total time=  49.3s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=2000;, score=(train=-0.196, test=-0.333) total time= 1.6min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=2000;, score=(train=-0.198, test=-0.312) total time= 1.6min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=1200;, score=(train=-0.200, test=-0.333) total time=  58.6s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=2000;, score=(train=-0.196, test=-0.315) total time= 1.6min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=2000;, score=(train=-0.198, test=-0.293) total time= 1.7min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=2000;, score=(train=-0.197, test=-0.306) total time= 1.6min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=1200;, score=(train=-0.203, test=-0.312) total time=  58.4s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=1200;, score=(train=-0.202, test=-0.316) total time= 1.0min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=1200;, score=(train=-0.203, test=-0.307) total time=  56.7s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=1200;, score=(train=-0.204, test=-0.293) total time=  58.3s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=1400;, score=(train=-0.200, test=-0.333) total time= 1.1min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=1400;, score=(train=-0.202, test=-0.316) total time= 1.1min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=1400;, score=(train=-0.203, test=-0.311) total time= 1.1min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=1400;, score=(train=-0.204, test=-0.292) total time= 1.2min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=1400;, score=(train=-0.204, test=-0.306) total time= 1.1min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=1600;, score=(train=-0.200, test=-0.332) total time= 1.3min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=1600;, score=(train=-0.203, test=-0.312) total time= 1.3min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=1600;, score=(train=-0.202, test=-0.315) total time= 1.3min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=1600;, score=(train=-0.204, test=-0.293) total time= 1.3min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=1600;, score=(train=-0.203, test=-0.307) total time= 1.3min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=1800;, score=(train=-0.200, test=-0.333) total time= 1.4min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=1800;, score=(train=-0.203, test=-0.312) total time= 1.4min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=1800;, score=(train=-0.202, test=-0.315) total time= 1.4min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=1800;, score=(train=-0.204, test=-0.293) total time= 1.4min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=1800;, score=(train=-0.203, test=-0.306) total time= 1.5min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=8, n_estimators=1000;, score=(train=-0.208, test=-0.332) total time=  47.1s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=2000;, score=(train=-0.201, test=-0.333) total time= 1.6min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=8, n_estimators=1000;, score=(train=-0.210, test=-0.312) total time=  49.4s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=2000;, score=(train=-0.203, test=-0.311) total time= 1.6min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=8, n_estimators=1000;, score=(train=-0.212, test=-0.293) total time=  45.5s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=8, n_estimators=1000;, score=(train=-0.209, test=-0.316) total time=  46.4s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=2000;, score=(train=-0.202, test=-0.315) total time= 1.6min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=8, n_estimators=1000;, score=(train=-0.211, test=-0.306) total time=  47.3s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=2000;, score=(train=-0.203, test=-0.306) total time= 1.6min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=2000;, score=(train=-0.203, test=-0.292) total time= 1.6min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=8, n_estimators=1200;, score=(train=-0.208, test=-0.333) total time=  55.6s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=8, n_estimators=1200;, score=(train=-0.210, test=-0.312) total time=  59.2s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=8, n_estimators=1200;, score=(train=-0.210, test=-0.317) total time=  56.7s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=8, n_estimators=1200;, score=(train=-0.212, test=-0.293) total time=  55.1s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=8, n_estimators=1200;, score=(train=-0.211, test=-0.306) total time=  55.4s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=8, n_estimators=1400;, score=(train=-0.208, test=-0.333) total time= 1.1min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=8, n_estimators=1400;, score=(train=-0.211, test=-0.312) total time= 1.1min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=8, n_estimators=1400;, score=(train=-0.209, test=-0.316) total time= 1.1min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=8, n_estimators=1400;, score=(train=-0.212, test=-0.293) total time= 1.1min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=8, n_estimators=1400;, score=(train=-0.210, test=-0.307) total time= 1.1min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=8, n_estimators=1600;, score=(train=-0.208, test=-0.333) total time= 1.3min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=8, n_estimators=1600;, score=(train=-0.210, test=-0.311) total time= 1.3min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=8, n_estimators=1600;, score=(train=-0.210, test=-0.316) total time= 1.2min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=8, n_estimators=1600;, score=(train=-0.212, test=-0.293) total time= 1.3min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=8, n_estimators=1600;, score=(train=-0.210, test=-0.306) total time= 1.3min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=8, n_estimators=1800;, score=(train=-0.207, test=-0.332) total time= 1.4min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=8, n_estimators=1800;, score=(train=-0.210, test=-0.311) total time= 1.4min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=8, n_estimators=1800;, score=(train=-0.210, test=-0.316) total time= 1.4min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=8, n_estimators=1800;, score=(train=-0.211, test=-0.292) total time= 1.4min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=8, n_estimators=1800;, score=(train=-0.211, test=-0.307) total time= 1.4min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=11, n_estimators=1000;, score=(train=-0.215, test=-0.333) total time=  45.2s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=11, n_estimators=1000;, score=(train=-0.218, test=-0.312) total time=  46.5s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=8, n_estimators=2000;, score=(train=-0.207, test=-0.332) total time= 1.6min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=11, n_estimators=1000;, score=(train=-0.217, test=-0.317) total time=  46.2s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=8, n_estimators=2000;, score=(train=-0.210, test=-0.312) total time= 1.6min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=11, n_estimators=1000;, score=(train=-0.220, test=-0.294) total time=  46.7s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=8, n_estimators=2000;, score=(train=-0.209, test=-0.316) total time= 1.6min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=8, n_estimators=2000;, score=(train=-0.212, test=-0.293) total time= 1.6min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=11, n_estimators=1000;, score=(train=-0.218, test=-0.307) total time=  47.7s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=8, n_estimators=2000;, score=(train=-0.211, test=-0.307) total time= 1.6min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=11, n_estimators=1200;, score=(train=-0.216, test=-0.333) total time=  57.1s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=11, n_estimators=1200;, score=(train=-0.218, test=-0.312) total time=  55.6s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=11, n_estimators=1200;, score=(train=-0.217, test=-0.316) total time=  56.2s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=11, n_estimators=1200;, score=(train=-0.219, test=-0.293) total time=  54.4s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=11, n_estimators=1200;, score=(train=-0.218, test=-0.307) total time=  56.2s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=11, n_estimators=1400;, score=(train=-0.215, test=-0.333) total time= 1.1min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=11, n_estimators=1400;, score=(train=-0.217, test=-0.316) total time= 1.1min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=11, n_estimators=1400;, score=(train=-0.218, test=-0.312) total time= 1.1min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=11, n_estimators=1400;, score=(train=-0.219, test=-0.294) total time= 1.1min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=11, n_estimators=1400;, score=(train=-0.218, test=-0.307) total time= 1.1min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=11, n_estimators=1600;, score=(train=-0.215, test=-0.334) total time= 1.3min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=11, n_estimators=1600;, score=(train=-0.218, test=-0.311) total time= 1.3min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=11, n_estimators=1600;, score=(train=-0.217, test=-0.317) total time= 1.3min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=11, n_estimators=1600;, score=(train=-0.220, test=-0.293) total time= 1.3min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=11, n_estimators=1600;, score=(train=-0.218, test=-0.306) total time= 1.3min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=11, n_estimators=1800;, score=(train=-0.215, test=-0.333) total time= 1.4min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=11, n_estimators=1800;, score=(train=-0.218, test=-0.312) total time= 1.4min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=11, n_estimators=1800;, score=(train=-0.218, test=-0.316) total time= 1.4min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=11, n_estimators=1800;, score=(train=-0.219, test=-0.293) total time= 1.4min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=11, n_estimators=1800;, score=(train=-0.218, test=-0.307) total time= 1.5min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=3, min_samples_split=2, n_estimators=1000;, score=(train=-0.206, test=-0.333) total time=  46.2s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=3, min_samples_split=2, n_estimators=1000;, score=(train=-0.209, test=-0.311) total time=  46.8s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=11, n_estimators=2000;, score=(train=-0.215, test=-0.333) total time= 1.6min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=3, min_samples_split=2, n_estimators=1000;, score=(train=-0.208, test=-0.314) total time=  49.0s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=3, min_samples_split=2, n_estimators=1000;, score=(train=-0.210, test=-0.292) total time=  45.7s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=11, n_estimators=2000;, score=(train=-0.217, test=-0.312) total time= 1.5min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=11, n_estimators=2000;, score=(train=-0.219, test=-0.293) total time= 1.5min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=3, min_samples_split=2, n_estimators=1000;, score=(train=-0.210, test=-0.306) total time=  45.7s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=11, n_estimators=2000;, score=(train=-0.218, test=-0.316) total time= 1.6min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=11, n_estimators=2000;, score=(train=-0.218, test=-0.307) total time= 1.5min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=3, min_samples_split=2, n_estimators=1200;, score=(train=-0.206, test=-0.332) total time=  54.3s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=3, min_samples_split=2, n_estimators=1200;, score=(train=-0.209, test=-0.311) total time=  55.5s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=3, min_samples_split=2, n_estimators=1200;, score=(train=-0.208, test=-0.314) total time=  56.5s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=3, min_samples_split=2, n_estimators=1200;, score=(train=-0.210, test=-0.293) total time=  54.3s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=3, min_samples_split=2, n_estimators=1200;, score=(train=-0.210, test=-0.307) total time=  54.0s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=3, min_samples_split=2, n_estimators=1400;, score=(train=-0.206, test=-0.332) total time= 1.0min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=3, min_samples_split=2, n_estimators=1400;, score=(train=-0.210, test=-0.311) total time= 1.0min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=3, min_samples_split=2, n_estimators=1400;, score=(train=-0.209, test=-0.314) total time= 1.0min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=3, min_samples_split=2, n_estimators=1400;, score=(train=-0.211, test=-0.293) total time= 1.0min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=3, min_samples_split=2, n_estimators=1400;, score=(train=-0.209, test=-0.306) total time= 1.0min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=3, min_samples_split=2, n_estimators=1600;, score=(train=-0.206, test=-0.332) total time= 1.2min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=3, min_samples_split=2, n_estimators=1600;, score=(train=-0.209, test=-0.311) total time= 1.2min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=3, min_samples_split=2, n_estimators=1600;, score=(train=-0.209, test=-0.314) total time= 1.2min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=3, min_samples_split=2, n_estimators=1600;, score=(train=-0.211, test=-0.292) total time= 1.2min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=3, min_samples_split=2, n_estimators=1600;, score=(train=-0.209, test=-0.307) total time= 1.2min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=3, min_samples_split=2, n_estimators=1800;, score=(train=-0.206, test=-0.332) total time= 1.3min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=3, min_samples_split=2, n_estimators=1800;, score=(train=-0.210, test=-0.311) total time= 1.3min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=3, min_samples_split=2, n_estimators=1800;, score=(train=-0.211, test=-0.293) total time= 1.3min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=3, min_samples_split=2, n_estimators=1800;, score=(train=-0.208, test=-0.314) total time= 1.3min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=3, min_samples_split=2, n_estimators=1800;, score=(train=-0.209, test=-0.306) total time= 1.4min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=3, min_samples_split=5, n_estimators=1000;, score=(train=-0.207, test=-0.332) total time=  44.3s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=3, min_samples_split=5, n_estimators=1000;, score=(train=-0.209, test=-0.311) total time=  44.5s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=3, min_samples_split=5, n_estimators=1000;, score=(train=-0.208, test=-0.313) total time=  44.7s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=3, min_samples_split=2, n_estimators=2000;, score=(train=-0.206, test=-0.332) total time= 1.5min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=3, min_samples_split=2, n_estimators=2000;, score=(train=-0.210, test=-0.311) total time= 1.5min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=3, min_samples_split=5, n_estimators=1000;, score=(train=-0.211, test=-0.293) total time=  44.0s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=3, min_samples_split=2, n_estimators=2000;, score=(train=-0.209, test=-0.314) total time= 1.5min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=3, min_samples_split=2, n_estimators=2000;, score=(train=-0.211, test=-0.294) total time= 1.5min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=3, min_samples_split=5, n_estimators=1000;, score=(train=-0.209, test=-0.305) total time=  44.1s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=3, min_samples_split=2, n_estimators=2000;, score=(train=-0.210, test=-0.306) total time= 1.5min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=3, min_samples_split=5, n_estimators=1200;, score=(train=-0.207, test=-0.333) total time=  52.8s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=3, min_samples_split=5, n_estimators=1200;, score=(train=-0.209, test=-0.311) total time=  53.5s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=3, min_samples_split=5, n_estimators=1200;, score=(train=-0.209, test=-0.314) total time=  53.7s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=3, min_samples_split=5, n_estimators=1200;, score=(train=-0.211, test=-0.293) total time=  53.9s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=3, min_samples_split=5, n_estimators=1200;, score=(train=-0.209, test=-0.306) total time=  53.6s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=3, min_samples_split=5, n_estimators=1400;, score=(train=-0.206, test=-0.332) total time= 1.0min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=3, min_samples_split=5, n_estimators=1400;, score=(train=-0.209, test=-0.311) total time= 1.0min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=3, min_samples_split=5, n_estimators=1400;, score=(train=-0.208, test=-0.314) total time= 1.0min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=3, min_samples_split=5, n_estimators=1400;, score=(train=-0.210, test=-0.293) total time= 1.0min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=3, min_samples_split=5, n_estimators=1400;, score=(train=-0.210, test=-0.307) total time= 1.1min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=3, min_samples_split=5, n_estimators=1600;, score=(train=-0.206, test=-0.332) total time= 1.2min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=3, min_samples_split=5, n_estimators=1600;, score=(train=-0.209, test=-0.311) total time= 1.2min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=3, min_samples_split=5, n_estimators=1600;, score=(train=-0.208, test=-0.313) total time= 1.2min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=3, min_samples_split=5, n_estimators=1600;, score=(train=-0.211, test=-0.293) total time= 1.2min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=3, min_samples_split=5, n_estimators=1600;, score=(train=-0.209, test=-0.306) total time= 1.2min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=3, min_samples_split=5, n_estimators=1800;, score=(train=-0.206, test=-0.333) total time= 1.3min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=3, min_samples_split=5, n_estimators=1800;, score=(train=-0.209, test=-0.311) total time= 1.3min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=3, min_samples_split=5, n_estimators=1800;, score=(train=-0.211, test=-0.293) total time= 1.3min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=3, min_samples_split=5, n_estimators=1800;, score=(train=-0.208, test=-0.314) total time= 1.3min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=3, min_samples_split=8, n_estimators=1000;, score=(train=-0.212, test=-0.332) total time=  44.6s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=3, min_samples_split=8, n_estimators=1000;, score=(train=-0.215, test=-0.311) total time=  43.4s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=3, min_samples_split=5, n_estimators=1800;, score=(train=-0.210, test=-0.306) total time= 1.3min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=3, min_samples_split=5, n_estimators=2000;, score=(train=-0.206, test=-0.333) total time= 1.5min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=3, min_samples_split=8, n_estimators=1000;, score=(train=-0.214, test=-0.315) total time=  44.1s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=3, min_samples_split=5, n_estimators=2000;, score=(train=-0.210, test=-0.312) total time= 1.5min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=3, min_samples_split=8, n_estimators=1000;, score=(train=-0.215, test=-0.293) total time=  44.4s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=3, min_samples_split=5, n_estimators=2000;, score=(train=-0.208, test=-0.314) total time= 1.5min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=3, min_samples_split=5, n_estimators=2000;, score=(train=-0.211, test=-0.293) total time= 1.5min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=3, min_samples_split=8, n_estimators=1000;, score=(train=-0.216, test=-0.306) total time=  43.9s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=3, min_samples_split=5, n_estimators=2000;, score=(train=-0.210, test=-0.306) total time= 1.5min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=3, min_samples_split=8, n_estimators=1200;, score=(train=-0.211, test=-0.332) total time=  53.9s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=3, min_samples_split=8, n_estimators=1200;, score=(train=-0.215, test=-0.311) total time=  53.6s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=3, min_samples_split=8, n_estimators=1200;, score=(train=-0.214, test=-0.314) total time=  53.0s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=3, min_samples_split=8, n_estimators=1200;, score=(train=-0.216, test=-0.293) total time=  53.7s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=3, min_samples_split=8, n_estimators=1200;, score=(train=-0.215, test=-0.306) total time=  53.0s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=3, min_samples_split=8, n_estimators=1400;, score=(train=-0.211, test=-0.333) total time= 1.0min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=3, min_samples_split=8, n_estimators=1400;, score=(train=-0.215, test=-0.311) total time= 1.0min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=3, min_samples_split=8, n_estimators=1400;, score=(train=-0.214, test=-0.314) total time= 1.0min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=3, min_samples_split=8, n_estimators=1400;, score=(train=-0.216, test=-0.293) total time= 1.0min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=3, min_samples_split=8, n_estimators=1400;, score=(train=-0.215, test=-0.306) total time= 1.0min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=3, min_samples_split=8, n_estimators=1600;, score=(train=-0.211, test=-0.333) total time= 1.2min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=3, min_samples_split=8, n_estimators=1600;, score=(train=-0.214, test=-0.311) total time= 1.2min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=3, min_samples_split=8, n_estimators=1600;, score=(train=-0.214, test=-0.315) total time= 1.2min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=3, min_samples_split=8, n_estimators=1600;, score=(train=-0.216, test=-0.293) total time= 1.2min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=3, min_samples_split=8, n_estimators=1600;, score=(train=-0.215, test=-0.306) total time= 1.2min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=3, min_samples_split=8, n_estimators=1800;, score=(train=-0.211, test=-0.333) total time= 1.3min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=3, min_samples_split=8, n_estimators=1800;, score=(train=-0.215, test=-0.311) total time= 1.3min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=3, min_samples_split=8, n_estimators=1800;, score=(train=-0.214, test=-0.314) total time= 1.3min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=3, min_samples_split=8, n_estimators=1800;, score=(train=-0.216, test=-0.293) total time= 1.3min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=3, min_samples_split=8, n_estimators=1800;, score=(train=-0.215, test=-0.306) total time= 1.3min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=3, min_samples_split=11, n_estimators=1000;, score=(train=-0.223, test=-0.311) total time=  43.7s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=3, min_samples_split=11, n_estimators=1000;, score=(train=-0.219, test=-0.332) total time=  44.6s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=3, min_samples_split=11, n_estimators=1000;, score=(train=-0.222, test=-0.315) total time=  43.5s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=3, min_samples_split=8, n_estimators=2000;, score=(train=-0.211, test=-0.333) total time= 1.5min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=3, min_samples_split=8, n_estimators=2000;, score=(train=-0.215, test=-0.310) total time= 1.5min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=3, min_samples_split=11, n_estimators=1000;, score=(train=-0.224, test=-0.293) total time=  43.2s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=3, min_samples_split=8, n_estimators=2000;, score=(train=-0.213, test=-0.314) total time= 1.5min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=3, min_samples_split=8, n_estimators=2000;, score=(train=-0.216, test=-0.292) total time= 1.5min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=3, min_samples_split=11, n_estimators=1000;, score=(train=-0.223, test=-0.306) total time=  43.5s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=3, min_samples_split=8, n_estimators=2000;, score=(train=-0.215, test=-0.306) total time= 1.5min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=3, min_samples_split=11, n_estimators=1200;, score=(train=-0.222, test=-0.312) total time=  52.7s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=3, min_samples_split=11, n_estimators=1200;, score=(train=-0.219, test=-0.332) total time=  56.0s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=3, min_samples_split=11, n_estimators=1200;, score=(train=-0.222, test=-0.314) total time=  56.3s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=3, min_samples_split=11, n_estimators=1200;, score=(train=-0.224, test=-0.293) total time=  56.2s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=3, min_samples_split=11, n_estimators=1200;, score=(train=-0.223, test=-0.306) total time=  53.7s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=3, min_samples_split=11, n_estimators=1400;, score=(train=-0.219, test=-0.333) total time= 1.1min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=3, min_samples_split=11, n_estimators=1400;, score=(train=-0.222, test=-0.312) total time= 1.1min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=3, min_samples_split=11, n_estimators=1400;, score=(train=-0.221, test=-0.314) total time= 1.1min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=3, min_samples_split=11, n_estimators=1400;, score=(train=-0.223, test=-0.306) total time= 1.1min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=3, min_samples_split=11, n_estimators=1400;, score=(train=-0.224, test=-0.293) total time= 1.1min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=3, min_samples_split=11, n_estimators=1600;, score=(train=-0.219, test=-0.332) total time= 1.3min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=3, min_samples_split=11, n_estimators=1600;, score=(train=-0.222, test=-0.311) total time= 1.2min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=3, min_samples_split=11, n_estimators=1600;, score=(train=-0.222, test=-0.314) total time= 1.3min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=3, min_samples_split=11, n_estimators=1600;, score=(train=-0.224, test=-0.293) total time= 1.3min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=3, min_samples_split=11, n_estimators=1600;, score=(train=-0.223, test=-0.307) total time= 1.3min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=3, min_samples_split=11, n_estimators=1800;, score=(train=-0.219, test=-0.333) total time= 1.4min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=3, min_samples_split=11, n_estimators=1800;, score=(train=-0.222, test=-0.311) total time= 1.4min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=3, min_samples_split=11, n_estimators=1800;, score=(train=-0.222, test=-0.315) total time= 1.4min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=3, min_samples_split=11, n_estimators=1800;, score=(train=-0.224, test=-0.294) total time= 1.4min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=1000;, score=(train=-0.221, test=-0.333) total time=  46.8s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=3, min_samples_split=11, n_estimators=1800;, score=(train=-0.223, test=-0.306) total time= 1.5min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=1000;, score=(train=-0.225, test=-0.311) total time=  46.7s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=3, min_samples_split=11, n_estimators=2000;, score=(train=-0.219, test=-0.333) total time= 1.5min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=1000;, score=(train=-0.225, test=-0.315) total time=  45.3s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=3, min_samples_split=11, n_estimators=2000;, score=(train=-0.223, test=-0.311) total time= 1.6min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=1000;, score=(train=-0.227, test=-0.293) total time=  46.2s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=3, min_samples_split=11, n_estimators=2000;, score=(train=-0.222, test=-0.314) total time= 1.6min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=1000;, score=(train=-0.226, test=-0.308) total time=  45.9s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=3, min_samples_split=11, n_estimators=2000;, score=(train=-0.223, test=-0.293) total time= 1.6min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=1200;, score=(train=-0.221, test=-0.333) total time=  53.3s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=3, min_samples_split=11, n_estimators=2000;, score=(train=-0.223, test=-0.306) total time= 1.5min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=1200;, score=(train=-0.224, test=-0.315) total time=  54.4s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=1200;, score=(train=-0.225, test=-0.312) total time=  54.9s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=1200;, score=(train=-0.227, test=-0.294) total time=  55.1s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=1200;, score=(train=-0.226, test=-0.306) total time=  55.7s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=1400;, score=(train=-0.221, test=-0.333) total time= 1.1min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=1400;, score=(train=-0.225, test=-0.312) total time= 1.1min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=1400;, score=(train=-0.224, test=-0.315) total time= 1.1min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=1400;, score=(train=-0.226, test=-0.293) total time= 1.1min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=1400;, score=(train=-0.226, test=-0.308) total time= 1.1min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=1600;, score=(train=-0.221, test=-0.333) total time= 1.2min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=1600;, score=(train=-0.225, test=-0.311) total time= 1.2min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=1600;, score=(train=-0.225, test=-0.315) total time= 1.2min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=1600;, score=(train=-0.225, test=-0.307) total time= 1.2min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=1600;, score=(train=-0.226, test=-0.293) total time= 1.3min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=1800;, score=(train=-0.221, test=-0.333) total time= 1.4min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=1800;, score=(train=-0.225, test=-0.312) total time= 1.4min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=1800;, score=(train=-0.224, test=-0.315) total time= 1.4min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=1800;, score=(train=-0.226, test=-0.294) total time= 1.4min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=1800;, score=(train=-0.225, test=-0.307) total time= 1.3min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=1000;, score=(train=-0.222, test=-0.333) total time=  45.0s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=1000;, score=(train=-0.225, test=-0.312) total time=  44.6s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=2000;, score=(train=-0.221, test=-0.333) total time= 1.5min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=2000;, score=(train=-0.225, test=-0.312) total time= 1.5min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=1000;, score=(train=-0.225, test=-0.314) total time=  44.5s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=1000;, score=(train=-0.227, test=-0.293) total time=  43.5s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=2000;, score=(train=-0.224, test=-0.314) total time= 1.5min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=1000;, score=(train=-0.226, test=-0.306) total time=  44.0s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=2000;, score=(train=-0.226, test=-0.293) total time= 1.5min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=2000;, score=(train=-0.226, test=-0.307) total time= 1.5min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=1200;, score=(train=-0.221, test=-0.333) total time=  52.7s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=1200;, score=(train=-0.225, test=-0.311) total time=  52.4s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=1200;, score=(train=-0.225, test=-0.314) total time=  52.9s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=1200;, score=(train=-0.227, test=-0.293) total time=  52.7s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=1200;, score=(train=-0.226, test=-0.307) total time=  52.4s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=1400;, score=(train=-0.221, test=-0.332) total time= 1.0min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=1400;, score=(train=-0.225, test=-0.311) total time= 1.0min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=1400;, score=(train=-0.225, test=-0.314) total time= 1.0min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=1400;, score=(train=-0.226, test=-0.294) total time= 1.0min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=1400;, score=(train=-0.225, test=-0.307) total time= 1.0min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=1600;, score=(train=-0.221, test=-0.332) total time= 1.2min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=1600;, score=(train=-0.225, test=-0.312) total time= 1.2min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=1600;, score=(train=-0.226, test=-0.293) total time= 1.2min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=1600;, score=(train=-0.225, test=-0.314) total time= 1.2min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=1600;, score=(train=-0.225, test=-0.307) total time= 1.2min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=1800;, score=(train=-0.221, test=-0.333) total time= 1.4min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=1800;, score=(train=-0.225, test=-0.311) total time= 1.4min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=1800;, score=(train=-0.224, test=-0.314) total time= 1.4min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=5, min_samples_split=8, n_estimators=1000;, score=(train=-0.221, test=-0.333) total time=  45.1s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=1800;, score=(train=-0.226, test=-0.293) total time= 1.4min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=1800;, score=(train=-0.226, test=-0.307) total time= 1.4min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=5, min_samples_split=8, n_estimators=1000;, score=(train=-0.225, test=-0.311) total time=  45.7s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=2000;, score=(train=-0.221, test=-0.332) total time= 1.6min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=5, min_samples_split=8, n_estimators=1000;, score=(train=-0.224, test=-0.314) total time=  45.1s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=2000;, score=(train=-0.225, test=-0.312) total time= 1.6min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=5, min_samples_split=8, n_estimators=1000;, score=(train=-0.227, test=-0.293) total time=  47.0s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=2000;, score=(train=-0.224, test=-0.314) total time= 1.5min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=2000;, score=(train=-0.226, test=-0.293) total time= 1.6min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=5, min_samples_split=8, n_estimators=1000;, score=(train=-0.226, test=-0.307) total time=  45.6s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=2000;, score=(train=-0.225, test=-0.306) total time= 1.5min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=5, min_samples_split=8, n_estimators=1200;, score=(train=-0.221, test=-0.333) total time=  55.0s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=5, min_samples_split=8, n_estimators=1200;, score=(train=-0.225, test=-0.311) total time=  55.0s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=5, min_samples_split=8, n_estimators=1200;, score=(train=-0.224, test=-0.314) total time=  54.3s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=5, min_samples_split=8, n_estimators=1200;, score=(train=-0.226, test=-0.293) total time=  57.7s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=5, min_samples_split=8, n_estimators=1200;, score=(train=-0.226, test=-0.307) total time=  55.1s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=5, min_samples_split=8, n_estimators=1400;, score=(train=-0.221, test=-0.333) total time= 1.1min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=5, min_samples_split=8, n_estimators=1400;, score=(train=-0.225, test=-0.311) total time= 1.0min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=5, min_samples_split=8, n_estimators=1400;, score=(train=-0.224, test=-0.314) total time= 1.1min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=5, min_samples_split=8, n_estimators=1400;, score=(train=-0.226, test=-0.293) total time= 1.1min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=5, min_samples_split=8, n_estimators=1400;, score=(train=-0.225, test=-0.306) total time= 1.0min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=5, min_samples_split=8, n_estimators=1600;, score=(train=-0.221, test=-0.333) total time= 1.2min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=5, min_samples_split=8, n_estimators=1600;, score=(train=-0.225, test=-0.312) total time= 1.2min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=5, min_samples_split=8, n_estimators=1600;, score=(train=-0.224, test=-0.315) total time= 1.2min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=5, min_samples_split=8, n_estimators=1600;, score=(train=-0.226, test=-0.293) total time= 1.3min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=5, min_samples_split=8, n_estimators=1600;, score=(train=-0.226, test=-0.307) total time= 1.2min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=5, min_samples_split=8, n_estimators=1800;, score=(train=-0.225, test=-0.312) total time= 1.3min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=5, min_samples_split=8, n_estimators=1800;, score=(train=-0.221, test=-0.332) total time= 1.4min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=5, min_samples_split=8, n_estimators=1800;, score=(train=-0.224, test=-0.314) total time= 1.3min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=5, min_samples_split=8, n_estimators=1800;, score=(train=-0.227, test=-0.294) total time= 1.4min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=5, min_samples_split=8, n_estimators=1800;, score=(train=-0.226, test=-0.306) total time= 1.3min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=5, min_samples_split=11, n_estimators=1000;, score=(train=-0.223, test=-0.333) total time=  44.4s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=5, min_samples_split=11, n_estimators=1000;, score=(train=-0.227, test=-0.312) total time=  44.3s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=5, min_samples_split=8, n_estimators=2000;, score=(train=-0.221, test=-0.333) total time= 1.5min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=5, min_samples_split=8, n_estimators=2000;, score=(train=-0.225, test=-0.311) total time= 1.5min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=5, min_samples_split=11, n_estimators=1000;, score=(train=-0.229, test=-0.294) total time=  43.5s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=5, min_samples_split=11, n_estimators=1000;, score=(train=-0.227, test=-0.315) total time=  45.0s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=5, min_samples_split=8, n_estimators=2000;, score=(train=-0.225, test=-0.315) total time= 1.5min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=5, min_samples_split=8, n_estimators=2000;, score=(train=-0.227, test=-0.293) total time= 1.5min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=5, min_samples_split=11, n_estimators=1000;, score=(train=-0.228, test=-0.306) total time=  43.2s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=5, min_samples_split=8, n_estimators=2000;, score=(train=-0.225, test=-0.307) total time= 1.5min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=5, min_samples_split=11, n_estimators=1200;, score=(train=-0.222, test=-0.333) total time=  55.1s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=5, min_samples_split=11, n_estimators=1200;, score=(train=-0.226, test=-0.314) total time=  51.6s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=5, min_samples_split=11, n_estimators=1200;, score=(train=-0.227, test=-0.312) total time=  53.5s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=5, min_samples_split=11, n_estimators=1200;, score=(train=-0.229, test=-0.293) total time=  54.2s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=5, min_samples_split=11, n_estimators=1200;, score=(train=-0.228, test=-0.307) total time=  57.1s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=5, min_samples_split=11, n_estimators=1400;, score=(train=-0.223, test=-0.333) total time= 1.0min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=5, min_samples_split=11, n_estimators=1400;, score=(train=-0.227, test=-0.312) total time= 1.0min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=5, min_samples_split=11, n_estimators=1400;, score=(train=-0.227, test=-0.315) total time= 1.0min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=5, min_samples_split=11, n_estimators=1400;, score=(train=-0.228, test=-0.294) total time= 1.1min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=5, min_samples_split=11, n_estimators=1400;, score=(train=-0.228, test=-0.306) total time= 1.1min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=5, min_samples_split=11, n_estimators=1600;, score=(train=-0.223, test=-0.333) total time= 1.1min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=5, min_samples_split=11, n_estimators=1600;, score=(train=-0.227, test=-0.312) total time= 1.1min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=5, min_samples_split=11, n_estimators=1600;, score=(train=-0.229, test=-0.293) total time= 1.2min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=5, min_samples_split=11, n_estimators=1600;, score=(train=-0.227, test=-0.314) total time= 1.2min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=5, min_samples_split=11, n_estimators=1600;, score=(train=-0.228, test=-0.306) total time= 1.2min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=5, min_samples_split=11, n_estimators=1800;, score=(train=-0.223, test=-0.333) total time= 1.4min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=5, min_samples_split=11, n_estimators=1800;, score=(train=-0.227, test=-0.312) total time= 1.4min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=5, min_samples_split=11, n_estimators=1800;, score=(train=-0.228, test=-0.307) total time= 1.3min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=5, min_samples_split=11, n_estimators=1800;, score=(train=-0.226, test=-0.315) total time= 1.4min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=5, min_samples_split=11, n_estimators=1800;, score=(train=-0.229, test=-0.293) total time= 1.3min\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=5, min_samples_split=11, n_estimators=2000;, score=(train=-0.223, test=-0.333) total time= 1.5min\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=5, min_samples_split=11, n_estimators=2000;, score=(train=-0.227, test=-0.312) total time= 1.5min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=(train=-0.141, test=-0.312) total time= 1.1min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=(train=-0.141, test=-0.333) total time= 1.1min\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=5, min_samples_split=11, n_estimators=2000;, score=(train=-0.227, test=-0.314) total time= 1.5min\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=5, min_samples_split=11, n_estimators=2000;, score=(train=-0.229, test=-0.293) total time= 1.5min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=(train=-0.140, test=-0.315) total time= 1.1min\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=5, min_samples_split=11, n_estimators=2000;, score=(train=-0.228, test=-0.307) total time= 1.5min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=(train=-0.143, test=-0.293) total time= 1.0min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=(train=-0.141, test=-0.306) total time= 1.0min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=(train=-0.141, test=-0.333) total time= 1.3min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=(train=-0.141, test=-0.313) total time= 1.3min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=(train=-0.143, test=-0.294) total time= 1.3min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=(train=-0.139, test=-0.315) total time= 1.3min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=(train=-0.141, test=-0.306) total time= 1.3min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=1400;, score=(train=-0.140, test=-0.311) total time= 1.5min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=1400;, score=(train=-0.140, test=-0.316) total time= 1.4min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=1400;, score=(train=-0.141, test=-0.333) total time= 1.5min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=1400;, score=(train=-0.143, test=-0.294) total time= 1.5min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=1400;, score=(train=-0.141, test=-0.307) total time= 1.6min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=1600;, score=(train=-0.140, test=-0.332) total time= 1.7min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=1600;, score=(train=-0.141, test=-0.311) total time= 1.7min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=1600;, score=(train=-0.140, test=-0.315) total time= 1.7min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=1600;, score=(train=-0.143, test=-0.293) total time= 1.8min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=1600;, score=(train=-0.140, test=-0.306) total time= 1.6min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=1800;, score=(train=-0.141, test=-0.333) total time= 1.9min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=1800;, score=(train=-0.141, test=-0.312) total time= 1.9min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=1800;, score=(train=-0.140, test=-0.314) total time= 1.9min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=1800;, score=(train=-0.142, test=-0.294) total time= 1.9min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=1800;, score=(train=-0.140, test=-0.306) total time= 1.9min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=1000;, score=(train=-0.152, test=-0.333) total time= 1.0min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=2000;, score=(train=-0.141, test=-0.333) total time= 2.1min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=1000;, score=(train=-0.153, test=-0.312) total time= 1.0min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=2000;, score=(train=-0.141, test=-0.311) total time= 2.2min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=1000;, score=(train=-0.153, test=-0.314) total time= 1.0min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=1000;, score=(train=-0.154, test=-0.294) total time= 1.0min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=2000;, score=(train=-0.140, test=-0.314) total time= 2.1min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=2000;, score=(train=-0.143, test=-0.295) total time= 2.2min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=1000;, score=(train=-0.153, test=-0.306) total time= 1.0min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=1200;, score=(train=-0.152, test=-0.333) total time= 1.2min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=1200;, score=(train=-0.152, test=-0.311) total time= 1.2min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=2000;, score=(train=-0.141, test=-0.306) total time= 2.1min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=1200;, score=(train=-0.152, test=-0.315) total time= 1.2min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=1200;, score=(train=-0.155, test=-0.294) total time= 1.3min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=1200;, score=(train=-0.153, test=-0.306) total time= 1.2min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=1400;, score=(train=-0.152, test=-0.312) total time= 1.4min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=1400;, score=(train=-0.151, test=-0.333) total time= 1.4min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=1400;, score=(train=-0.152, test=-0.314) total time= 1.4min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=1400;, score=(train=-0.154, test=-0.294) total time= 1.4min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=1400;, score=(train=-0.153, test=-0.306) total time= 1.4min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=1600;, score=(train=-0.152, test=-0.333) total time= 1.6min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=1600;, score=(train=-0.153, test=-0.311) total time= 1.6min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=1600;, score=(train=-0.152, test=-0.315) total time= 1.6min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=1600;, score=(train=-0.155, test=-0.294) total time= 1.6min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=1600;, score=(train=-0.153, test=-0.306) total time= 1.6min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=1800;, score=(train=-0.152, test=-0.312) total time= 1.7min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=1800;, score=(train=-0.152, test=-0.332) total time= 1.8min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=1800;, score=(train=-0.152, test=-0.314) total time= 1.7min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=1, min_samples_split=8, n_estimators=1000;, score=(train=-0.166, test=-0.334) total time=  59.4s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=1800;, score=(train=-0.154, test=-0.294) total time= 1.8min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=1800;, score=(train=-0.153, test=-0.306) total time= 1.8min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=1, min_samples_split=8, n_estimators=1000;, score=(train=-0.168, test=-0.312) total time=  58.2s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=2000;, score=(train=-0.152, test=-0.333) total time= 2.0min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=2000;, score=(train=-0.153, test=-0.312) total time= 2.0min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=1, min_samples_split=8, n_estimators=1000;, score=(train=-0.167, test=-0.315) total time=  57.9s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=1, min_samples_split=8, n_estimators=1000;, score=(train=-0.170, test=-0.293) total time=  59.5s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=2000;, score=(train=-0.152, test=-0.315) total time= 2.0min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=2000;, score=(train=-0.155, test=-0.294) total time= 2.0min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=2000;, score=(train=-0.153, test=-0.306) total time= 2.0min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=1, min_samples_split=8, n_estimators=1000;, score=(train=-0.168, test=-0.307) total time=  57.8s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=1, min_samples_split=8, n_estimators=1200;, score=(train=-0.167, test=-0.333) total time= 1.2min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=1, min_samples_split=8, n_estimators=1200;, score=(train=-0.168, test=-0.311) total time= 1.2min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=1, min_samples_split=8, n_estimators=1200;, score=(train=-0.167, test=-0.315) total time= 1.1min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=1, min_samples_split=8, n_estimators=1200;, score=(train=-0.170, test=-0.294) total time= 1.2min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=1, min_samples_split=8, n_estimators=1200;, score=(train=-0.168, test=-0.307) total time= 1.2min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=1, min_samples_split=8, n_estimators=1400;, score=(train=-0.166, test=-0.333) total time= 1.4min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=1, min_samples_split=8, n_estimators=1400;, score=(train=-0.168, test=-0.311) total time= 1.4min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=1, min_samples_split=8, n_estimators=1400;, score=(train=-0.167, test=-0.314) total time= 1.4min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=1, min_samples_split=8, n_estimators=1400;, score=(train=-0.170, test=-0.294) total time= 1.4min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=1, min_samples_split=8, n_estimators=1400;, score=(train=-0.168, test=-0.306) total time= 1.3min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=1, min_samples_split=8, n_estimators=1600;, score=(train=-0.166, test=-0.333) total time= 1.6min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=1, min_samples_split=8, n_estimators=1600;, score=(train=-0.168, test=-0.311) total time= 1.5min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=1, min_samples_split=8, n_estimators=1600;, score=(train=-0.167, test=-0.314) total time= 1.6min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=1, min_samples_split=8, n_estimators=1600;, score=(train=-0.168, test=-0.306) total time= 1.5min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=1, min_samples_split=8, n_estimators=1600;, score=(train=-0.170, test=-0.294) total time= 1.6min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=1, min_samples_split=8, n_estimators=1800;, score=(train=-0.166, test=-0.333) total time= 1.7min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=1, min_samples_split=8, n_estimators=1800;, score=(train=-0.168, test=-0.311) total time= 1.7min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=1, min_samples_split=8, n_estimators=1800;, score=(train=-0.167, test=-0.315) total time= 1.7min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=1, min_samples_split=8, n_estimators=1800;, score=(train=-0.169, test=-0.294) total time= 1.7min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=1, min_samples_split=11, n_estimators=1000;, score=(train=-0.181, test=-0.311) total time=  57.4s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=1, min_samples_split=11, n_estimators=1000;, score=(train=-0.179, test=-0.334) total time=  58.6s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=1, min_samples_split=8, n_estimators=1800;, score=(train=-0.169, test=-0.307) total time= 1.8min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=1, min_samples_split=11, n_estimators=1000;, score=(train=-0.182, test=-0.316) total time=  57.1s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=1, min_samples_split=8, n_estimators=2000;, score=(train=-0.166, test=-0.333) total time= 2.0min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=1, min_samples_split=8, n_estimators=2000;, score=(train=-0.168, test=-0.311) total time= 1.9min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=1, min_samples_split=11, n_estimators=1000;, score=(train=-0.184, test=-0.295) total time=  56.8s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=1, min_samples_split=8, n_estimators=2000;, score=(train=-0.168, test=-0.315) total time= 1.9min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=1, min_samples_split=8, n_estimators=2000;, score=(train=-0.170, test=-0.294) total time= 1.9min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=1, min_samples_split=11, n_estimators=1000;, score=(train=-0.182, test=-0.307) total time=  56.8s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=1, min_samples_split=8, n_estimators=2000;, score=(train=-0.169, test=-0.307) total time= 1.9min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=1, min_samples_split=11, n_estimators=1200;, score=(train=-0.179, test=-0.333) total time= 1.1min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=1, min_samples_split=11, n_estimators=1200;, score=(train=-0.182, test=-0.316) total time= 1.1min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=1, min_samples_split=11, n_estimators=1200;, score=(train=-0.184, test=-0.294) total time= 1.1min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=1, min_samples_split=11, n_estimators=1200;, score=(train=-0.182, test=-0.312) total time= 1.2min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=1, min_samples_split=11, n_estimators=1200;, score=(train=-0.182, test=-0.307) total time= 1.2min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=1, min_samples_split=11, n_estimators=1400;, score=(train=-0.179, test=-0.333) total time= 1.3min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=1, min_samples_split=11, n_estimators=1400;, score=(train=-0.182, test=-0.311) total time= 1.3min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=1, min_samples_split=11, n_estimators=1400;, score=(train=-0.182, test=-0.316) total time= 1.3min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=1, min_samples_split=11, n_estimators=1400;, score=(train=-0.182, test=-0.307) total time= 1.3min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=1, min_samples_split=11, n_estimators=1400;, score=(train=-0.184, test=-0.294) total time= 1.3min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=1, min_samples_split=11, n_estimators=1600;, score=(train=-0.180, test=-0.332) total time= 1.5min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=1, min_samples_split=11, n_estimators=1600;, score=(train=-0.181, test=-0.312) total time= 1.5min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=1, min_samples_split=11, n_estimators=1600;, score=(train=-0.182, test=-0.315) total time= 1.5min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=1, min_samples_split=11, n_estimators=1600;, score=(train=-0.184, test=-0.294) total time= 1.5min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=1, min_samples_split=11, n_estimators=1600;, score=(train=-0.182, test=-0.307) total time= 1.5min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=1, min_samples_split=11, n_estimators=1800;, score=(train=-0.180, test=-0.333) total time= 1.7min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=1, min_samples_split=11, n_estimators=1800;, score=(train=-0.182, test=-0.312) total time= 1.7min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=1, min_samples_split=11, n_estimators=1800;, score=(train=-0.182, test=-0.316) total time= 1.7min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=1, min_samples_split=11, n_estimators=1800;, score=(train=-0.183, test=-0.294) total time= 1.7min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=1, min_samples_split=11, n_estimators=1800;, score=(train=-0.182, test=-0.307) total time= 1.7min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=3, min_samples_split=2, n_estimators=1000;, score=(train=-0.167, test=-0.333) total time=  55.4s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=3, min_samples_split=2, n_estimators=1000;, score=(train=-0.169, test=-0.312) total time=  55.3s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=3, min_samples_split=2, n_estimators=1000;, score=(train=-0.169, test=-0.313) total time=  55.7s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=1, min_samples_split=11, n_estimators=2000;, score=(train=-0.180, test=-0.333) total time= 1.9min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=1, min_samples_split=11, n_estimators=2000;, score=(train=-0.181, test=-0.312) total time= 1.9min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=3, min_samples_split=2, n_estimators=1000;, score=(train=-0.171, test=-0.293) total time=  55.9s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=1, min_samples_split=11, n_estimators=2000;, score=(train=-0.182, test=-0.315) total time= 1.9min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=3, min_samples_split=2, n_estimators=1000;, score=(train=-0.170, test=-0.306) total time=  55.8s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=1, min_samples_split=11, n_estimators=2000;, score=(train=-0.183, test=-0.294) total time= 1.9min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=1, min_samples_split=11, n_estimators=2000;, score=(train=-0.182, test=-0.307) total time= 1.9min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=3, min_samples_split=2, n_estimators=1200;, score=(train=-0.167, test=-0.332) total time= 1.1min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=3, min_samples_split=2, n_estimators=1200;, score=(train=-0.169, test=-0.311) total time= 1.1min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=3, min_samples_split=2, n_estimators=1200;, score=(train=-0.170, test=-0.293) total time= 1.1min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=3, min_samples_split=2, n_estimators=1200;, score=(train=-0.168, test=-0.313) total time= 1.1min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=3, min_samples_split=2, n_estimators=1200;, score=(train=-0.170, test=-0.306) total time= 1.1min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=3, min_samples_split=2, n_estimators=1400;, score=(train=-0.167, test=-0.333) total time= 1.3min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=3, min_samples_split=2, n_estimators=1400;, score=(train=-0.169, test=-0.312) total time= 1.3min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=3, min_samples_split=2, n_estimators=1400;, score=(train=-0.168, test=-0.313) total time= 1.3min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=3, min_samples_split=2, n_estimators=1400;, score=(train=-0.171, test=-0.293) total time= 1.3min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=3, min_samples_split=2, n_estimators=1400;, score=(train=-0.170, test=-0.306) total time= 1.3min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=3, min_samples_split=2, n_estimators=1600;, score=(train=-0.167, test=-0.332) total time= 1.5min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=3, min_samples_split=2, n_estimators=1600;, score=(train=-0.169, test=-0.311) total time= 1.5min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=3, min_samples_split=2, n_estimators=1600;, score=(train=-0.168, test=-0.313) total time= 1.5min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=3, min_samples_split=2, n_estimators=1600;, score=(train=-0.171, test=-0.293) total time= 1.5min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=3, min_samples_split=2, n_estimators=1600;, score=(train=-0.170, test=-0.305) total time= 1.5min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=3, min_samples_split=2, n_estimators=1800;, score=(train=-0.167, test=-0.332) total time= 1.7min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=3, min_samples_split=2, n_estimators=1800;, score=(train=-0.169, test=-0.311) total time= 1.7min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=3, min_samples_split=2, n_estimators=1800;, score=(train=-0.169, test=-0.313) total time= 1.7min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=3, min_samples_split=2, n_estimators=1800;, score=(train=-0.171, test=-0.293) total time= 1.7min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=3, min_samples_split=2, n_estimators=1800;, score=(train=-0.170, test=-0.306) total time= 1.7min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=3, min_samples_split=5, n_estimators=1000;, score=(train=-0.167, test=-0.333) total time=  54.8s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=3, min_samples_split=5, n_estimators=1000;, score=(train=-0.169, test=-0.312) total time=  56.1s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=3, min_samples_split=5, n_estimators=1000;, score=(train=-0.169, test=-0.314) total time=  55.5s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=3, min_samples_split=2, n_estimators=2000;, score=(train=-0.166, test=-0.332) total time= 1.8min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=3, min_samples_split=2, n_estimators=2000;, score=(train=-0.169, test=-0.312) total time= 1.8min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=3, min_samples_split=5, n_estimators=1000;, score=(train=-0.171, test=-0.293) total time=  55.1s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=3, min_samples_split=2, n_estimators=2000;, score=(train=-0.168, test=-0.313) total time= 1.8min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=3, min_samples_split=5, n_estimators=1000;, score=(train=-0.170, test=-0.306) total time=  55.6s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=3, min_samples_split=2, n_estimators=2000;, score=(train=-0.170, test=-0.293) total time= 1.9min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=3, min_samples_split=2, n_estimators=2000;, score=(train=-0.169, test=-0.305) total time= 1.8min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=3, min_samples_split=5, n_estimators=1200;, score=(train=-0.167, test=-0.333) total time= 1.1min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=3, min_samples_split=5, n_estimators=1200;, score=(train=-0.169, test=-0.312) total time= 1.1min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=3, min_samples_split=5, n_estimators=1200;, score=(train=-0.169, test=-0.314) total time= 1.1min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=3, min_samples_split=5, n_estimators=1200;, score=(train=-0.171, test=-0.294) total time= 1.1min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=3, min_samples_split=5, n_estimators=1200;, score=(train=-0.170, test=-0.306) total time= 1.1min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=3, min_samples_split=5, n_estimators=1400;, score=(train=-0.167, test=-0.332) total time= 1.3min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=3, min_samples_split=5, n_estimators=1400;, score=(train=-0.169, test=-0.311) total time= 1.3min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=3, min_samples_split=5, n_estimators=1400;, score=(train=-0.169, test=-0.313) total time= 1.3min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=3, min_samples_split=5, n_estimators=1400;, score=(train=-0.171, test=-0.293) total time= 1.3min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=3, min_samples_split=5, n_estimators=1400;, score=(train=-0.169, test=-0.306) total time= 1.3min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=3, min_samples_split=5, n_estimators=1600;, score=(train=-0.167, test=-0.333) total time= 1.5min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=3, min_samples_split=5, n_estimators=1600;, score=(train=-0.169, test=-0.311) total time= 1.5min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=3, min_samples_split=5, n_estimators=1600;, score=(train=-0.168, test=-0.313) total time= 1.5min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=3, min_samples_split=5, n_estimators=1600;, score=(train=-0.171, test=-0.293) total time= 1.5min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=3, min_samples_split=5, n_estimators=1600;, score=(train=-0.169, test=-0.306) total time= 1.5min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=3, min_samples_split=5, n_estimators=1800;, score=(train=-0.167, test=-0.332) total time= 1.7min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=3, min_samples_split=5, n_estimators=1800;, score=(train=-0.169, test=-0.311) total time= 1.7min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=3, min_samples_split=5, n_estimators=1800;, score=(train=-0.168, test=-0.313) total time= 1.7min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=3, min_samples_split=5, n_estimators=1800;, score=(train=-0.171, test=-0.293) total time= 1.6min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=3, min_samples_split=5, n_estimators=1800;, score=(train=-0.169, test=-0.307) total time= 1.6min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=3, min_samples_split=8, n_estimators=1000;, score=(train=-0.176, test=-0.333) total time=  54.4s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=3, min_samples_split=8, n_estimators=1000;, score=(train=-0.179, test=-0.312) total time=  54.6s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=3, min_samples_split=8, n_estimators=1000;, score=(train=-0.178, test=-0.314) total time=  54.6s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=3, min_samples_split=5, n_estimators=2000;, score=(train=-0.167, test=-0.332) total time= 1.8min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=3, min_samples_split=5, n_estimators=2000;, score=(train=-0.169, test=-0.311) total time= 1.8min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=3, min_samples_split=8, n_estimators=1000;, score=(train=-0.181, test=-0.294) total time=  55.5s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=3, min_samples_split=5, n_estimators=2000;, score=(train=-0.168, test=-0.313) total time= 1.8min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=3, min_samples_split=8, n_estimators=1000;, score=(train=-0.180, test=-0.306) total time=  54.6s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=3, min_samples_split=5, n_estimators=2000;, score=(train=-0.171, test=-0.293) total time= 1.9min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=3, min_samples_split=5, n_estimators=2000;, score=(train=-0.169, test=-0.306) total time= 1.8min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=3, min_samples_split=8, n_estimators=1200;, score=(train=-0.179, test=-0.312) total time= 1.1min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=3, min_samples_split=8, n_estimators=1200;, score=(train=-0.176, test=-0.331) total time= 1.1min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=3, min_samples_split=8, n_estimators=1200;, score=(train=-0.178, test=-0.314) total time= 1.1min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=3, min_samples_split=8, n_estimators=1200;, score=(train=-0.181, test=-0.294) total time= 1.1min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=3, min_samples_split=8, n_estimators=1200;, score=(train=-0.180, test=-0.307) total time= 1.1min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=3, min_samples_split=8, n_estimators=1400;, score=(train=-0.176, test=-0.332) total time= 1.3min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=3, min_samples_split=8, n_estimators=1400;, score=(train=-0.179, test=-0.311) total time= 1.3min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=3, min_samples_split=8, n_estimators=1400;, score=(train=-0.178, test=-0.314) total time= 1.3min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=3, min_samples_split=8, n_estimators=1400;, score=(train=-0.180, test=-0.293) total time= 1.3min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=3, min_samples_split=8, n_estimators=1400;, score=(train=-0.179, test=-0.306) total time= 1.3min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=3, min_samples_split=8, n_estimators=1600;, score=(train=-0.176, test=-0.332) total time= 1.5min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=3, min_samples_split=8, n_estimators=1600;, score=(train=-0.179, test=-0.312) total time= 1.5min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=3, min_samples_split=8, n_estimators=1600;, score=(train=-0.178, test=-0.314) total time= 1.5min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=3, min_samples_split=8, n_estimators=1600;, score=(train=-0.180, test=-0.306) total time= 1.5min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=3, min_samples_split=8, n_estimators=1600;, score=(train=-0.181, test=-0.293) total time= 1.5min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=3, min_samples_split=8, n_estimators=1800;, score=(train=-0.176, test=-0.332) total time= 1.7min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=3, min_samples_split=8, n_estimators=1800;, score=(train=-0.179, test=-0.311) total time= 1.7min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=3, min_samples_split=8, n_estimators=1800;, score=(train=-0.178, test=-0.313) total time= 1.7min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=3, min_samples_split=8, n_estimators=1800;, score=(train=-0.181, test=-0.293) total time= 1.7min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=3, min_samples_split=11, n_estimators=1000;, score=(train=-0.189, test=-0.333) total time=  55.6s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=3, min_samples_split=8, n_estimators=1800;, score=(train=-0.179, test=-0.306) total time= 1.8min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=3, min_samples_split=11, n_estimators=1000;, score=(train=-0.193, test=-0.311) total time=  58.2s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=3, min_samples_split=11, n_estimators=1000;, score=(train=-0.193, test=-0.314) total time=  58.5s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=3, min_samples_split=8, n_estimators=2000;, score=(train=-0.176, test=-0.332) total time= 1.9min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=3, min_samples_split=8, n_estimators=2000;, score=(train=-0.179, test=-0.311) total time= 1.9min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=3, min_samples_split=11, n_estimators=1000;, score=(train=-0.194, test=-0.293) total time=  56.4s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=3, min_samples_split=8, n_estimators=2000;, score=(train=-0.178, test=-0.314) total time= 1.9min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=3, min_samples_split=8, n_estimators=2000;, score=(train=-0.180, test=-0.293) total time= 2.0min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=3, min_samples_split=11, n_estimators=1000;, score=(train=-0.193, test=-0.307) total time=  57.8s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=3, min_samples_split=8, n_estimators=2000;, score=(train=-0.179, test=-0.306) total time= 2.0min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=3, min_samples_split=11, n_estimators=1200;, score=(train=-0.189, test=-0.333) total time= 1.2min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=3, min_samples_split=11, n_estimators=1200;, score=(train=-0.193, test=-0.312) total time= 1.1min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=3, min_samples_split=11, n_estimators=1200;, score=(train=-0.192, test=-0.315) total time= 1.1min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=3, min_samples_split=11, n_estimators=1200;, score=(train=-0.194, test=-0.293) total time= 1.2min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=3, min_samples_split=11, n_estimators=1200;, score=(train=-0.193, test=-0.307) total time= 1.1min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=3, min_samples_split=11, n_estimators=1400;, score=(train=-0.189, test=-0.333) total time= 1.3min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=3, min_samples_split=11, n_estimators=1400;, score=(train=-0.192, test=-0.311) total time= 1.3min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=3, min_samples_split=11, n_estimators=1400;, score=(train=-0.192, test=-0.314) total time= 1.3min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=3, min_samples_split=11, n_estimators=1400;, score=(train=-0.194, test=-0.294) total time= 1.4min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=3, min_samples_split=11, n_estimators=1400;, score=(train=-0.193, test=-0.306) total time= 1.3min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=3, min_samples_split=11, n_estimators=1600;, score=(train=-0.189, test=-0.333) total time= 1.5min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=3, min_samples_split=11, n_estimators=1600;, score=(train=-0.192, test=-0.314) total time= 1.5min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=3, min_samples_split=11, n_estimators=1600;, score=(train=-0.192, test=-0.311) total time= 1.6min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=3, min_samples_split=11, n_estimators=1600;, score=(train=-0.194, test=-0.293) total time= 1.5min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=3, min_samples_split=11, n_estimators=1600;, score=(train=-0.192, test=-0.307) total time= 1.6min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=3, min_samples_split=11, n_estimators=1800;, score=(train=-0.189, test=-0.333) total time= 1.8min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=3, min_samples_split=11, n_estimators=1800;, score=(train=-0.193, test=-0.312) total time= 1.7min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=3, min_samples_split=11, n_estimators=1800;, score=(train=-0.192, test=-0.315) total time= 1.7min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=3, min_samples_split=11, n_estimators=1800;, score=(train=-0.194, test=-0.294) total time= 1.7min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=1000;, score=(train=-0.195, test=-0.332) total time=  55.6s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=3, min_samples_split=11, n_estimators=1800;, score=(train=-0.193, test=-0.307) total time= 1.7min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=1000;, score=(train=-0.199, test=-0.312) total time=  54.5s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=1000;, score=(train=-0.198, test=-0.315) total time=  54.6s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=3, min_samples_split=11, n_estimators=2000;, score=(train=-0.189, test=-0.332) total time= 1.9min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=3, min_samples_split=11, n_estimators=2000;, score=(train=-0.193, test=-0.312) total time= 1.9min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=1000;, score=(train=-0.200, test=-0.294) total time=  53.8s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=3, min_samples_split=11, n_estimators=2000;, score=(train=-0.192, test=-0.313) total time= 1.9min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=1000;, score=(train=-0.199, test=-0.307) total time=  56.6s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=3, min_samples_split=11, n_estimators=2000;, score=(train=-0.194, test=-0.294) total time= 1.9min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=3, min_samples_split=11, n_estimators=2000;, score=(train=-0.193, test=-0.306) total time= 1.9min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=1200;, score=(train=-0.195, test=-0.333) total time= 1.1min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=1200;, score=(train=-0.199, test=-0.312) total time= 1.1min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=1200;, score=(train=-0.198, test=-0.313) total time= 1.1min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=1200;, score=(train=-0.200, test=-0.293) total time= 1.1min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=1200;, score=(train=-0.200, test=-0.306) total time= 1.1min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=1400;, score=(train=-0.195, test=-0.333) total time= 1.2min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=1400;, score=(train=-0.198, test=-0.314) total time= 1.2min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=1400;, score=(train=-0.199, test=-0.312) total time= 1.3min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=1400;, score=(train=-0.200, test=-0.294) total time= 1.2min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=1400;, score=(train=-0.199, test=-0.307) total time= 1.2min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=1600;, score=(train=-0.195, test=-0.332) total time= 1.4min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=1600;, score=(train=-0.198, test=-0.314) total time= 1.4min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=1600;, score=(train=-0.198, test=-0.312) total time= 1.4min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=1600;, score=(train=-0.200, test=-0.294) total time= 1.5min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=1600;, score=(train=-0.199, test=-0.307) total time= 1.4min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=1800;, score=(train=-0.195, test=-0.333) total time= 1.6min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=1800;, score=(train=-0.198, test=-0.314) total time= 1.6min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=1800;, score=(train=-0.199, test=-0.311) total time= 1.7min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=1800;, score=(train=-0.200, test=-0.294) total time= 1.6min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=1800;, score=(train=-0.199, test=-0.306) total time= 1.6min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=1000;, score=(train=-0.199, test=-0.312) total time=  52.5s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=1000;, score=(train=-0.195, test=-0.333) total time=  57.1s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=1000;, score=(train=-0.198, test=-0.313) total time=  53.3s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=2000;, score=(train=-0.195, test=-0.332) total time= 1.8min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=2000;, score=(train=-0.199, test=-0.312) total time= 1.8min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=1000;, score=(train=-0.200, test=-0.293) total time=  53.7s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=1000;, score=(train=-0.199, test=-0.307) total time=  53.3s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=2000;, score=(train=-0.198, test=-0.314) total time= 1.9min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=2000;, score=(train=-0.200, test=-0.294) total time= 1.8min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=2000;, score=(train=-0.199, test=-0.307) total time= 1.9min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=1200;, score=(train=-0.195, test=-0.333) total time= 1.1min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=1200;, score=(train=-0.199, test=-0.312) total time= 1.1min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=1200;, score=(train=-0.198, test=-0.314) total time= 1.1min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=1200;, score=(train=-0.201, test=-0.294) total time= 1.1min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=1200;, score=(train=-0.199, test=-0.307) total time= 1.1min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=1400;, score=(train=-0.195, test=-0.332) total time= 1.3min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=1400;, score=(train=-0.199, test=-0.312) total time= 1.2min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=1400;, score=(train=-0.198, test=-0.315) total time= 1.2min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=1400;, score=(train=-0.200, test=-0.293) total time= 1.3min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=1400;, score=(train=-0.200, test=-0.307) total time= 1.3min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=1600;, score=(train=-0.195, test=-0.333) total time= 1.5min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=1600;, score=(train=-0.199, test=-0.311) total time= 1.5min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=1600;, score=(train=-0.198, test=-0.313) total time= 1.5min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=1600;, score=(train=-0.200, test=-0.294) total time= 1.5min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=1600;, score=(train=-0.199, test=-0.306) total time= 1.4min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=1800;, score=(train=-0.195, test=-0.332) total time= 1.7min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=1800;, score=(train=-0.198, test=-0.311) total time= 1.6min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=1800;, score=(train=-0.200, test=-0.294) total time= 1.6min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=1800;, score=(train=-0.198, test=-0.314) total time= 1.7min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=5, min_samples_split=8, n_estimators=1000;, score=(train=-0.195, test=-0.332) total time=  54.8s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=5, min_samples_split=8, n_estimators=1000;, score=(train=-0.199, test=-0.312) total time=  54.5s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=1800;, score=(train=-0.200, test=-0.307) total time= 1.6min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=5, min_samples_split=8, n_estimators=1000;, score=(train=-0.198, test=-0.314) total time=  53.9s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=2000;, score=(train=-0.195, test=-0.333) total time= 1.9min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=2000;, score=(train=-0.199, test=-0.312) total time= 1.9min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=5, min_samples_split=8, n_estimators=1000;, score=(train=-0.200, test=-0.294) total time=  55.2s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=2000;, score=(train=-0.198, test=-0.314) total time= 1.8min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=2000;, score=(train=-0.200, test=-0.294) total time= 1.8min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=5, min_samples_split=8, n_estimators=1000;, score=(train=-0.199, test=-0.308) total time=  55.1s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=2000;, score=(train=-0.199, test=-0.307) total time= 1.8min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=5, min_samples_split=8, n_estimators=1200;, score=(train=-0.195, test=-0.333) total time= 1.1min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=5, min_samples_split=8, n_estimators=1200;, score=(train=-0.199, test=-0.311) total time= 1.1min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=5, min_samples_split=8, n_estimators=1200;, score=(train=-0.198, test=-0.313) total time= 1.1min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=5, min_samples_split=8, n_estimators=1200;, score=(train=-0.200, test=-0.293) total time= 1.1min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=5, min_samples_split=8, n_estimators=1200;, score=(train=-0.199, test=-0.306) total time= 1.1min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=5, min_samples_split=8, n_estimators=1400;, score=(train=-0.199, test=-0.311) total time= 1.3min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=5, min_samples_split=8, n_estimators=1400;, score=(train=-0.195, test=-0.333) total time= 1.3min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=5, min_samples_split=8, n_estimators=1400;, score=(train=-0.198, test=-0.314) total time= 1.3min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=5, min_samples_split=8, n_estimators=1400;, score=(train=-0.200, test=-0.294) total time= 1.3min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=5, min_samples_split=8, n_estimators=1400;, score=(train=-0.199, test=-0.307) total time= 1.3min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=5, min_samples_split=8, n_estimators=1600;, score=(train=-0.195, test=-0.332) total time= 1.4min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=5, min_samples_split=8, n_estimators=1600;, score=(train=-0.199, test=-0.312) total time= 1.4min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=5, min_samples_split=8, n_estimators=1600;, score=(train=-0.198, test=-0.314) total time= 1.4min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=5, min_samples_split=8, n_estimators=1600;, score=(train=-0.200, test=-0.294) total time= 1.5min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=5, min_samples_split=8, n_estimators=1600;, score=(train=-0.199, test=-0.307) total time= 1.5min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=5, min_samples_split=8, n_estimators=1800;, score=(train=-0.195, test=-0.333) total time= 1.7min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=5, min_samples_split=8, n_estimators=1800;, score=(train=-0.199, test=-0.311) total time= 1.7min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=5, min_samples_split=8, n_estimators=1800;, score=(train=-0.200, test=-0.293) total time= 1.6min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=5, min_samples_split=8, n_estimators=1800;, score=(train=-0.198, test=-0.314) total time= 1.7min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=5, min_samples_split=8, n_estimators=1800;, score=(train=-0.199, test=-0.307) total time= 1.6min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=5, min_samples_split=11, n_estimators=1000;, score=(train=-0.199, test=-0.333) total time=  56.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=5, min_samples_split=11, n_estimators=1000;, score=(train=-0.202, test=-0.310) total time=  54.6s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=5, min_samples_split=8, n_estimators=2000;, score=(train=-0.195, test=-0.332) total time= 1.8min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=5, min_samples_split=8, n_estimators=2000;, score=(train=-0.199, test=-0.312) total time= 1.8min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=5, min_samples_split=11, n_estimators=1000;, score=(train=-0.201, test=-0.314) total time=  55.9s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=5, min_samples_split=8, n_estimators=2000;, score=(train=-0.198, test=-0.314) total time= 1.8min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=5, min_samples_split=8, n_estimators=2000;, score=(train=-0.200, test=-0.294) total time= 1.8min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=5, min_samples_split=11, n_estimators=1000;, score=(train=-0.203, test=-0.293) total time=  54.5s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=5, min_samples_split=8, n_estimators=2000;, score=(train=-0.199, test=-0.307) total time= 1.8min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=5, min_samples_split=11, n_estimators=1000;, score=(train=-0.203, test=-0.307) total time=  53.2s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=5, min_samples_split=11, n_estimators=1200;, score=(train=-0.202, test=-0.313) total time= 1.1min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=5, min_samples_split=11, n_estimators=1200;, score=(train=-0.199, test=-0.332) total time= 1.1min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=5, min_samples_split=11, n_estimators=1200;, score=(train=-0.202, test=-0.314) total time= 1.1min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=5, min_samples_split=11, n_estimators=1200;, score=(train=-0.204, test=-0.294) total time= 1.1min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=5, min_samples_split=11, n_estimators=1200;, score=(train=-0.203, test=-0.307) total time= 1.1min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=5, min_samples_split=11, n_estimators=1400;, score=(train=-0.199, test=-0.333) total time= 1.3min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=5, min_samples_split=11, n_estimators=1400;, score=(train=-0.202, test=-0.312) total time= 1.3min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=5, min_samples_split=11, n_estimators=1400;, score=(train=-0.202, test=-0.314) total time= 1.2min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=5, min_samples_split=11, n_estimators=1400;, score=(train=-0.203, test=-0.306) total time= 1.3min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=5, min_samples_split=11, n_estimators=1400;, score=(train=-0.204, test=-0.294) total time= 1.3min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=5, min_samples_split=11, n_estimators=1600;, score=(train=-0.202, test=-0.312) total time= 1.5min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=5, min_samples_split=11, n_estimators=1600;, score=(train=-0.199, test=-0.332) total time= 1.5min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=5, min_samples_split=11, n_estimators=1600;, score=(train=-0.202, test=-0.314) total time= 1.4min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=5, min_samples_split=11, n_estimators=1600;, score=(train=-0.204, test=-0.294) total time= 1.4min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=5, min_samples_split=11, n_estimators=1600;, score=(train=-0.203, test=-0.307) total time= 1.5min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=5, min_samples_split=11, n_estimators=1800;, score=(train=-0.199, test=-0.333) total time= 1.6min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=5, min_samples_split=11, n_estimators=1800;, score=(train=-0.202, test=-0.312) total time= 1.7min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=5, min_samples_split=11, n_estimators=1800;, score=(train=-0.202, test=-0.315) total time= 1.6min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=5, min_samples_split=11, n_estimators=1800;, score=(train=-0.204, test=-0.294) total time= 1.7min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=5, min_samples_split=11, n_estimators=1800;, score=(train=-0.203, test=-0.306) total time= 1.6min\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=5, min_samples_split=11, n_estimators=2000;, score=(train=-0.199, test=-0.333) total time= 1.8min\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=5, min_samples_split=11, n_estimators=2000;, score=(train=-0.202, test=-0.312) total time= 1.8min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=(train=-0.121, test=-0.333) total time= 1.2min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=(train=-0.122, test=-0.312) total time= 1.2min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=(train=-0.121, test=-0.315) total time= 1.2min\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=5, min_samples_split=11, n_estimators=2000;, score=(train=-0.201, test=-0.314) total time= 1.8min\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=5, min_samples_split=11, n_estimators=2000;, score=(train=-0.204, test=-0.294) total time= 1.9min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=(train=-0.123, test=-0.294) total time= 1.2min\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=5, min_samples_split=11, n_estimators=2000;, score=(train=-0.203, test=-0.306) total time= 1.8min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=(train=-0.122, test=-0.307) total time= 1.2min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=(train=-0.121, test=-0.333) total time= 1.4min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=(train=-0.122, test=-0.312) total time= 1.4min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=(train=-0.121, test=-0.315) total time= 1.4min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=(train=-0.123, test=-0.294) total time= 1.4min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=(train=-0.122, test=-0.306) total time= 1.4min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=1400;, score=(train=-0.120, test=-0.333) total time= 1.6min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=1400;, score=(train=-0.122, test=-0.312) total time= 1.6min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=1400;, score=(train=-0.121, test=-0.315) total time= 1.6min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=1400;, score=(train=-0.123, test=-0.294) total time= 1.6min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=1400;, score=(train=-0.122, test=-0.307) total time= 1.6min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=1600;, score=(train=-0.120, test=-0.333) total time= 1.9min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=1600;, score=(train=-0.121, test=-0.312) total time= 1.9min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=1600;, score=(train=-0.121, test=-0.315) total time= 1.8min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=1600;, score=(train=-0.123, test=-0.294) total time= 1.9min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=1600;, score=(train=-0.122, test=-0.306) total time= 1.9min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=1800;, score=(train=-0.122, test=-0.312) total time= 2.1min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=1800;, score=(train=-0.121, test=-0.333) total time= 2.1min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=1800;, score=(train=-0.121, test=-0.314) total time= 2.1min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=1800;, score=(train=-0.123, test=-0.294) total time= 2.0min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=1800;, score=(train=-0.122, test=-0.306) total time= 2.1min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=1000;, score=(train=-0.135, test=-0.333) total time= 1.1min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=1000;, score=(train=-0.137, test=-0.312) total time= 1.1min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=2000;, score=(train=-0.121, test=-0.333) total time= 2.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pawel/.pyenv/versions/university/lib/python3.13/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=2000;, score=(train=-0.122, test=-0.312) total time= 2.3min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=1000;, score=(train=-0.136, test=-0.315) total time= 1.1min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=1000;, score=(train=-0.138, test=-0.295) total time= 1.1min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=2000;, score=(train=-0.121, test=-0.315) total time= 2.3min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=2000;, score=(train=-0.122, test=-0.294) total time= 2.3min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=1000;, score=(train=-0.137, test=-0.307) total time= 1.1min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=2000;, score=(train=-0.121, test=-0.306) total time= 2.3min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=1200;, score=(train=-0.135, test=-0.332) total time= 1.3min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=1200;, score=(train=-0.137, test=-0.311) total time= 1.3min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=1200;, score=(train=-0.136, test=-0.316) total time= 1.3min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=1200;, score=(train=-0.138, test=-0.296) total time= 1.3min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=1200;, score=(train=-0.137, test=-0.306) total time= 1.3min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=1400;, score=(train=-0.135, test=-0.334) total time= 1.6min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=1400;, score=(train=-0.137, test=-0.312) total time= 1.5min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=1400;, score=(train=-0.137, test=-0.315) total time= 1.5min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=1400;, score=(train=-0.139, test=-0.294) total time= 1.6min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=1400;, score=(train=-0.138, test=-0.307) total time= 1.5min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=1600;, score=(train=-0.135, test=-0.333) total time= 1.8min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=1600;, score=(train=-0.137, test=-0.311) total time= 1.8min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=1600;, score=(train=-0.137, test=-0.315) total time= 1.8min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=1600;, score=(train=-0.138, test=-0.294) total time= 1.8min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=1600;, score=(train=-0.137, test=-0.306) total time= 1.8min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=1800;, score=(train=-0.137, test=-0.312) total time= 2.0min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=1800;, score=(train=-0.135, test=-0.333) total time= 2.0min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=1800;, score=(train=-0.136, test=-0.314) total time= 2.0min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=1800;, score=(train=-0.138, test=-0.294) total time= 2.0min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=1800;, score=(train=-0.137, test=-0.307) total time= 2.0min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=1, min_samples_split=8, n_estimators=1000;, score=(train=-0.153, test=-0.333) total time= 1.1min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=1, min_samples_split=8, n_estimators=1000;, score=(train=-0.155, test=-0.312) total time= 1.1min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=2000;, score=(train=-0.135, test=-0.334) total time= 2.2min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=2000;, score=(train=-0.137, test=-0.312) total time= 2.2min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=1, min_samples_split=8, n_estimators=1000;, score=(train=-0.155, test=-0.315) total time= 1.1min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=1, min_samples_split=8, n_estimators=1000;, score=(train=-0.157, test=-0.294) total time= 1.1min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=2000;, score=(train=-0.137, test=-0.315) total time= 2.2min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=1, min_samples_split=8, n_estimators=1000;, score=(train=-0.155, test=-0.306) total time= 1.1min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=2000;, score=(train=-0.138, test=-0.295) total time= 2.2min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=2000;, score=(train=-0.137, test=-0.307) total time= 2.2min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=1, min_samples_split=8, n_estimators=1200;, score=(train=-0.155, test=-0.313) total time= 1.3min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=1, min_samples_split=8, n_estimators=1200;, score=(train=-0.153, test=-0.333) total time= 1.3min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=1, min_samples_split=8, n_estimators=1200;, score=(train=-0.155, test=-0.316) total time= 1.3min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=1, min_samples_split=8, n_estimators=1200;, score=(train=-0.157, test=-0.295) total time= 1.3min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=1, min_samples_split=8, n_estimators=1200;, score=(train=-0.155, test=-0.306) total time= 1.3min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=1, min_samples_split=8, n_estimators=1400;, score=(train=-0.152, test=-0.333) total time= 1.5min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=1, min_samples_split=8, n_estimators=1400;, score=(train=-0.155, test=-0.312) total time= 1.5min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=1, min_samples_split=8, n_estimators=1400;, score=(train=-0.155, test=-0.316) total time= 1.5min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=1, min_samples_split=8, n_estimators=1400;, score=(train=-0.156, test=-0.294) total time= 1.5min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=1, min_samples_split=8, n_estimators=1400;, score=(train=-0.156, test=-0.307) total time= 1.5min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=1, min_samples_split=8, n_estimators=1600;, score=(train=-0.152, test=-0.333) total time= 1.8min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=1, min_samples_split=8, n_estimators=1600;, score=(train=-0.155, test=-0.312) total time= 1.7min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=1, min_samples_split=8, n_estimators=1600;, score=(train=-0.155, test=-0.315) total time= 1.7min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=1, min_samples_split=8, n_estimators=1600;, score=(train=-0.156, test=-0.294) total time= 1.7min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=1, min_samples_split=8, n_estimators=1600;, score=(train=-0.156, test=-0.308) total time= 1.8min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=1, min_samples_split=8, n_estimators=1800;, score=(train=-0.152, test=-0.333) total time= 2.0min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=1, min_samples_split=8, n_estimators=1800;, score=(train=-0.155, test=-0.312) total time= 2.0min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=1, min_samples_split=8, n_estimators=1800;, score=(train=-0.155, test=-0.316) total time= 2.0min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=1, min_samples_split=8, n_estimators=1800;, score=(train=-0.155, test=-0.306) total time= 1.9min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=1, min_samples_split=11, n_estimators=1000;, score=(train=-0.168, test=-0.333) total time= 1.1min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=1, min_samples_split=8, n_estimators=1800;, score=(train=-0.157, test=-0.295) total time= 2.0min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=1, min_samples_split=11, n_estimators=1000;, score=(train=-0.171, test=-0.312) total time= 1.1min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=1, min_samples_split=11, n_estimators=1000;, score=(train=-0.171, test=-0.316) total time= 1.1min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=1, min_samples_split=8, n_estimators=2000;, score=(train=-0.153, test=-0.334) total time= 2.2min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=1, min_samples_split=8, n_estimators=2000;, score=(train=-0.155, test=-0.312) total time= 2.2min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=1, min_samples_split=11, n_estimators=1000;, score=(train=-0.172, test=-0.294) total time= 1.1min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=1, min_samples_split=8, n_estimators=2000;, score=(train=-0.155, test=-0.316) total time= 2.2min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=1, min_samples_split=8, n_estimators=2000;, score=(train=-0.157, test=-0.294) total time= 2.2min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=1, min_samples_split=11, n_estimators=1000;, score=(train=-0.172, test=-0.306) total time= 1.1min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=1, min_samples_split=8, n_estimators=2000;, score=(train=-0.155, test=-0.307) total time= 2.2min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=1, min_samples_split=11, n_estimators=1200;, score=(train=-0.168, test=-0.333) total time= 1.3min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=1, min_samples_split=11, n_estimators=1200;, score=(train=-0.171, test=-0.316) total time= 1.3min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=1, min_samples_split=11, n_estimators=1200;, score=(train=-0.171, test=-0.312) total time= 1.3min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=1, min_samples_split=11, n_estimators=1200;, score=(train=-0.173, test=-0.294) total time= 1.3min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=1, min_samples_split=11, n_estimators=1200;, score=(train=-0.172, test=-0.308) total time= 1.3min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=1, min_samples_split=11, n_estimators=1400;, score=(train=-0.168, test=-0.334) total time= 1.5min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=1, min_samples_split=11, n_estimators=1400;, score=(train=-0.171, test=-0.312) total time= 1.5min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=1, min_samples_split=11, n_estimators=1400;, score=(train=-0.171, test=-0.316) total time= 1.5min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=1, min_samples_split=11, n_estimators=1400;, score=(train=-0.172, test=-0.294) total time= 1.5min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=1, min_samples_split=11, n_estimators=1400;, score=(train=-0.171, test=-0.307) total time= 1.5min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=1, min_samples_split=11, n_estimators=1600;, score=(train=-0.168, test=-0.333) total time= 1.7min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=1, min_samples_split=11, n_estimators=1600;, score=(train=-0.171, test=-0.313) total time= 1.7min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=1, min_samples_split=11, n_estimators=1600;, score=(train=-0.171, test=-0.316) total time= 1.7min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=1, min_samples_split=11, n_estimators=1600;, score=(train=-0.172, test=-0.307) total time= 1.7min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=1, min_samples_split=11, n_estimators=1600;, score=(train=-0.173, test=-0.294) total time= 1.7min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=1, min_samples_split=11, n_estimators=1800;, score=(train=-0.168, test=-0.333) total time= 1.9min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=1, min_samples_split=11, n_estimators=1800;, score=(train=-0.171, test=-0.312) total time= 1.9min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=1, min_samples_split=11, n_estimators=1800;, score=(train=-0.172, test=-0.316) total time= 1.9min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=1, min_samples_split=11, n_estimators=1800;, score=(train=-0.173, test=-0.295) total time= 1.9min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1000;, score=(train=-0.156, test=-0.333) total time= 1.0min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1000;, score=(train=-0.160, test=-0.311) total time=  59.8s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=1, min_samples_split=11, n_estimators=1800;, score=(train=-0.172, test=-0.307) total time= 1.9min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1000;, score=(train=-0.159, test=-0.313) total time=  59.9s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1000;, score=(train=-0.162, test=-0.292) total time= 1.0min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=1, min_samples_split=11, n_estimators=2000;, score=(train=-0.168, test=-0.333) total time= 2.2min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=1, min_samples_split=11, n_estimators=2000;, score=(train=-0.171, test=-0.312) total time= 2.2min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=1, min_samples_split=11, n_estimators=2000;, score=(train=-0.171, test=-0.316) total time= 2.1min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1000;, score=(train=-0.160, test=-0.307) total time= 1.0min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=1, min_samples_split=11, n_estimators=2000;, score=(train=-0.173, test=-0.294) total time= 2.1min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1200;, score=(train=-0.157, test=-0.332) total time= 1.2min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=1, min_samples_split=11, n_estimators=2000;, score=(train=-0.172, test=-0.308) total time= 2.2min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1200;, score=(train=-0.160, test=-0.312) total time= 1.2min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1200;, score=(train=-0.159, test=-0.314) total time= 1.2min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1200;, score=(train=-0.161, test=-0.293) total time= 1.2min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1200;, score=(train=-0.160, test=-0.306) total time= 1.2min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1400;, score=(train=-0.160, test=-0.311) total time= 1.4min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1400;, score=(train=-0.159, test=-0.313) total time= 1.4min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1400;, score=(train=-0.157, test=-0.333) total time= 1.4min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1400;, score=(train=-0.161, test=-0.293) total time= 1.4min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1400;, score=(train=-0.160, test=-0.306) total time= 1.4min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1600;, score=(train=-0.156, test=-0.333) total time= 1.6min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1600;, score=(train=-0.160, test=-0.311) total time= 1.6min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1600;, score=(train=-0.159, test=-0.313) total time= 1.6min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1600;, score=(train=-0.161, test=-0.294) total time= 1.6min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1600;, score=(train=-0.160, test=-0.306) total time= 1.6min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1800;, score=(train=-0.157, test=-0.332) total time= 1.8min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1800;, score=(train=-0.160, test=-0.311) total time= 1.8min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1800;, score=(train=-0.159, test=-0.313) total time= 1.8min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1800;, score=(train=-0.161, test=-0.294) total time= 1.8min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=1800;, score=(train=-0.160, test=-0.306) total time= 1.8min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=3, min_samples_split=5, n_estimators=1000;, score=(train=-0.156, test=-0.332) total time= 1.0min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=3, min_samples_split=5, n_estimators=1000;, score=(train=-0.160, test=-0.311) total time=  59.9s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=3, min_samples_split=5, n_estimators=1000;, score=(train=-0.159, test=-0.313) total time=  58.9s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=2000;, score=(train=-0.156, test=-0.333) total time= 2.0min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=2000;, score=(train=-0.160, test=-0.311) total time= 2.0min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=3, min_samples_split=5, n_estimators=1000;, score=(train=-0.161, test=-0.294) total time= 1.0min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=2000;, score=(train=-0.159, test=-0.313) total time= 2.0min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=3, min_samples_split=5, n_estimators=1000;, score=(train=-0.160, test=-0.307) total time=  59.8s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=2000;, score=(train=-0.161, test=-0.293) total time= 2.0min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=2000;, score=(train=-0.160, test=-0.306) total time= 2.0min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=3, min_samples_split=5, n_estimators=1200;, score=(train=-0.160, test=-0.312) total time= 1.2min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=3, min_samples_split=5, n_estimators=1200;, score=(train=-0.156, test=-0.332) total time= 1.2min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=3, min_samples_split=5, n_estimators=1200;, score=(train=-0.159, test=-0.313) total time= 1.2min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=3, min_samples_split=5, n_estimators=1200;, score=(train=-0.161, test=-0.294) total time= 1.2min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=3, min_samples_split=5, n_estimators=1200;, score=(train=-0.160, test=-0.307) total time= 1.2min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=3, min_samples_split=5, n_estimators=1400;, score=(train=-0.157, test=-0.332) total time= 1.4min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=3, min_samples_split=5, n_estimators=1400;, score=(train=-0.160, test=-0.312) total time= 1.4min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=3, min_samples_split=5, n_estimators=1400;, score=(train=-0.159, test=-0.313) total time= 1.4min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=3, min_samples_split=5, n_estimators=1400;, score=(train=-0.161, test=-0.293) total time= 1.4min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=3, min_samples_split=5, n_estimators=1400;, score=(train=-0.161, test=-0.306) total time= 1.4min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=3, min_samples_split=5, n_estimators=1600;, score=(train=-0.157, test=-0.332) total time= 1.6min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=3, min_samples_split=5, n_estimators=1600;, score=(train=-0.160, test=-0.312) total time= 1.6min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=3, min_samples_split=5, n_estimators=1600;, score=(train=-0.159, test=-0.314) total time= 1.6min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=3, min_samples_split=5, n_estimators=1600;, score=(train=-0.160, test=-0.306) total time= 1.6min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=3, min_samples_split=5, n_estimators=1600;, score=(train=-0.161, test=-0.294) total time= 1.6min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=3, min_samples_split=5, n_estimators=1800;, score=(train=-0.156, test=-0.332) total time= 1.8min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=3, min_samples_split=5, n_estimators=1800;, score=(train=-0.160, test=-0.311) total time= 1.9min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=3, min_samples_split=5, n_estimators=1800;, score=(train=-0.159, test=-0.313) total time= 1.8min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=3, min_samples_split=5, n_estimators=1800;, score=(train=-0.161, test=-0.292) total time= 1.8min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=3, min_samples_split=8, n_estimators=1000;, score=(train=-0.171, test=-0.311) total time=  58.5s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=3, min_samples_split=8, n_estimators=1000;, score=(train=-0.167, test=-0.333) total time=  59.9s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=3, min_samples_split=5, n_estimators=1800;, score=(train=-0.160, test=-0.306) total time= 1.8min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=3, min_samples_split=8, n_estimators=1000;, score=(train=-0.170, test=-0.314) total time=  58.2s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=3, min_samples_split=5, n_estimators=2000;, score=(train=-0.156, test=-0.333) total time= 2.0min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=3, min_samples_split=8, n_estimators=1000;, score=(train=-0.172, test=-0.293) total time=  59.5s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=3, min_samples_split=5, n_estimators=2000;, score=(train=-0.160, test=-0.312) total time= 2.0min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=3, min_samples_split=5, n_estimators=2000;, score=(train=-0.159, test=-0.313) total time= 2.0min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=3, min_samples_split=5, n_estimators=2000;, score=(train=-0.161, test=-0.293) total time= 2.0min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=3, min_samples_split=8, n_estimators=1000;, score=(train=-0.172, test=-0.306) total time=  58.5s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=3, min_samples_split=5, n_estimators=2000;, score=(train=-0.160, test=-0.305) total time= 2.0min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=3, min_samples_split=8, n_estimators=1200;, score=(train=-0.167, test=-0.332) total time= 1.2min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=3, min_samples_split=8, n_estimators=1200;, score=(train=-0.171, test=-0.312) total time= 1.2min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=3, min_samples_split=8, n_estimators=1200;, score=(train=-0.170, test=-0.314) total time= 1.2min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=3, min_samples_split=8, n_estimators=1200;, score=(train=-0.172, test=-0.293) total time= 1.2min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=3, min_samples_split=8, n_estimators=1200;, score=(train=-0.171, test=-0.306) total time= 1.2min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=3, min_samples_split=8, n_estimators=1400;, score=(train=-0.168, test=-0.332) total time= 1.4min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=3, min_samples_split=8, n_estimators=1400;, score=(train=-0.171, test=-0.311) total time= 1.4min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=3, min_samples_split=8, n_estimators=1400;, score=(train=-0.170, test=-0.314) total time= 1.4min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=3, min_samples_split=8, n_estimators=1400;, score=(train=-0.172, test=-0.293) total time= 1.4min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=3, min_samples_split=8, n_estimators=1400;, score=(train=-0.171, test=-0.306) total time= 1.4min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=3, min_samples_split=8, n_estimators=1600;, score=(train=-0.167, test=-0.333) total time= 1.6min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=3, min_samples_split=8, n_estimators=1600;, score=(train=-0.171, test=-0.311) total time= 1.6min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=3, min_samples_split=8, n_estimators=1600;, score=(train=-0.170, test=-0.314) total time= 1.6min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=3, min_samples_split=8, n_estimators=1600;, score=(train=-0.172, test=-0.293) total time= 1.6min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=3, min_samples_split=8, n_estimators=1600;, score=(train=-0.171, test=-0.306) total time= 1.6min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=3, min_samples_split=8, n_estimators=1800;, score=(train=-0.167, test=-0.332) total time= 1.8min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=3, min_samples_split=8, n_estimators=1800;, score=(train=-0.171, test=-0.311) total time= 1.8min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=3, min_samples_split=8, n_estimators=1800;, score=(train=-0.170, test=-0.313) total time= 1.8min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=3, min_samples_split=8, n_estimators=1800;, score=(train=-0.172, test=-0.293) total time= 1.8min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=3, min_samples_split=8, n_estimators=1800;, score=(train=-0.171, test=-0.306) total time= 1.8min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=3, min_samples_split=11, n_estimators=1000;, score=(train=-0.182, test=-0.333) total time= 1.0min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=3, min_samples_split=11, n_estimators=1000;, score=(train=-0.186, test=-0.311) total time=  59.4s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=3, min_samples_split=11, n_estimators=1000;, score=(train=-0.186, test=-0.313) total time=  59.1s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=3, min_samples_split=8, n_estimators=2000;, score=(train=-0.167, test=-0.332) total time= 2.0min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=3, min_samples_split=8, n_estimators=2000;, score=(train=-0.171, test=-0.311) total time= 2.0min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=3, min_samples_split=11, n_estimators=1000;, score=(train=-0.187, test=-0.294) total time=  59.4s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=3, min_samples_split=8, n_estimators=2000;, score=(train=-0.170, test=-0.314) total time= 2.0min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=3, min_samples_split=8, n_estimators=2000;, score=(train=-0.172, test=-0.294) total time= 2.0min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=3, min_samples_split=11, n_estimators=1000;, score=(train=-0.187, test=-0.307) total time=  57.7s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=3, min_samples_split=8, n_estimators=2000;, score=(train=-0.171, test=-0.306) total time= 2.0min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=3, min_samples_split=11, n_estimators=1200;, score=(train=-0.186, test=-0.312) total time= 1.2min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=3, min_samples_split=11, n_estimators=1200;, score=(train=-0.182, test=-0.333) total time= 1.2min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=3, min_samples_split=11, n_estimators=1200;, score=(train=-0.185, test=-0.314) total time= 1.2min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=3, min_samples_split=11, n_estimators=1200;, score=(train=-0.187, test=-0.293) total time= 1.2min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=3, min_samples_split=11, n_estimators=1200;, score=(train=-0.187, test=-0.306) total time= 1.2min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=3, min_samples_split=11, n_estimators=1400;, score=(train=-0.186, test=-0.312) total time= 1.4min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=3, min_samples_split=11, n_estimators=1400;, score=(train=-0.182, test=-0.333) total time= 1.4min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=3, min_samples_split=11, n_estimators=1400;, score=(train=-0.185, test=-0.314) total time= 1.4min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=3, min_samples_split=11, n_estimators=1400;, score=(train=-0.187, test=-0.294) total time= 1.4min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=3, min_samples_split=11, n_estimators=1400;, score=(train=-0.187, test=-0.307) total time= 1.4min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=3, min_samples_split=11, n_estimators=1600;, score=(train=-0.182, test=-0.332) total time= 1.6min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=3, min_samples_split=11, n_estimators=1600;, score=(train=-0.186, test=-0.312) total time= 1.6min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=3, min_samples_split=11, n_estimators=1600;, score=(train=-0.185, test=-0.314) total time= 1.5min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=3, min_samples_split=11, n_estimators=1600;, score=(train=-0.187, test=-0.294) total time= 1.6min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=3, min_samples_split=11, n_estimators=1600;, score=(train=-0.187, test=-0.307) total time= 1.5min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=3, min_samples_split=11, n_estimators=1800;, score=(train=-0.182, test=-0.332) total time= 1.8min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=3, min_samples_split=11, n_estimators=1800;, score=(train=-0.186, test=-0.312) total time= 1.8min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=3, min_samples_split=11, n_estimators=1800;, score=(train=-0.185, test=-0.315) total time= 1.7min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=3, min_samples_split=11, n_estimators=1800;, score=(train=-0.187, test=-0.293) total time= 1.7min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=3, min_samples_split=11, n_estimators=1800;, score=(train=-0.187, test=-0.307) total time= 1.8min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1000;, score=(train=-0.190, test=-0.333) total time=  55.4s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1000;, score=(train=-0.194, test=-0.312) total time=  55.4s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1000;, score=(train=-0.193, test=-0.314) total time=  54.4s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=3, min_samples_split=11, n_estimators=2000;, score=(train=-0.182, test=-0.333) total time= 2.0min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=3, min_samples_split=11, n_estimators=2000;, score=(train=-0.186, test=-0.312) total time= 2.0min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1000;, score=(train=-0.195, test=-0.294) total time=  55.6s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=3, min_samples_split=11, n_estimators=2000;, score=(train=-0.185, test=-0.314) total time= 2.0min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1000;, score=(train=-0.195, test=-0.307) total time=  54.8s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=3, min_samples_split=11, n_estimators=2000;, score=(train=-0.187, test=-0.294) total time= 2.0min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=3, min_samples_split=11, n_estimators=2000;, score=(train=-0.186, test=-0.307) total time= 2.0min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1200;, score=(train=-0.190, test=-0.334) total time= 1.1min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1200;, score=(train=-0.194, test=-0.311) total time= 1.1min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1200;, score=(train=-0.193, test=-0.314) total time= 1.1min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1200;, score=(train=-0.196, test=-0.294) total time= 1.1min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1200;, score=(train=-0.195, test=-0.308) total time= 1.1min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1400;, score=(train=-0.190, test=-0.332) total time= 1.3min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1400;, score=(train=-0.194, test=-0.312) total time= 1.3min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1400;, score=(train=-0.194, test=-0.314) total time= 1.3min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1400;, score=(train=-0.195, test=-0.294) total time= 1.3min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1400;, score=(train=-0.195, test=-0.306) total time= 1.3min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1600;, score=(train=-0.190, test=-0.332) total time= 1.5min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1600;, score=(train=-0.194, test=-0.311) total time= 1.5min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1600;, score=(train=-0.193, test=-0.314) total time= 1.5min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1600;, score=(train=-0.195, test=-0.295) total time= 1.5min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1600;, score=(train=-0.195, test=-0.307) total time= 1.4min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1800;, score=(train=-0.190, test=-0.333) total time= 1.7min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1800;, score=(train=-0.194, test=-0.311) total time= 1.7min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1800;, score=(train=-0.194, test=-0.314) total time= 1.6min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1800;, score=(train=-0.195, test=-0.293) total time= 1.7min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=5, min_samples_split=5, n_estimators=1000;, score=(train=-0.194, test=-0.312) total time=  55.2s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=5, min_samples_split=5, n_estimators=1000;, score=(train=-0.190, test=-0.332) total time=  56.2s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=1800;, score=(train=-0.195, test=-0.307) total time= 1.7min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=5, min_samples_split=5, n_estimators=1000;, score=(train=-0.193, test=-0.314) total time=  54.7s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=2000;, score=(train=-0.194, test=-0.311) total time= 1.8min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=5, min_samples_split=5, n_estimators=1000;, score=(train=-0.195, test=-0.295) total time=  54.6s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=2000;, score=(train=-0.190, test=-0.332) total time= 1.9min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=2000;, score=(train=-0.193, test=-0.314) total time= 1.8min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=5, min_samples_split=5, n_estimators=1000;, score=(train=-0.195, test=-0.307) total time=  55.4s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=2000;, score=(train=-0.195, test=-0.294) total time= 1.8min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=2000;, score=(train=-0.195, test=-0.307) total time= 1.9min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=5, min_samples_split=5, n_estimators=1200;, score=(train=-0.190, test=-0.333) total time= 1.1min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=5, min_samples_split=5, n_estimators=1200;, score=(train=-0.193, test=-0.314) total time= 1.1min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=5, min_samples_split=5, n_estimators=1200;, score=(train=-0.194, test=-0.312) total time= 1.1min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=5, min_samples_split=5, n_estimators=1200;, score=(train=-0.195, test=-0.294) total time= 1.1min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=5, min_samples_split=5, n_estimators=1200;, score=(train=-0.195, test=-0.307) total time= 1.1min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=5, min_samples_split=5, n_estimators=1400;, score=(train=-0.194, test=-0.312) total time= 1.3min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=5, min_samples_split=5, n_estimators=1400;, score=(train=-0.190, test=-0.333) total time= 1.3min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=5, min_samples_split=5, n_estimators=1400;, score=(train=-0.193, test=-0.314) total time= 1.3min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=5, min_samples_split=5, n_estimators=1400;, score=(train=-0.195, test=-0.293) total time= 1.3min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=5, min_samples_split=5, n_estimators=1400;, score=(train=-0.195, test=-0.307) total time= 1.3min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=5, min_samples_split=5, n_estimators=1600;, score=(train=-0.190, test=-0.333) total time= 1.5min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=5, min_samples_split=5, n_estimators=1600;, score=(train=-0.194, test=-0.312) total time= 1.5min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=5, min_samples_split=5, n_estimators=1600;, score=(train=-0.195, test=-0.294) total time= 1.5min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=5, min_samples_split=5, n_estimators=1600;, score=(train=-0.195, test=-0.307) total time= 1.5min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=5, min_samples_split=5, n_estimators=1600;, score=(train=-0.193, test=-0.314) total time= 1.5min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=5, min_samples_split=5, n_estimators=1800;, score=(train=-0.190, test=-0.333) total time= 1.7min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=5, min_samples_split=5, n_estimators=1800;, score=(train=-0.194, test=-0.312) total time= 1.7min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=5, min_samples_split=5, n_estimators=1800;, score=(train=-0.193, test=-0.314) total time= 1.6min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=5, min_samples_split=5, n_estimators=1800;, score=(train=-0.195, test=-0.294) total time= 1.7min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=5, min_samples_split=5, n_estimators=1800;, score=(train=-0.195, test=-0.308) total time= 1.6min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=5, min_samples_split=8, n_estimators=1000;, score=(train=-0.194, test=-0.311) total time=  55.9s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=5, min_samples_split=8, n_estimators=1000;, score=(train=-0.190, test=-0.333) total time=  56.9s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=5, min_samples_split=8, n_estimators=1000;, score=(train=-0.193, test=-0.314) total time=  56.2s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=5, min_samples_split=5, n_estimators=2000;, score=(train=-0.190, test=-0.332) total time= 1.8min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=5, min_samples_split=8, n_estimators=1000;, score=(train=-0.195, test=-0.294) total time=  55.0s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=5, min_samples_split=5, n_estimators=2000;, score=(train=-0.194, test=-0.311) total time= 1.8min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=5, min_samples_split=5, n_estimators=2000;, score=(train=-0.193, test=-0.314) total time= 1.8min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=5, min_samples_split=5, n_estimators=2000;, score=(train=-0.195, test=-0.294) total time= 1.8min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=5, min_samples_split=8, n_estimators=1000;, score=(train=-0.194, test=-0.307) total time=  54.4s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=5, min_samples_split=5, n_estimators=2000;, score=(train=-0.195, test=-0.307) total time= 1.8min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=5, min_samples_split=8, n_estimators=1200;, score=(train=-0.194, test=-0.312) total time= 1.1min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=5, min_samples_split=8, n_estimators=1200;, score=(train=-0.190, test=-0.333) total time= 1.1min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=5, min_samples_split=8, n_estimators=1200;, score=(train=-0.193, test=-0.313) total time= 1.1min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=5, min_samples_split=8, n_estimators=1200;, score=(train=-0.195, test=-0.294) total time= 1.1min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=5, min_samples_split=8, n_estimators=1200;, score=(train=-0.194, test=-0.307) total time= 1.1min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=5, min_samples_split=8, n_estimators=1400;, score=(train=-0.190, test=-0.333) total time= 1.3min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=5, min_samples_split=8, n_estimators=1400;, score=(train=-0.193, test=-0.314) total time= 1.3min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=5, min_samples_split=8, n_estimators=1400;, score=(train=-0.194, test=-0.311) total time= 1.3min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=5, min_samples_split=8, n_estimators=1400;, score=(train=-0.195, test=-0.295) total time= 1.3min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=5, min_samples_split=8, n_estimators=1400;, score=(train=-0.195, test=-0.307) total time= 1.3min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=5, min_samples_split=8, n_estimators=1600;, score=(train=-0.190, test=-0.333) total time= 1.5min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=5, min_samples_split=8, n_estimators=1600;, score=(train=-0.194, test=-0.312) total time= 1.5min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=5, min_samples_split=8, n_estimators=1600;, score=(train=-0.193, test=-0.314) total time= 1.4min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=5, min_samples_split=8, n_estimators=1600;, score=(train=-0.196, test=-0.293) total time= 1.5min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=5, min_samples_split=8, n_estimators=1600;, score=(train=-0.195, test=-0.307) total time= 1.5min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=5, min_samples_split=8, n_estimators=1800;, score=(train=-0.189, test=-0.332) total time= 1.7min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=5, min_samples_split=8, n_estimators=1800;, score=(train=-0.194, test=-0.312) total time= 1.7min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=5, min_samples_split=8, n_estimators=1800;, score=(train=-0.193, test=-0.314) total time= 1.7min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=5, min_samples_split=8, n_estimators=1800;, score=(train=-0.195, test=-0.307) total time= 1.6min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=5, min_samples_split=8, n_estimators=1800;, score=(train=-0.195, test=-0.294) total time= 1.7min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=5, min_samples_split=11, n_estimators=1000;, score=(train=-0.193, test=-0.332) total time=  56.4s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=5, min_samples_split=11, n_estimators=1000;, score=(train=-0.198, test=-0.311) total time=  55.0s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=5, min_samples_split=11, n_estimators=1000;, score=(train=-0.197, test=-0.314) total time=  54.6s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=5, min_samples_split=8, n_estimators=2000;, score=(train=-0.194, test=-0.312) total time= 1.8min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=5, min_samples_split=8, n_estimators=2000;, score=(train=-0.190, test=-0.333) total time= 1.9min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=5, min_samples_split=11, n_estimators=1000;, score=(train=-0.199, test=-0.294) total time=  56.0s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=5, min_samples_split=8, n_estimators=2000;, score=(train=-0.193, test=-0.314) total time= 1.8min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=5, min_samples_split=8, n_estimators=2000;, score=(train=-0.195, test=-0.294) total time= 1.8min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=5, min_samples_split=8, n_estimators=2000;, score=(train=-0.195, test=-0.307) total time= 1.8min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=5, min_samples_split=11, n_estimators=1000;, score=(train=-0.199, test=-0.307) total time=  54.8s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=5, min_samples_split=11, n_estimators=1200;, score=(train=-0.193, test=-0.333) total time= 1.1min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=5, min_samples_split=11, n_estimators=1200;, score=(train=-0.198, test=-0.311) total time= 1.1min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=5, min_samples_split=11, n_estimators=1200;, score=(train=-0.197, test=-0.314) total time= 1.1min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=5, min_samples_split=11, n_estimators=1200;, score=(train=-0.199, test=-0.294) total time= 1.1min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=5, min_samples_split=11, n_estimators=1200;, score=(train=-0.199, test=-0.307) total time= 1.1min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=5, min_samples_split=11, n_estimators=1400;, score=(train=-0.193, test=-0.334) total time= 1.3min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=5, min_samples_split=11, n_estimators=1400;, score=(train=-0.198, test=-0.311) total time= 1.3min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=5, min_samples_split=11, n_estimators=1400;, score=(train=-0.197, test=-0.314) total time= 1.3min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=5, min_samples_split=11, n_estimators=1400;, score=(train=-0.199, test=-0.294) total time= 1.3min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=5, min_samples_split=11, n_estimators=1400;, score=(train=-0.199, test=-0.307) total time= 1.3min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=5, min_samples_split=11, n_estimators=1600;, score=(train=-0.193, test=-0.333) total time= 1.5min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=5, min_samples_split=11, n_estimators=1600;, score=(train=-0.198, test=-0.311) total time= 1.5min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=5, min_samples_split=11, n_estimators=1600;, score=(train=-0.197, test=-0.314) total time= 1.5min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=5, min_samples_split=11, n_estimators=1600;, score=(train=-0.199, test=-0.294) total time= 1.5min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=5, min_samples_split=11, n_estimators=1600;, score=(train=-0.199, test=-0.307) total time= 1.5min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=5, min_samples_split=11, n_estimators=1800;, score=(train=-0.193, test=-0.333) total time= 1.7min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=5, min_samples_split=11, n_estimators=1800;, score=(train=-0.198, test=-0.312) total time= 1.7min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=5, min_samples_split=11, n_estimators=1800;, score=(train=-0.197, test=-0.314) total time= 1.6min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=5, min_samples_split=11, n_estimators=1800;, score=(train=-0.199, test=-0.294) total time= 1.6min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=5, min_samples_split=11, n_estimators=1800;, score=(train=-0.199, test=-0.307) total time= 1.6min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=(train=-0.115, test=-0.333) total time= 1.2min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=(train=-0.117, test=-0.311) total time= 1.2min\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=5, min_samples_split=11, n_estimators=2000;, score=(train=-0.193, test=-0.333) total time= 1.8min\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=5, min_samples_split=11, n_estimators=2000;, score=(train=-0.198, test=-0.312) total time= 1.8min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=(train=-0.117, test=-0.315) total time= 1.2min\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=5, min_samples_split=11, n_estimators=2000;, score=(train=-0.197, test=-0.314) total time= 1.8min\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=5, min_samples_split=11, n_estimators=2000;, score=(train=-0.199, test=-0.294) total time= 1.9min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=(train=-0.117, test=-0.295) total time= 1.2min\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=5, min_samples_split=11, n_estimators=2000;, score=(train=-0.198, test=-0.307) total time= 1.8min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=(train=-0.117, test=-0.307) total time= 1.2min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=(train=-0.114, test=-0.334) total time= 1.5min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=(train=-0.117, test=-0.312) total time= 1.4min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=(train=-0.116, test=-0.315) total time= 1.4min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=(train=-0.118, test=-0.294) total time= 1.5min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=(train=-0.117, test=-0.307) total time= 1.4min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=1, min_samples_split=2, n_estimators=1400;, score=(train=-0.115, test=-0.334) total time= 1.7min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=1, min_samples_split=2, n_estimators=1400;, score=(train=-0.117, test=-0.312) total time= 1.7min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=1, min_samples_split=2, n_estimators=1400;, score=(train=-0.117, test=-0.315) total time= 1.7min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=1, min_samples_split=2, n_estimators=1400;, score=(train=-0.118, test=-0.294) total time= 1.7min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=1, min_samples_split=2, n_estimators=1400;, score=(train=-0.117, test=-0.307) total time= 1.7min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=1, min_samples_split=2, n_estimators=1600;, score=(train=-0.115, test=-0.333) total time= 2.0min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=1, min_samples_split=2, n_estimators=1600;, score=(train=-0.117, test=-0.312) total time= 2.0min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=1, min_samples_split=2, n_estimators=1600;, score=(train=-0.116, test=-0.315) total time= 1.9min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=1, min_samples_split=2, n_estimators=1600;, score=(train=-0.118, test=-0.294) total time= 1.9min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=1, min_samples_split=2, n_estimators=1600;, score=(train=-0.117, test=-0.307) total time= 1.9min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=1, min_samples_split=2, n_estimators=1800;, score=(train=-0.117, test=-0.312) total time= 2.2min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=1, min_samples_split=2, n_estimators=1800;, score=(train=-0.115, test=-0.333) total time= 2.2min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=1, min_samples_split=2, n_estimators=1800;, score=(train=-0.116, test=-0.315) total time= 2.2min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=1, min_samples_split=2, n_estimators=1800;, score=(train=-0.118, test=-0.294) total time= 2.2min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=1, min_samples_split=2, n_estimators=1800;, score=(train=-0.117, test=-0.307) total time= 2.1min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=1, min_samples_split=5, n_estimators=1000;, score=(train=-0.130, test=-0.334) total time= 1.2min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=1, min_samples_split=5, n_estimators=1000;, score=(train=-0.134, test=-0.312) total time= 1.2min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=1, min_samples_split=2, n_estimators=2000;, score=(train=-0.117, test=-0.312) total time= 2.4min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=1, min_samples_split=2, n_estimators=2000;, score=(train=-0.115, test=-0.334) total time= 2.4min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=1, min_samples_split=5, n_estimators=1000;, score=(train=-0.133, test=-0.316) total time= 1.2min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=1, min_samples_split=5, n_estimators=1000;, score=(train=-0.134, test=-0.294) total time= 1.2min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=1, min_samples_split=2, n_estimators=2000;, score=(train=-0.116, test=-0.315) total time= 2.4min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=1, min_samples_split=5, n_estimators=1000;, score=(train=-0.134, test=-0.306) total time= 1.2min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=1, min_samples_split=2, n_estimators=2000;, score=(train=-0.118, test=-0.294) total time= 2.4min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=1, min_samples_split=2, n_estimators=2000;, score=(train=-0.117, test=-0.307) total time= 2.4min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=1, min_samples_split=5, n_estimators=1200;, score=(train=-0.130, test=-0.334) total time= 1.4min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=1, min_samples_split=5, n_estimators=1200;, score=(train=-0.133, test=-0.312) total time= 1.4min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=1, min_samples_split=5, n_estimators=1200;, score=(train=-0.133, test=-0.314) total time= 1.4min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=1, min_samples_split=5, n_estimators=1200;, score=(train=-0.134, test=-0.295) total time= 1.4min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=1, min_samples_split=5, n_estimators=1200;, score=(train=-0.134, test=-0.308) total time= 1.4min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=1, min_samples_split=5, n_estimators=1400;, score=(train=-0.130, test=-0.334) total time= 1.6min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=1, min_samples_split=5, n_estimators=1400;, score=(train=-0.133, test=-0.312) total time= 1.6min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=1, min_samples_split=5, n_estimators=1400;, score=(train=-0.133, test=-0.315) total time= 1.6min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=1, min_samples_split=5, n_estimators=1400;, score=(train=-0.134, test=-0.295) total time= 1.7min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=1, min_samples_split=5, n_estimators=1400;, score=(train=-0.134, test=-0.307) total time= 1.6min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=1, min_samples_split=5, n_estimators=1600;, score=(train=-0.130, test=-0.333) total time= 1.9min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=1, min_samples_split=5, n_estimators=1600;, score=(train=-0.133, test=-0.312) total time= 1.8min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=1, min_samples_split=5, n_estimators=1600;, score=(train=-0.133, test=-0.315) total time= 1.8min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=1, min_samples_split=5, n_estimators=1600;, score=(train=-0.134, test=-0.307) total time= 1.8min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=1, min_samples_split=5, n_estimators=1600;, score=(train=-0.134, test=-0.295) total time= 1.9min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=1, min_samples_split=5, n_estimators=1800;, score=(train=-0.131, test=-0.334) total time= 2.1min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=1, min_samples_split=5, n_estimators=1800;, score=(train=-0.133, test=-0.312) total time= 2.1min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=1, min_samples_split=5, n_estimators=1800;, score=(train=-0.133, test=-0.315) total time= 2.0min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=1, min_samples_split=5, n_estimators=1800;, score=(train=-0.134, test=-0.294) total time= 2.1min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=1, min_samples_split=5, n_estimators=1800;, score=(train=-0.134, test=-0.307) total time= 2.1min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=1, min_samples_split=8, n_estimators=1000;, score=(train=-0.152, test=-0.311) total time= 1.1min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=1, min_samples_split=8, n_estimators=1000;, score=(train=-0.150, test=-0.334) total time= 1.2min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=1, min_samples_split=5, n_estimators=2000;, score=(train=-0.130, test=-0.333) total time= 2.4min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=1, min_samples_split=5, n_estimators=2000;, score=(train=-0.133, test=-0.311) total time= 2.3min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=1, min_samples_split=8, n_estimators=1000;, score=(train=-0.152, test=-0.315) total time= 1.1min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=1, min_samples_split=8, n_estimators=1000;, score=(train=-0.153, test=-0.295) total time= 1.1min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=1, min_samples_split=5, n_estimators=2000;, score=(train=-0.133, test=-0.315) total time= 2.3min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=1, min_samples_split=8, n_estimators=1000;, score=(train=-0.152, test=-0.307) total time= 1.1min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=1, min_samples_split=5, n_estimators=2000;, score=(train=-0.134, test=-0.294) total time= 2.3min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=1, min_samples_split=5, n_estimators=2000;, score=(train=-0.134, test=-0.307) total time= 2.3min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=1, min_samples_split=8, n_estimators=1200;, score=(train=-0.152, test=-0.311) total time= 1.4min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=1, min_samples_split=8, n_estimators=1200;, score=(train=-0.149, test=-0.333) total time= 1.4min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=1, min_samples_split=8, n_estimators=1200;, score=(train=-0.152, test=-0.316) total time= 1.3min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=1, min_samples_split=8, n_estimators=1200;, score=(train=-0.153, test=-0.295) total time= 1.4min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=1, min_samples_split=8, n_estimators=1200;, score=(train=-0.153, test=-0.306) total time= 1.4min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=1, min_samples_split=8, n_estimators=1400;, score=(train=-0.152, test=-0.311) total time= 1.6min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=1, min_samples_split=8, n_estimators=1400;, score=(train=-0.149, test=-0.334) total time= 1.6min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=1, min_samples_split=8, n_estimators=1400;, score=(train=-0.152, test=-0.316) total time= 1.6min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=1, min_samples_split=8, n_estimators=1400;, score=(train=-0.153, test=-0.294) total time= 1.6min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=1, min_samples_split=8, n_estimators=1400;, score=(train=-0.152, test=-0.307) total time= 1.6min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=1, min_samples_split=8, n_estimators=1600;, score=(train=-0.149, test=-0.334) total time= 1.8min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=1, min_samples_split=8, n_estimators=1600;, score=(train=-0.152, test=-0.312) total time= 1.8min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=1, min_samples_split=8, n_estimators=1600;, score=(train=-0.153, test=-0.307) total time= 1.8min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=1, min_samples_split=8, n_estimators=1600;, score=(train=-0.152, test=-0.316) total time= 1.8min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=1, min_samples_split=8, n_estimators=1600;, score=(train=-0.153, test=-0.294) total time= 1.8min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=1, min_samples_split=8, n_estimators=1800;, score=(train=-0.149, test=-0.335) total time= 2.0min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=1, min_samples_split=8, n_estimators=1800;, score=(train=-0.152, test=-0.313) total time= 2.0min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=1, min_samples_split=8, n_estimators=1800;, score=(train=-0.152, test=-0.316) total time= 2.0min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=1, min_samples_split=8, n_estimators=1800;, score=(train=-0.153, test=-0.307) total time= 2.0min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=1, min_samples_split=8, n_estimators=1800;, score=(train=-0.153, test=-0.294) total time= 2.0min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=1, min_samples_split=11, n_estimators=1000;, score=(train=-0.168, test=-0.312) total time= 1.1min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=1, min_samples_split=11, n_estimators=1000;, score=(train=-0.165, test=-0.333) total time= 1.1min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=1, min_samples_split=11, n_estimators=1000;, score=(train=-0.169, test=-0.316) total time= 1.1min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=1, min_samples_split=8, n_estimators=2000;, score=(train=-0.152, test=-0.312) total time= 2.2min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=1, min_samples_split=8, n_estimators=2000;, score=(train=-0.149, test=-0.333) total time= 2.3min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=1, min_samples_split=11, n_estimators=1000;, score=(train=-0.170, test=-0.295) total time= 1.1min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=1, min_samples_split=8, n_estimators=2000;, score=(train=-0.152, test=-0.316) total time= 2.2min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=1, min_samples_split=8, n_estimators=2000;, score=(train=-0.154, test=-0.295) total time= 2.3min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=1, min_samples_split=11, n_estimators=1000;, score=(train=-0.170, test=-0.308) total time= 1.1min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=1, min_samples_split=8, n_estimators=2000;, score=(train=-0.153, test=-0.307) total time= 2.3min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=1, min_samples_split=11, n_estimators=1200;, score=(train=-0.168, test=-0.313) total time= 1.3min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=1, min_samples_split=11, n_estimators=1200;, score=(train=-0.165, test=-0.334) total time= 1.4min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=1, min_samples_split=11, n_estimators=1200;, score=(train=-0.169, test=-0.317) total time= 1.3min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=1, min_samples_split=11, n_estimators=1200;, score=(train=-0.170, test=-0.295) total time= 1.3min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=1, min_samples_split=11, n_estimators=1200;, score=(train=-0.169, test=-0.307) total time= 1.4min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=1, min_samples_split=11, n_estimators=1400;, score=(train=-0.165, test=-0.334) total time= 1.6min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=1, min_samples_split=11, n_estimators=1400;, score=(train=-0.169, test=-0.312) total time= 1.6min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=1, min_samples_split=11, n_estimators=1400;, score=(train=-0.169, test=-0.316) total time= 1.6min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=1, min_samples_split=11, n_estimators=1400;, score=(train=-0.170, test=-0.295) total time= 1.6min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=1, min_samples_split=11, n_estimators=1400;, score=(train=-0.169, test=-0.308) total time= 1.5min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=1, min_samples_split=11, n_estimators=1600;, score=(train=-0.165, test=-0.333) total time= 1.8min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=1, min_samples_split=11, n_estimators=1600;, score=(train=-0.168, test=-0.312) total time= 1.8min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=1, min_samples_split=11, n_estimators=1600;, score=(train=-0.169, test=-0.316) total time= 1.8min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=1, min_samples_split=11, n_estimators=1600;, score=(train=-0.170, test=-0.295) total time= 1.8min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=1, min_samples_split=11, n_estimators=1600;, score=(train=-0.170, test=-0.308) total time= 1.8min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=1, min_samples_split=11, n_estimators=1800;, score=(train=-0.165, test=-0.334) total time= 2.0min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=1, min_samples_split=11, n_estimators=1800;, score=(train=-0.169, test=-0.312) total time= 2.0min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=1, min_samples_split=11, n_estimators=1800;, score=(train=-0.169, test=-0.316) total time= 2.0min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=1, min_samples_split=11, n_estimators=1800;, score=(train=-0.170, test=-0.294) total time= 2.0min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=3, min_samples_split=2, n_estimators=1000;, score=(train=-0.158, test=-0.312) total time= 1.0min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=3, min_samples_split=2, n_estimators=1000;, score=(train=-0.155, test=-0.332) total time= 1.1min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=1, min_samples_split=11, n_estimators=1800;, score=(train=-0.170, test=-0.308) total time= 2.0min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=3, min_samples_split=2, n_estimators=1000;, score=(train=-0.157, test=-0.315) total time= 1.0min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=3, min_samples_split=2, n_estimators=1000;, score=(train=-0.159, test=-0.294) total time= 1.0min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=1, min_samples_split=11, n_estimators=2000;, score=(train=-0.168, test=-0.312) total time= 2.2min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=1, min_samples_split=11, n_estimators=2000;, score=(train=-0.165, test=-0.334) total time= 2.3min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=1, min_samples_split=11, n_estimators=2000;, score=(train=-0.169, test=-0.316) total time= 2.2min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=3, min_samples_split=2, n_estimators=1000;, score=(train=-0.159, test=-0.307) total time= 1.0min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=1, min_samples_split=11, n_estimators=2000;, score=(train=-0.170, test=-0.295) total time= 2.2min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=1, min_samples_split=11, n_estimators=2000;, score=(train=-0.170, test=-0.307) total time= 2.2min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=3, min_samples_split=2, n_estimators=1200;, score=(train=-0.154, test=-0.333) total time= 1.2min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=3, min_samples_split=2, n_estimators=1200;, score=(train=-0.157, test=-0.313) total time= 1.2min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=3, min_samples_split=2, n_estimators=1200;, score=(train=-0.159, test=-0.310) total time= 1.2min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=3, min_samples_split=2, n_estimators=1200;, score=(train=-0.160, test=-0.294) total time= 1.2min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=3, min_samples_split=2, n_estimators=1200;, score=(train=-0.159, test=-0.306) total time= 1.2min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=3, min_samples_split=2, n_estimators=1400;, score=(train=-0.159, test=-0.312) total time= 1.4min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=3, min_samples_split=2, n_estimators=1400;, score=(train=-0.155, test=-0.333) total time= 1.5min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=3, min_samples_split=2, n_estimators=1400;, score=(train=-0.158, test=-0.313) total time= 1.4min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=3, min_samples_split=2, n_estimators=1400;, score=(train=-0.159, test=-0.306) total time= 1.4min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=3, min_samples_split=2, n_estimators=1400;, score=(train=-0.159, test=-0.293) total time= 1.4min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=3, min_samples_split=2, n_estimators=1600;, score=(train=-0.154, test=-0.333) total time= 1.6min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=3, min_samples_split=2, n_estimators=1600;, score=(train=-0.158, test=-0.312) total time= 1.6min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=3, min_samples_split=2, n_estimators=1600;, score=(train=-0.157, test=-0.313) total time= 1.6min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=3, min_samples_split=2, n_estimators=1600;, score=(train=-0.159, test=-0.293) total time= 1.6min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=3, min_samples_split=2, n_estimators=1600;, score=(train=-0.159, test=-0.307) total time= 1.6min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=3, min_samples_split=2, n_estimators=1800;, score=(train=-0.154, test=-0.332) total time= 1.8min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=3, min_samples_split=2, n_estimators=1800;, score=(train=-0.159, test=-0.311) total time= 1.8min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=3, min_samples_split=2, n_estimators=1800;, score=(train=-0.157, test=-0.313) total time= 1.8min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=3, min_samples_split=2, n_estimators=1800;, score=(train=-0.159, test=-0.307) total time= 1.8min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=3, min_samples_split=5, n_estimators=1000;, score=(train=-0.158, test=-0.311) total time= 1.0min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=3, min_samples_split=2, n_estimators=1800;, score=(train=-0.159, test=-0.293) total time= 1.8min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=3, min_samples_split=5, n_estimators=1000;, score=(train=-0.154, test=-0.332) total time= 1.0min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=3, min_samples_split=5, n_estimators=1000;, score=(train=-0.157, test=-0.314) total time= 1.0min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=3, min_samples_split=2, n_estimators=2000;, score=(train=-0.158, test=-0.311) total time= 2.0min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=3, min_samples_split=2, n_estimators=2000;, score=(train=-0.154, test=-0.332) total time= 2.1min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=3, min_samples_split=5, n_estimators=1000;, score=(train=-0.160, test=-0.294) total time= 1.0min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=3, min_samples_split=2, n_estimators=2000;, score=(train=-0.157, test=-0.313) total time= 2.0min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=3, min_samples_split=2, n_estimators=2000;, score=(train=-0.159, test=-0.294) total time= 2.0min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=3, min_samples_split=2, n_estimators=2000;, score=(train=-0.159, test=-0.306) total time= 2.0min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=3, min_samples_split=5, n_estimators=1000;, score=(train=-0.159, test=-0.306) total time= 1.0min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=3, min_samples_split=5, n_estimators=1200;, score=(train=-0.158, test=-0.313) total time= 1.2min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=3, min_samples_split=5, n_estimators=1200;, score=(train=-0.158, test=-0.311) total time= 1.2min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=3, min_samples_split=5, n_estimators=1200;, score=(train=-0.154, test=-0.333) total time= 1.2min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=3, min_samples_split=5, n_estimators=1200;, score=(train=-0.159, test=-0.293) total time= 1.2min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=3, min_samples_split=5, n_estimators=1200;, score=(train=-0.159, test=-0.306) total time= 1.2min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=3, min_samples_split=5, n_estimators=1400;, score=(train=-0.158, test=-0.311) total time= 1.4min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=3, min_samples_split=5, n_estimators=1400;, score=(train=-0.157, test=-0.313) total time= 1.4min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=3, min_samples_split=5, n_estimators=1400;, score=(train=-0.155, test=-0.333) total time= 1.4min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=3, min_samples_split=5, n_estimators=1400;, score=(train=-0.159, test=-0.293) total time= 1.4min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=3, min_samples_split=5, n_estimators=1400;, score=(train=-0.159, test=-0.306) total time= 1.4min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=3, min_samples_split=5, n_estimators=1600;, score=(train=-0.154, test=-0.333) total time= 1.7min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=3, min_samples_split=5, n_estimators=1600;, score=(train=-0.158, test=-0.312) total time= 1.6min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=3, min_samples_split=5, n_estimators=1600;, score=(train=-0.157, test=-0.313) total time= 1.6min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=3, min_samples_split=5, n_estimators=1600;, score=(train=-0.159, test=-0.306) total time= 1.6min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=3, min_samples_split=5, n_estimators=1600;, score=(train=-0.159, test=-0.293) total time= 1.7min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=3, min_samples_split=5, n_estimators=1800;, score=(train=-0.154, test=-0.332) total time= 1.9min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=3, min_samples_split=5, n_estimators=1800;, score=(train=-0.159, test=-0.311) total time= 1.9min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=3, min_samples_split=5, n_estimators=1800;, score=(train=-0.157, test=-0.314) total time= 1.8min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=3, min_samples_split=5, n_estimators=1800;, score=(train=-0.159, test=-0.293) total time= 1.8min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=3, min_samples_split=5, n_estimators=1800;, score=(train=-0.159, test=-0.306) total time= 1.8min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=3, min_samples_split=8, n_estimators=1000;, score=(train=-0.170, test=-0.311) total time= 1.0min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=3, min_samples_split=8, n_estimators=1000;, score=(train=-0.165, test=-0.332) total time= 1.1min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=3, min_samples_split=8, n_estimators=1000;, score=(train=-0.169, test=-0.314) total time= 1.0min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=3, min_samples_split=5, n_estimators=2000;, score=(train=-0.154, test=-0.333) total time= 2.1min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=3, min_samples_split=5, n_estimators=2000;, score=(train=-0.158, test=-0.311) total time= 2.1min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=3, min_samples_split=8, n_estimators=1000;, score=(train=-0.171, test=-0.293) total time= 1.0min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=3, min_samples_split=5, n_estimators=2000;, score=(train=-0.159, test=-0.294) total time= 2.0min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=3, min_samples_split=5, n_estimators=2000;, score=(train=-0.158, test=-0.313) total time= 2.0min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=3, min_samples_split=8, n_estimators=1000;, score=(train=-0.170, test=-0.307) total time= 1.0min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=3, min_samples_split=5, n_estimators=2000;, score=(train=-0.159, test=-0.307) total time= 2.0min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=3, min_samples_split=8, n_estimators=1200;, score=(train=-0.170, test=-0.312) total time= 1.2min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=3, min_samples_split=8, n_estimators=1200;, score=(train=-0.166, test=-0.333) total time= 1.2min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=3, min_samples_split=8, n_estimators=1200;, score=(train=-0.169, test=-0.315) total time= 1.2min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=3, min_samples_split=8, n_estimators=1200;, score=(train=-0.171, test=-0.293) total time= 1.2min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=3, min_samples_split=8, n_estimators=1200;, score=(train=-0.170, test=-0.306) total time= 1.2min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=3, min_samples_split=8, n_estimators=1400;, score=(train=-0.165, test=-0.332) total time= 1.4min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=3, min_samples_split=8, n_estimators=1400;, score=(train=-0.170, test=-0.312) total time= 1.4min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=3, min_samples_split=8, n_estimators=1400;, score=(train=-0.168, test=-0.314) total time= 1.4min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=3, min_samples_split=8, n_estimators=1400;, score=(train=-0.170, test=-0.294) total time= 1.4min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=3, min_samples_split=8, n_estimators=1400;, score=(train=-0.170, test=-0.305) total time= 1.4min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=3, min_samples_split=8, n_estimators=1600;, score=(train=-0.165, test=-0.333) total time= 1.6min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=3, min_samples_split=8, n_estimators=1600;, score=(train=-0.170, test=-0.312) total time= 1.6min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=3, min_samples_split=8, n_estimators=1600;, score=(train=-0.169, test=-0.313) total time= 1.6min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=3, min_samples_split=8, n_estimators=1600;, score=(train=-0.171, test=-0.294) total time= 1.6min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=3, min_samples_split=8, n_estimators=1600;, score=(train=-0.170, test=-0.307) total time= 1.6min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=3, min_samples_split=8, n_estimators=1800;, score=(train=-0.165, test=-0.333) total time= 1.9min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=3, min_samples_split=8, n_estimators=1800;, score=(train=-0.170, test=-0.311) total time= 1.9min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=3, min_samples_split=8, n_estimators=1800;, score=(train=-0.169, test=-0.314) total time= 1.8min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=3, min_samples_split=11, n_estimators=1000;, score=(train=-0.181, test=-0.332) total time=  60.0s\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=3, min_samples_split=8, n_estimators=1800;, score=(train=-0.171, test=-0.294) total time= 1.8min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=3, min_samples_split=8, n_estimators=1800;, score=(train=-0.170, test=-0.306) total time= 1.8min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=3, min_samples_split=11, n_estimators=1000;, score=(train=-0.185, test=-0.312) total time=  59.2s\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=3, min_samples_split=11, n_estimators=1000;, score=(train=-0.184, test=-0.314) total time=  59.0s\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=3, min_samples_split=8, n_estimators=2000;, score=(train=-0.166, test=-0.332) total time= 2.0min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=3, min_samples_split=8, n_estimators=2000;, score=(train=-0.169, test=-0.312) total time= 2.0min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=3, min_samples_split=11, n_estimators=1000;, score=(train=-0.187, test=-0.293) total time= 1.0min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=3, min_samples_split=8, n_estimators=2000;, score=(train=-0.169, test=-0.314) total time= 2.0min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=3, min_samples_split=8, n_estimators=2000;, score=(train=-0.170, test=-0.307) total time= 2.0min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=3, min_samples_split=8, n_estimators=2000;, score=(train=-0.170, test=-0.293) total time= 2.0min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=3, min_samples_split=11, n_estimators=1000;, score=(train=-0.186, test=-0.306) total time= 1.0min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=3, min_samples_split=11, n_estimators=1200;, score=(train=-0.181, test=-0.332) total time= 1.2min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=3, min_samples_split=11, n_estimators=1200;, score=(train=-0.184, test=-0.312) total time= 1.2min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=3, min_samples_split=11, n_estimators=1200;, score=(train=-0.184, test=-0.314) total time= 1.2min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=3, min_samples_split=11, n_estimators=1200;, score=(train=-0.186, test=-0.294) total time= 1.2min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=3, min_samples_split=11, n_estimators=1200;, score=(train=-0.186, test=-0.306) total time= 1.2min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=3, min_samples_split=11, n_estimators=1400;, score=(train=-0.181, test=-0.333) total time= 1.4min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=3, min_samples_split=11, n_estimators=1400;, score=(train=-0.185, test=-0.311) total time= 1.4min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=3, min_samples_split=11, n_estimators=1400;, score=(train=-0.185, test=-0.315) total time= 1.4min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=3, min_samples_split=11, n_estimators=1400;, score=(train=-0.186, test=-0.294) total time= 1.4min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=3, min_samples_split=11, n_estimators=1400;, score=(train=-0.186, test=-0.306) total time= 1.4min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=3, min_samples_split=11, n_estimators=1600;, score=(train=-0.185, test=-0.311) total time= 1.6min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=3, min_samples_split=11, n_estimators=1600;, score=(train=-0.180, test=-0.334) total time= 1.6min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=3, min_samples_split=11, n_estimators=1600;, score=(train=-0.184, test=-0.314) total time= 1.6min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=3, min_samples_split=11, n_estimators=1600;, score=(train=-0.186, test=-0.293) total time= 1.6min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=3, min_samples_split=11, n_estimators=1600;, score=(train=-0.186, test=-0.307) total time= 1.6min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=3, min_samples_split=11, n_estimators=1800;, score=(train=-0.181, test=-0.333) total time= 1.8min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=3, min_samples_split=11, n_estimators=1800;, score=(train=-0.185, test=-0.312) total time= 1.8min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=3, min_samples_split=11, n_estimators=1800;, score=(train=-0.184, test=-0.314) total time= 1.8min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=3, min_samples_split=11, n_estimators=1800;, score=(train=-0.186, test=-0.294) total time= 1.8min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=5, min_samples_split=2, n_estimators=1000;, score=(train=-0.194, test=-0.311) total time=  54.9s\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=5, min_samples_split=2, n_estimators=1000;, score=(train=-0.189, test=-0.332) total time=  56.3s\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=3, min_samples_split=11, n_estimators=1800;, score=(train=-0.186, test=-0.307) total time= 1.8min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=5, min_samples_split=2, n_estimators=1000;, score=(train=-0.192, test=-0.314) total time=  55.8s\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=3, min_samples_split=11, n_estimators=2000;, score=(train=-0.181, test=-0.333) total time= 2.0min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=3, min_samples_split=11, n_estimators=2000;, score=(train=-0.185, test=-0.312) total time= 2.0min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=5, min_samples_split=2, n_estimators=1000;, score=(train=-0.195, test=-0.293) total time=  55.8s\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=3, min_samples_split=11, n_estimators=2000;, score=(train=-0.184, test=-0.314) total time= 2.0min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=3, min_samples_split=11, n_estimators=2000;, score=(train=-0.186, test=-0.294) total time= 2.0min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=5, min_samples_split=2, n_estimators=1000;, score=(train=-0.194, test=-0.307) total time=  55.1s\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=3, min_samples_split=11, n_estimators=2000;, score=(train=-0.185, test=-0.307) total time= 2.0min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=5, min_samples_split=2, n_estimators=1200;, score=(train=-0.189, test=-0.332) total time= 1.1min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=5, min_samples_split=2, n_estimators=1200;, score=(train=-0.193, test=-0.314) total time= 1.1min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=5, min_samples_split=2, n_estimators=1200;, score=(train=-0.193, test=-0.311) total time= 1.2min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=5, min_samples_split=2, n_estimators=1200;, score=(train=-0.195, test=-0.294) total time= 1.1min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=5, min_samples_split=2, n_estimators=1200;, score=(train=-0.194, test=-0.307) total time= 1.1min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=5, min_samples_split=2, n_estimators=1400;, score=(train=-0.189, test=-0.333) total time= 1.3min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=5, min_samples_split=2, n_estimators=1400;, score=(train=-0.193, test=-0.312) total time= 1.3min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=5, min_samples_split=2, n_estimators=1400;, score=(train=-0.193, test=-0.315) total time= 1.3min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=5, min_samples_split=2, n_estimators=1400;, score=(train=-0.195, test=-0.294) total time= 1.3min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=5, min_samples_split=2, n_estimators=1400;, score=(train=-0.194, test=-0.306) total time= 1.3min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=5, min_samples_split=2, n_estimators=1600;, score=(train=-0.189, test=-0.333) total time= 1.5min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=5, min_samples_split=2, n_estimators=1600;, score=(train=-0.193, test=-0.312) total time= 1.5min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=5, min_samples_split=2, n_estimators=1600;, score=(train=-0.193, test=-0.314) total time= 1.5min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=5, min_samples_split=2, n_estimators=1600;, score=(train=-0.195, test=-0.294) total time= 1.5min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=5, min_samples_split=2, n_estimators=1600;, score=(train=-0.194, test=-0.307) total time= 1.5min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=5, min_samples_split=2, n_estimators=1800;, score=(train=-0.189, test=-0.332) total time= 1.7min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=5, min_samples_split=2, n_estimators=1800;, score=(train=-0.193, test=-0.311) total time= 1.7min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=5, min_samples_split=2, n_estimators=1800;, score=(train=-0.193, test=-0.314) total time= 1.7min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=5, min_samples_split=2, n_estimators=1800;, score=(train=-0.195, test=-0.294) total time= 1.6min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=5, min_samples_split=5, n_estimators=1000;, score=(train=-0.194, test=-0.311) total time=  55.2s\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=5, min_samples_split=5, n_estimators=1000;, score=(train=-0.189, test=-0.333) total time=  56.0s\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=5, min_samples_split=2, n_estimators=1800;, score=(train=-0.194, test=-0.307) total time= 1.6min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=5, min_samples_split=5, n_estimators=1000;, score=(train=-0.193, test=-0.315) total time=  55.1s\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=5, min_samples_split=2, n_estimators=2000;, score=(train=-0.194, test=-0.311) total time= 1.9min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=5, min_samples_split=2, n_estimators=2000;, score=(train=-0.189, test=-0.333) total time= 1.9min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=5, min_samples_split=5, n_estimators=1000;, score=(train=-0.195, test=-0.294) total time=  55.1s\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=5, min_samples_split=2, n_estimators=2000;, score=(train=-0.192, test=-0.315) total time= 1.8min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=5, min_samples_split=5, n_estimators=1000;, score=(train=-0.194, test=-0.306) total time=  55.1s\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=5, min_samples_split=2, n_estimators=2000;, score=(train=-0.195, test=-0.293) total time= 1.8min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=5, min_samples_split=2, n_estimators=2000;, score=(train=-0.194, test=-0.307) total time= 1.8min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=5, min_samples_split=5, n_estimators=1200;, score=(train=-0.193, test=-0.314) total time= 1.1min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=5, min_samples_split=5, n_estimators=1200;, score=(train=-0.194, test=-0.312) total time= 1.1min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=5, min_samples_split=5, n_estimators=1200;, score=(train=-0.189, test=-0.333) total time= 1.1min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=5, min_samples_split=5, n_estimators=1200;, score=(train=-0.195, test=-0.294) total time= 1.1min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=5, min_samples_split=5, n_estimators=1200;, score=(train=-0.194, test=-0.307) total time= 1.1min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=5, min_samples_split=5, n_estimators=1400;, score=(train=-0.189, test=-0.332) total time= 1.3min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=5, min_samples_split=5, n_estimators=1400;, score=(train=-0.193, test=-0.311) total time= 1.3min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=5, min_samples_split=5, n_estimators=1400;, score=(train=-0.193, test=-0.314) total time= 1.3min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=5, min_samples_split=5, n_estimators=1400;, score=(train=-0.195, test=-0.295) total time= 1.3min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=5, min_samples_split=5, n_estimators=1400;, score=(train=-0.194, test=-0.307) total time= 1.3min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=5, min_samples_split=5, n_estimators=1600;, score=(train=-0.189, test=-0.333) total time= 1.5min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=5, min_samples_split=5, n_estimators=1600;, score=(train=-0.193, test=-0.312) total time= 1.5min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=5, min_samples_split=5, n_estimators=1600;, score=(train=-0.193, test=-0.313) total time= 1.5min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=5, min_samples_split=5, n_estimators=1600;, score=(train=-0.194, test=-0.307) total time= 1.5min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=5, min_samples_split=5, n_estimators=1600;, score=(train=-0.195, test=-0.294) total time= 1.5min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=5, min_samples_split=5, n_estimators=1800;, score=(train=-0.189, test=-0.333) total time= 1.7min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=5, min_samples_split=5, n_estimators=1800;, score=(train=-0.194, test=-0.312) total time= 1.7min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=5, min_samples_split=5, n_estimators=1800;, score=(train=-0.192, test=-0.314) total time= 1.6min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=5, min_samples_split=5, n_estimators=1800;, score=(train=-0.194, test=-0.307) total time= 1.6min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=5, min_samples_split=5, n_estimators=1800;, score=(train=-0.195, test=-0.294) total time= 1.7min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=5, min_samples_split=8, n_estimators=1000;, score=(train=-0.194, test=-0.312) total time=  54.9s\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=5, min_samples_split=8, n_estimators=1000;, score=(train=-0.189, test=-0.332) total time=  56.7s\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=5, min_samples_split=8, n_estimators=1000;, score=(train=-0.193, test=-0.314) total time=  54.4s\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=5, min_samples_split=5, n_estimators=2000;, score=(train=-0.189, test=-0.332) total time= 1.9min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=5, min_samples_split=5, n_estimators=2000;, score=(train=-0.193, test=-0.311) total time= 1.8min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=5, min_samples_split=8, n_estimators=1000;, score=(train=-0.195, test=-0.294) total time=  55.1s\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=5, min_samples_split=5, n_estimators=2000;, score=(train=-0.193, test=-0.314) total time= 1.8min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=5, min_samples_split=5, n_estimators=2000;, score=(train=-0.195, test=-0.293) total time= 1.8min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=5, min_samples_split=8, n_estimators=1000;, score=(train=-0.194, test=-0.307) total time=  54.9s\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=5, min_samples_split=5, n_estimators=2000;, score=(train=-0.194, test=-0.307) total time= 1.8min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=5, min_samples_split=8, n_estimators=1200;, score=(train=-0.194, test=-0.312) total time= 1.1min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=5, min_samples_split=8, n_estimators=1200;, score=(train=-0.189, test=-0.333) total time= 1.1min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=5, min_samples_split=8, n_estimators=1200;, score=(train=-0.193, test=-0.314) total time= 1.1min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=5, min_samples_split=8, n_estimators=1200;, score=(train=-0.194, test=-0.295) total time= 1.1min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=5, min_samples_split=8, n_estimators=1200;, score=(train=-0.194, test=-0.307) total time= 1.1min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=5, min_samples_split=8, n_estimators=1400;, score=(train=-0.189, test=-0.333) total time= 1.3min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=5, min_samples_split=8, n_estimators=1400;, score=(train=-0.194, test=-0.312) total time= 1.3min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=5, min_samples_split=8, n_estimators=1400;, score=(train=-0.193, test=-0.314) total time= 1.3min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=5, min_samples_split=8, n_estimators=1400;, score=(train=-0.195, test=-0.294) total time= 1.3min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=5, min_samples_split=8, n_estimators=1400;, score=(train=-0.194, test=-0.307) total time= 1.3min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=5, min_samples_split=8, n_estimators=1600;, score=(train=-0.189, test=-0.332) total time= 1.5min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=5, min_samples_split=8, n_estimators=1600;, score=(train=-0.193, test=-0.311) total time= 1.5min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=5, min_samples_split=8, n_estimators=1600;, score=(train=-0.194, test=-0.294) total time= 1.5min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=5, min_samples_split=8, n_estimators=1600;, score=(train=-0.193, test=-0.314) total time= 1.5min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=5, min_samples_split=8, n_estimators=1600;, score=(train=-0.194, test=-0.307) total time= 1.5min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=5, min_samples_split=8, n_estimators=1800;, score=(train=-0.189, test=-0.334) total time= 1.7min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=5, min_samples_split=8, n_estimators=1800;, score=(train=-0.194, test=-0.312) total time= 1.7min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=5, min_samples_split=8, n_estimators=1800;, score=(train=-0.193, test=-0.314) total time= 1.6min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=5, min_samples_split=8, n_estimators=1800;, score=(train=-0.195, test=-0.294) total time= 1.7min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=5, min_samples_split=8, n_estimators=1800;, score=(train=-0.194, test=-0.307) total time= 1.6min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=5, min_samples_split=11, n_estimators=1000;, score=(train=-0.193, test=-0.334) total time=  57.4s\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=5, min_samples_split=11, n_estimators=1000;, score=(train=-0.197, test=-0.312) total time=  57.3s\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=5, min_samples_split=11, n_estimators=1000;, score=(train=-0.196, test=-0.314) total time=  54.7s\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=5, min_samples_split=8, n_estimators=2000;, score=(train=-0.189, test=-0.333) total time= 1.9min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=5, min_samples_split=8, n_estimators=2000;, score=(train=-0.194, test=-0.312) total time= 1.9min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=5, min_samples_split=11, n_estimators=1000;, score=(train=-0.198, test=-0.293) total time=  54.8s\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=5, min_samples_split=8, n_estimators=2000;, score=(train=-0.193, test=-0.314) total time= 1.8min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=5, min_samples_split=11, n_estimators=1000;, score=(train=-0.198, test=-0.306) total time=  54.8s\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=5, min_samples_split=8, n_estimators=2000;, score=(train=-0.195, test=-0.295) total time= 1.9min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=5, min_samples_split=8, n_estimators=2000;, score=(train=-0.194, test=-0.307) total time= 1.8min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=5, min_samples_split=11, n_estimators=1200;, score=(train=-0.193, test=-0.334) total time= 1.1min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=5, min_samples_split=11, n_estimators=1200;, score=(train=-0.198, test=-0.313) total time= 1.1min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=5, min_samples_split=11, n_estimators=1200;, score=(train=-0.197, test=-0.314) total time= 1.1min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=5, min_samples_split=11, n_estimators=1200;, score=(train=-0.199, test=-0.295) total time= 1.1min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=5, min_samples_split=11, n_estimators=1200;, score=(train=-0.198, test=-0.307) total time= 1.1min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=5, min_samples_split=11, n_estimators=1400;, score=(train=-0.193, test=-0.333) total time= 1.3min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=5, min_samples_split=11, n_estimators=1400;, score=(train=-0.197, test=-0.312) total time= 1.3min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=5, min_samples_split=11, n_estimators=1400;, score=(train=-0.196, test=-0.314) total time= 1.3min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=5, min_samples_split=11, n_estimators=1400;, score=(train=-0.198, test=-0.294) total time= 1.3min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=5, min_samples_split=11, n_estimators=1400;, score=(train=-0.198, test=-0.307) total time= 1.3min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=5, min_samples_split=11, n_estimators=1600;, score=(train=-0.193, test=-0.333) total time= 1.5min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=5, min_samples_split=11, n_estimators=1600;, score=(train=-0.197, test=-0.311) total time= 1.5min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=5, min_samples_split=11, n_estimators=1600;, score=(train=-0.197, test=-0.314) total time= 1.5min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=5, min_samples_split=11, n_estimators=1600;, score=(train=-0.198, test=-0.307) total time= 1.5min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=5, min_samples_split=11, n_estimators=1600;, score=(train=-0.198, test=-0.294) total time= 1.5min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=5, min_samples_split=11, n_estimators=1800;, score=(train=-0.193, test=-0.333) total time= 1.7min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=5, min_samples_split=11, n_estimators=1800;, score=(train=-0.198, test=-0.311) total time= 1.7min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=5, min_samples_split=11, n_estimators=1800;, score=(train=-0.196, test=-0.314) total time= 1.6min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=5, min_samples_split=11, n_estimators=1800;, score=(train=-0.199, test=-0.294) total time= 1.7min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=5, min_samples_split=11, n_estimators=1800;, score=(train=-0.198, test=-0.307) total time= 1.6min\n",
      "[CV 2/5] END max_depth=25, min_samples_leaf=5, min_samples_split=11, n_estimators=2000;, score=(train=-0.197, test=-0.311) total time= 1.9min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=(train=-0.113, test=-0.334) total time= 1.2min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=(train=-0.116, test=-0.313) total time= 1.3min\n",
      "[CV 1/5] END max_depth=25, min_samples_leaf=5, min_samples_split=11, n_estimators=2000;, score=(train=-0.193, test=-0.333) total time= 1.9min\n",
      "[CV 4/5] END max_depth=25, min_samples_leaf=5, min_samples_split=11, n_estimators=2000;, score=(train=-0.199, test=-0.294) total time= 1.8min\n",
      "[CV 3/5] END max_depth=25, min_samples_leaf=5, min_samples_split=11, n_estimators=2000;, score=(train=-0.197, test=-0.314) total time= 1.9min\n",
      "[CV 5/5] END max_depth=25, min_samples_leaf=5, min_samples_split=11, n_estimators=2000;, score=(train=-0.198, test=-0.307) total time= 1.8min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=(train=-0.116, test=-0.315) total time= 1.2min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=(train=-0.117, test=-0.294) total time= 1.2min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=1000;, score=(train=-0.116, test=-0.306) total time= 1.2min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=(train=-0.113, test=-0.333) total time= 1.5min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=(train=-0.115, test=-0.313) total time= 1.5min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=(train=-0.116, test=-0.315) total time= 1.4min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=(train=-0.117, test=-0.294) total time= 1.4min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=(train=-0.116, test=-0.307) total time= 1.5min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=1400;, score=(train=-0.114, test=-0.333) total time= 1.8min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=1400;, score=(train=-0.116, test=-0.315) total time= 1.7min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=1400;, score=(train=-0.117, test=-0.295) total time= 1.7min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=1400;, score=(train=-0.116, test=-0.312) total time= 1.7min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=1400;, score=(train=-0.116, test=-0.307) total time= 1.7min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=1600;, score=(train=-0.113, test=-0.333) total time= 2.0min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=1600;, score=(train=-0.116, test=-0.312) total time= 2.0min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=1600;, score=(train=-0.116, test=-0.316) total time= 1.9min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=1600;, score=(train=-0.117, test=-0.295) total time= 2.0min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=1600;, score=(train=-0.116, test=-0.306) total time= 2.0min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=1800;, score=(train=-0.113, test=-0.333) total time= 2.2min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=1800;, score=(train=-0.116, test=-0.312) total time= 2.2min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=1800;, score=(train=-0.116, test=-0.315) total time= 2.2min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=1000;, score=(train=-0.129, test=-0.334) total time= 1.2min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=1800;, score=(train=-0.116, test=-0.307) total time= 2.2min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=1800;, score=(train=-0.116, test=-0.294) total time= 2.2min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=2000;, score=(train=-0.116, test=-0.312) total time= 2.5min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=2000;, score=(train=-0.113, test=-0.333) total time= 2.5min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=1000;, score=(train=-0.132, test=-0.313) total time= 1.2min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=2000;, score=(train=-0.115, test=-0.315) total time= 2.4min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=1000;, score=(train=-0.132, test=-0.315) total time= 1.2min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=1000;, score=(train=-0.133, test=-0.295) total time= 1.2min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=2000;, score=(train=-0.117, test=-0.294) total time= 2.4min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=1000;, score=(train=-0.133, test=-0.306) total time= 1.2min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=2000;, score=(train=-0.116, test=-0.308) total time= 2.4min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=1200;, score=(train=-0.129, test=-0.333) total time= 1.4min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=1200;, score=(train=-0.132, test=-0.312) total time= 1.4min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=1200;, score=(train=-0.132, test=-0.315) total time= 1.4min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=1200;, score=(train=-0.134, test=-0.294) total time= 1.4min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=1200;, score=(train=-0.133, test=-0.307) total time= 1.4min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=1400;, score=(train=-0.129, test=-0.333) total time= 1.6min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=1400;, score=(train=-0.132, test=-0.312) total time= 1.6min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=1400;, score=(train=-0.132, test=-0.316) total time= 1.6min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=1400;, score=(train=-0.134, test=-0.296) total time= 1.6min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=1400;, score=(train=-0.133, test=-0.308) total time= 1.6min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=1600;, score=(train=-0.129, test=-0.333) total time= 1.9min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=1600;, score=(train=-0.132, test=-0.312) total time= 1.9min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=1600;, score=(train=-0.132, test=-0.315) total time= 1.9min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=1600;, score=(train=-0.133, test=-0.295) total time= 1.9min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=1600;, score=(train=-0.133, test=-0.307) total time= 1.9min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=1800;, score=(train=-0.132, test=-0.312) total time= 2.1min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=1800;, score=(train=-0.129, test=-0.333) total time= 2.2min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=1800;, score=(train=-0.132, test=-0.316) total time= 2.1min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=1800;, score=(train=-0.133, test=-0.295) total time= 2.1min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=1800;, score=(train=-0.133, test=-0.307) total time= 2.1min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=1, min_samples_split=8, n_estimators=1000;, score=(train=-0.152, test=-0.311) total time= 1.1min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=1, min_samples_split=8, n_estimators=1000;, score=(train=-0.148, test=-0.334) total time= 1.2min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=2000;, score=(train=-0.129, test=-0.334) total time= 2.4min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=2000;, score=(train=-0.132, test=-0.312) total time= 2.4min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=1, min_samples_split=8, n_estimators=1000;, score=(train=-0.151, test=-0.316) total time= 1.1min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=1, min_samples_split=8, n_estimators=1000;, score=(train=-0.153, test=-0.295) total time= 1.1min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=2000;, score=(train=-0.132, test=-0.315) total time= 2.3min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=1, min_samples_split=8, n_estimators=1000;, score=(train=-0.152, test=-0.307) total time= 1.1min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=2000;, score=(train=-0.134, test=-0.295) total time= 2.3min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=2000;, score=(train=-0.132, test=-0.306) total time= 2.4min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=1, min_samples_split=8, n_estimators=1200;, score=(train=-0.148, test=-0.334) total time= 1.4min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=1, min_samples_split=8, n_estimators=1200;, score=(train=-0.151, test=-0.312) total time= 1.4min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=1, min_samples_split=8, n_estimators=1200;, score=(train=-0.151, test=-0.316) total time= 1.3min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=1, min_samples_split=8, n_estimators=1200;, score=(train=-0.153, test=-0.294) total time= 1.4min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=1, min_samples_split=8, n_estimators=1200;, score=(train=-0.152, test=-0.307) total time= 1.4min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=1, min_samples_split=8, n_estimators=1400;, score=(train=-0.148, test=-0.333) total time= 1.6min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=1, min_samples_split=8, n_estimators=1400;, score=(train=-0.151, test=-0.312) total time= 1.6min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=1, min_samples_split=8, n_estimators=1400;, score=(train=-0.151, test=-0.316) total time= 1.6min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=1, min_samples_split=8, n_estimators=1400;, score=(train=-0.152, test=-0.295) total time= 1.6min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=1, min_samples_split=8, n_estimators=1400;, score=(train=-0.152, test=-0.307) total time= 1.6min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=1, min_samples_split=8, n_estimators=1600;, score=(train=-0.148, test=-0.333) total time= 1.8min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=1, min_samples_split=8, n_estimators=1600;, score=(train=-0.151, test=-0.312) total time= 1.9min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=1, min_samples_split=8, n_estimators=1600;, score=(train=-0.151, test=-0.316) total time= 1.8min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=1, min_samples_split=8, n_estimators=1600;, score=(train=-0.153, test=-0.294) total time= 1.8min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=1, min_samples_split=8, n_estimators=1600;, score=(train=-0.152, test=-0.307) total time= 1.9min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=1, min_samples_split=8, n_estimators=1800;, score=(train=-0.148, test=-0.333) total time= 2.1min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=1, min_samples_split=8, n_estimators=1800;, score=(train=-0.151, test=-0.312) total time= 2.1min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=1, min_samples_split=8, n_estimators=1800;, score=(train=-0.151, test=-0.316) total time= 2.1min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=1, min_samples_split=8, n_estimators=1800;, score=(train=-0.152, test=-0.307) total time= 2.1min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=1, min_samples_split=11, n_estimators=1000;, score=(train=-0.165, test=-0.334) total time= 1.2min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=1, min_samples_split=8, n_estimators=1800;, score=(train=-0.152, test=-0.294) total time= 2.1min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=1, min_samples_split=11, n_estimators=1000;, score=(train=-0.168, test=-0.312) total time= 1.2min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=1, min_samples_split=11, n_estimators=1000;, score=(train=-0.169, test=-0.316) total time= 1.1min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=1, min_samples_split=8, n_estimators=2000;, score=(train=-0.151, test=-0.312) total time= 2.3min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=1, min_samples_split=8, n_estimators=2000;, score=(train=-0.148, test=-0.334) total time= 2.4min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=1, min_samples_split=11, n_estimators=1000;, score=(train=-0.169, test=-0.294) total time= 1.1min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=1, min_samples_split=8, n_estimators=2000;, score=(train=-0.151, test=-0.316) total time= 2.3min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=1, min_samples_split=11, n_estimators=1000;, score=(train=-0.169, test=-0.307) total time= 1.1min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=1, min_samples_split=8, n_estimators=2000;, score=(train=-0.152, test=-0.295) total time= 2.3min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=1, min_samples_split=8, n_estimators=2000;, score=(train=-0.153, test=-0.308) total time= 2.3min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=1, min_samples_split=11, n_estimators=1200;, score=(train=-0.168, test=-0.317) total time= 1.4min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=1, min_samples_split=11, n_estimators=1200;, score=(train=-0.165, test=-0.334) total time= 1.4min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=1, min_samples_split=11, n_estimators=1200;, score=(train=-0.168, test=-0.311) total time= 1.4min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=1, min_samples_split=11, n_estimators=1200;, score=(train=-0.169, test=-0.295) total time= 1.4min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=1, min_samples_split=11, n_estimators=1200;, score=(train=-0.169, test=-0.309) total time= 1.4min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=1, min_samples_split=11, n_estimators=1400;, score=(train=-0.165, test=-0.334) total time= 1.6min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=1, min_samples_split=11, n_estimators=1400;, score=(train=-0.168, test=-0.312) total time= 1.6min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=1, min_samples_split=11, n_estimators=1400;, score=(train=-0.168, test=-0.316) total time= 1.6min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=1, min_samples_split=11, n_estimators=1400;, score=(train=-0.170, test=-0.295) total time= 1.6min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=1, min_samples_split=11, n_estimators=1400;, score=(train=-0.169, test=-0.309) total time= 1.6min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=1, min_samples_split=11, n_estimators=1600;, score=(train=-0.165, test=-0.334) total time= 1.9min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=1, min_samples_split=11, n_estimators=1600;, score=(train=-0.168, test=-0.312) total time= 1.8min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=1, min_samples_split=11, n_estimators=1600;, score=(train=-0.169, test=-0.316) total time= 1.8min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=1, min_samples_split=11, n_estimators=1600;, score=(train=-0.169, test=-0.307) total time= 1.8min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=1, min_samples_split=11, n_estimators=1600;, score=(train=-0.169, test=-0.294) total time= 1.8min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=1, min_samples_split=11, n_estimators=1800;, score=(train=-0.165, test=-0.334) total time= 2.0min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=1, min_samples_split=11, n_estimators=1800;, score=(train=-0.168, test=-0.312) total time= 2.0min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=1, min_samples_split=11, n_estimators=1800;, score=(train=-0.168, test=-0.316) total time= 2.0min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=1, min_samples_split=11, n_estimators=1800;, score=(train=-0.169, test=-0.295) total time= 2.1min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=1, min_samples_split=11, n_estimators=1800;, score=(train=-0.169, test=-0.307) total time= 2.0min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=3, min_samples_split=2, n_estimators=1000;, score=(train=-0.158, test=-0.312) total time= 1.0min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=3, min_samples_split=2, n_estimators=1000;, score=(train=-0.154, test=-0.333) total time= 1.0min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=3, min_samples_split=2, n_estimators=1000;, score=(train=-0.157, test=-0.313) total time= 1.0min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=1, min_samples_split=11, n_estimators=2000;, score=(train=-0.164, test=-0.334) total time= 2.3min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=3, min_samples_split=2, n_estimators=1000;, score=(train=-0.159, test=-0.294) total time= 1.0min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=1, min_samples_split=11, n_estimators=2000;, score=(train=-0.168, test=-0.312) total time= 2.3min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=3, min_samples_split=2, n_estimators=1000;, score=(train=-0.159, test=-0.307) total time= 1.0min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=1, min_samples_split=11, n_estimators=2000;, score=(train=-0.168, test=-0.316) total time= 2.3min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=1, min_samples_split=11, n_estimators=2000;, score=(train=-0.169, test=-0.295) total time= 2.3min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=3, min_samples_split=2, n_estimators=1200;, score=(train=-0.154, test=-0.332) total time= 1.3min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=3, min_samples_split=2, n_estimators=1200;, score=(train=-0.158, test=-0.312) total time= 1.2min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=1, min_samples_split=11, n_estimators=2000;, score=(train=-0.169, test=-0.308) total time= 2.2min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=3, min_samples_split=2, n_estimators=1200;, score=(train=-0.157, test=-0.313) total time= 1.2min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=3, min_samples_split=2, n_estimators=1200;, score=(train=-0.159, test=-0.294) total time= 1.2min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=3, min_samples_split=2, n_estimators=1200;, score=(train=-0.158, test=-0.306) total time= 1.2min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=3, min_samples_split=2, n_estimators=1400;, score=(train=-0.154, test=-0.332) total time= 1.4min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=3, min_samples_split=2, n_estimators=1400;, score=(train=-0.158, test=-0.311) total time= 1.4min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=3, min_samples_split=2, n_estimators=1400;, score=(train=-0.157, test=-0.314) total time= 1.5min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=3, min_samples_split=2, n_estimators=1400;, score=(train=-0.159, test=-0.293) total time= 1.4min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=3, min_samples_split=2, n_estimators=1400;, score=(train=-0.159, test=-0.306) total time= 1.4min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=3, min_samples_split=2, n_estimators=1600;, score=(train=-0.154, test=-0.333) total time= 1.7min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=3, min_samples_split=2, n_estimators=1600;, score=(train=-0.158, test=-0.311) total time= 1.6min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=3, min_samples_split=2, n_estimators=1600;, score=(train=-0.158, test=-0.314) total time= 1.6min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=3, min_samples_split=2, n_estimators=1600;, score=(train=-0.159, test=-0.294) total time= 1.7min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=3, min_samples_split=2, n_estimators=1600;, score=(train=-0.159, test=-0.307) total time= 1.7min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=3, min_samples_split=2, n_estimators=1800;, score=(train=-0.154, test=-0.332) total time= 1.9min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=3, min_samples_split=2, n_estimators=1800;, score=(train=-0.158, test=-0.311) total time= 1.8min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=3, min_samples_split=2, n_estimators=1800;, score=(train=-0.157, test=-0.313) total time= 1.8min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=3, min_samples_split=2, n_estimators=1800;, score=(train=-0.159, test=-0.306) total time= 1.8min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=3, min_samples_split=2, n_estimators=1800;, score=(train=-0.159, test=-0.293) total time= 1.9min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=3, min_samples_split=5, n_estimators=1000;, score=(train=-0.154, test=-0.332) total time= 1.1min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=3, min_samples_split=5, n_estimators=1000;, score=(train=-0.158, test=-0.310) total time= 1.0min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=3, min_samples_split=5, n_estimators=1000;, score=(train=-0.157, test=-0.313) total time= 1.0min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=3, min_samples_split=2, n_estimators=2000;, score=(train=-0.154, test=-0.332) total time= 2.1min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=3, min_samples_split=2, n_estimators=2000;, score=(train=-0.158, test=-0.311) total time= 2.1min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=3, min_samples_split=5, n_estimators=1000;, score=(train=-0.159, test=-0.294) total time= 1.0min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=3, min_samples_split=2, n_estimators=2000;, score=(train=-0.157, test=-0.313) total time= 2.0min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=3, min_samples_split=5, n_estimators=1000;, score=(train=-0.159, test=-0.308) total time= 1.0min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=3, min_samples_split=2, n_estimators=2000;, score=(train=-0.159, test=-0.293) total time= 2.0min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=3, min_samples_split=2, n_estimators=2000;, score=(train=-0.158, test=-0.306) total time= 2.0min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=3, min_samples_split=5, n_estimators=1200;, score=(train=-0.159, test=-0.311) total time= 1.2min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=3, min_samples_split=5, n_estimators=1200;, score=(train=-0.154, test=-0.333) total time= 1.3min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=3, min_samples_split=5, n_estimators=1200;, score=(train=-0.159, test=-0.294) total time= 1.2min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=3, min_samples_split=5, n_estimators=1200;, score=(train=-0.157, test=-0.313) total time= 1.2min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=3, min_samples_split=5, n_estimators=1200;, score=(train=-0.158, test=-0.306) total time= 1.2min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=3, min_samples_split=5, n_estimators=1400;, score=(train=-0.154, test=-0.334) total time= 1.5min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=3, min_samples_split=5, n_estimators=1400;, score=(train=-0.158, test=-0.312) total time= 1.4min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=3, min_samples_split=5, n_estimators=1400;, score=(train=-0.157, test=-0.314) total time= 1.4min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=3, min_samples_split=5, n_estimators=1400;, score=(train=-0.159, test=-0.294) total time= 1.4min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=3, min_samples_split=5, n_estimators=1400;, score=(train=-0.159, test=-0.306) total time= 1.4min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=3, min_samples_split=5, n_estimators=1600;, score=(train=-0.158, test=-0.312) total time= 1.6min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=3, min_samples_split=5, n_estimators=1600;, score=(train=-0.154, test=-0.333) total time= 1.7min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=3, min_samples_split=5, n_estimators=1600;, score=(train=-0.157, test=-0.314) total time= 1.6min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=3, min_samples_split=5, n_estimators=1600;, score=(train=-0.159, test=-0.293) total time= 1.6min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=3, min_samples_split=5, n_estimators=1600;, score=(train=-0.159, test=-0.306) total time= 1.6min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=3, min_samples_split=5, n_estimators=1800;, score=(train=-0.154, test=-0.332) total time= 1.9min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=3, min_samples_split=5, n_estimators=1800;, score=(train=-0.158, test=-0.312) total time= 1.8min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=3, min_samples_split=5, n_estimators=1800;, score=(train=-0.157, test=-0.314) total time= 1.8min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=3, min_samples_split=5, n_estimators=1800;, score=(train=-0.159, test=-0.294) total time= 1.9min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=3, min_samples_split=5, n_estimators=1800;, score=(train=-0.159, test=-0.306) total time= 1.8min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=3, min_samples_split=8, n_estimators=1000;, score=(train=-0.170, test=-0.311) total time= 1.0min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=3, min_samples_split=8, n_estimators=1000;, score=(train=-0.165, test=-0.333) total time= 1.0min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=3, min_samples_split=8, n_estimators=1000;, score=(train=-0.169, test=-0.314) total time=  59.9s\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=3, min_samples_split=5, n_estimators=2000;, score=(train=-0.154, test=-0.333) total time= 2.1min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=3, min_samples_split=8, n_estimators=1000;, score=(train=-0.171, test=-0.294) total time= 1.0min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=3, min_samples_split=5, n_estimators=2000;, score=(train=-0.159, test=-0.311) total time= 2.1min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=3, min_samples_split=5, n_estimators=2000;, score=(train=-0.157, test=-0.313) total time= 2.0min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=3, min_samples_split=5, n_estimators=2000;, score=(train=-0.159, test=-0.293) total time= 2.0min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=3, min_samples_split=8, n_estimators=1000;, score=(train=-0.170, test=-0.307) total time= 1.0min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=3, min_samples_split=5, n_estimators=2000;, score=(train=-0.158, test=-0.306) total time= 2.0min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=3, min_samples_split=8, n_estimators=1200;, score=(train=-0.165, test=-0.332) total time= 1.3min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=3, min_samples_split=8, n_estimators=1200;, score=(train=-0.170, test=-0.312) total time= 1.2min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=3, min_samples_split=8, n_estimators=1200;, score=(train=-0.171, test=-0.293) total time= 1.2min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=3, min_samples_split=8, n_estimators=1200;, score=(train=-0.168, test=-0.314) total time= 1.2min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=3, min_samples_split=8, n_estimators=1200;, score=(train=-0.170, test=-0.307) total time= 1.2min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=3, min_samples_split=8, n_estimators=1400;, score=(train=-0.169, test=-0.314) total time= 1.4min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=3, min_samples_split=8, n_estimators=1400;, score=(train=-0.165, test=-0.333) total time= 1.4min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=3, min_samples_split=8, n_estimators=1400;, score=(train=-0.169, test=-0.311) total time= 1.5min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=3, min_samples_split=8, n_estimators=1400;, score=(train=-0.170, test=-0.307) total time= 1.4min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=3, min_samples_split=8, n_estimators=1400;, score=(train=-0.171, test=-0.294) total time= 1.4min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=3, min_samples_split=8, n_estimators=1600;, score=(train=-0.165, test=-0.332) total time= 1.6min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=3, min_samples_split=8, n_estimators=1600;, score=(train=-0.169, test=-0.312) total time= 1.6min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=3, min_samples_split=8, n_estimators=1600;, score=(train=-0.169, test=-0.314) total time= 1.6min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=3, min_samples_split=8, n_estimators=1600;, score=(train=-0.170, test=-0.294) total time= 1.6min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=3, min_samples_split=8, n_estimators=1600;, score=(train=-0.170, test=-0.307) total time= 1.6min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=3, min_samples_split=8, n_estimators=1800;, score=(train=-0.165, test=-0.333) total time= 1.9min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=3, min_samples_split=8, n_estimators=1800;, score=(train=-0.169, test=-0.311) total time= 1.8min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=3, min_samples_split=8, n_estimators=1800;, score=(train=-0.169, test=-0.314) total time= 1.8min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=3, min_samples_split=8, n_estimators=1800;, score=(train=-0.171, test=-0.293) total time= 1.8min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=3, min_samples_split=8, n_estimators=1800;, score=(train=-0.170, test=-0.306) total time= 1.8min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=3, min_samples_split=11, n_estimators=1000;, score=(train=-0.180, test=-0.332) total time= 1.0min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=3, min_samples_split=11, n_estimators=1000;, score=(train=-0.185, test=-0.311) total time= 1.0min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=3, min_samples_split=11, n_estimators=1000;, score=(train=-0.184, test=-0.314) total time=  58.6s\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=3, min_samples_split=8, n_estimators=2000;, score=(train=-0.170, test=-0.312) total time= 2.0min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=3, min_samples_split=8, n_estimators=2000;, score=(train=-0.165, test=-0.333) total time= 2.0min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=3, min_samples_split=11, n_estimators=1000;, score=(train=-0.186, test=-0.294) total time=  59.7s\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=3, min_samples_split=8, n_estimators=2000;, score=(train=-0.169, test=-0.314) total time= 2.0min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=3, min_samples_split=8, n_estimators=2000;, score=(train=-0.171, test=-0.294) total time= 2.0min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=3, min_samples_split=11, n_estimators=1000;, score=(train=-0.185, test=-0.307) total time= 1.0min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=3, min_samples_split=8, n_estimators=2000;, score=(train=-0.170, test=-0.306) total time= 2.0min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=3, min_samples_split=11, n_estimators=1200;, score=(train=-0.180, test=-0.333) total time= 1.2min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=3, min_samples_split=11, n_estimators=1200;, score=(train=-0.185, test=-0.312) total time= 1.2min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=3, min_samples_split=11, n_estimators=1200;, score=(train=-0.184, test=-0.314) total time= 1.2min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=3, min_samples_split=11, n_estimators=1200;, score=(train=-0.186, test=-0.294) total time= 1.2min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=3, min_samples_split=11, n_estimators=1200;, score=(train=-0.185, test=-0.308) total time= 1.2min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=3, min_samples_split=11, n_estimators=1400;, score=(train=-0.185, test=-0.312) total time= 1.4min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=3, min_samples_split=11, n_estimators=1400;, score=(train=-0.181, test=-0.333) total time= 1.4min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=3, min_samples_split=11, n_estimators=1400;, score=(train=-0.184, test=-0.315) total time= 1.4min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=3, min_samples_split=11, n_estimators=1400;, score=(train=-0.186, test=-0.293) total time= 1.4min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=3, min_samples_split=11, n_estimators=1400;, score=(train=-0.186, test=-0.307) total time= 1.4min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=3, min_samples_split=11, n_estimators=1600;, score=(train=-0.181, test=-0.333) total time= 1.6min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=3, min_samples_split=11, n_estimators=1600;, score=(train=-0.185, test=-0.311) total time= 1.6min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=3, min_samples_split=11, n_estimators=1600;, score=(train=-0.184, test=-0.314) total time= 1.6min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=3, min_samples_split=11, n_estimators=1600;, score=(train=-0.186, test=-0.293) total time= 1.6min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=3, min_samples_split=11, n_estimators=1600;, score=(train=-0.185, test=-0.307) total time= 1.6min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=3, min_samples_split=11, n_estimators=1800;, score=(train=-0.180, test=-0.333) total time= 1.8min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=3, min_samples_split=11, n_estimators=1800;, score=(train=-0.185, test=-0.311) total time= 1.8min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=3, min_samples_split=11, n_estimators=1800;, score=(train=-0.184, test=-0.314) total time= 1.8min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=3, min_samples_split=11, n_estimators=1800;, score=(train=-0.186, test=-0.294) total time= 1.8min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=5, min_samples_split=2, n_estimators=1000;, score=(train=-0.189, test=-0.332) total time=  56.0s\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=3, min_samples_split=11, n_estimators=1800;, score=(train=-0.186, test=-0.306) total time= 1.8min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=5, min_samples_split=2, n_estimators=1000;, score=(train=-0.193, test=-0.313) total time=  56.2s\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=5, min_samples_split=2, n_estimators=1000;, score=(train=-0.193, test=-0.314) total time=  55.5s\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=3, min_samples_split=11, n_estimators=2000;, score=(train=-0.180, test=-0.333) total time= 2.0min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=3, min_samples_split=11, n_estimators=2000;, score=(train=-0.185, test=-0.312) total time= 2.0min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=5, min_samples_split=2, n_estimators=1000;, score=(train=-0.195, test=-0.294) total time=  56.4s\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=3, min_samples_split=11, n_estimators=2000;, score=(train=-0.184, test=-0.314) total time= 2.0min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=5, min_samples_split=2, n_estimators=1000;, score=(train=-0.194, test=-0.307) total time=  56.4s\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=3, min_samples_split=11, n_estimators=2000;, score=(train=-0.186, test=-0.294) total time= 2.0min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=3, min_samples_split=11, n_estimators=2000;, score=(train=-0.185, test=-0.307) total time= 2.0min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=5, min_samples_split=2, n_estimators=1200;, score=(train=-0.189, test=-0.333) total time= 1.1min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=5, min_samples_split=2, n_estimators=1200;, score=(train=-0.194, test=-0.312) total time= 1.2min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=5, min_samples_split=2, n_estimators=1200;, score=(train=-0.195, test=-0.294) total time= 1.1min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=5, min_samples_split=2, n_estimators=1200;, score=(train=-0.193, test=-0.314) total time= 1.1min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=5, min_samples_split=2, n_estimators=1200;, score=(train=-0.194, test=-0.306) total time= 1.1min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=5, min_samples_split=2, n_estimators=1400;, score=(train=-0.189, test=-0.333) total time= 1.3min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=5, min_samples_split=2, n_estimators=1400;, score=(train=-0.194, test=-0.312) total time= 1.3min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=5, min_samples_split=2, n_estimators=1400;, score=(train=-0.193, test=-0.314) total time= 1.3min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=5, min_samples_split=2, n_estimators=1400;, score=(train=-0.195, test=-0.294) total time= 1.3min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=5, min_samples_split=2, n_estimators=1400;, score=(train=-0.194, test=-0.307) total time= 1.3min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=5, min_samples_split=2, n_estimators=1600;, score=(train=-0.193, test=-0.312) total time= 1.5min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=5, min_samples_split=2, n_estimators=1600;, score=(train=-0.189, test=-0.332) total time= 1.5min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=5, min_samples_split=2, n_estimators=1600;, score=(train=-0.193, test=-0.314) total time= 1.5min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=5, min_samples_split=2, n_estimators=1600;, score=(train=-0.195, test=-0.294) total time= 1.5min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=5, min_samples_split=2, n_estimators=1600;, score=(train=-0.194, test=-0.306) total time= 1.5min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=5, min_samples_split=2, n_estimators=1800;, score=(train=-0.189, test=-0.333) total time= 1.7min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=5, min_samples_split=2, n_estimators=1800;, score=(train=-0.193, test=-0.312) total time= 1.7min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=5, min_samples_split=2, n_estimators=1800;, score=(train=-0.193, test=-0.314) total time= 1.6min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=5, min_samples_split=2, n_estimators=1800;, score=(train=-0.195, test=-0.294) total time= 1.6min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=5, min_samples_split=5, n_estimators=1000;, score=(train=-0.194, test=-0.311) total time=  55.3s\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=5, min_samples_split=5, n_estimators=1000;, score=(train=-0.188, test=-0.332) total time=  58.6s\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=5, min_samples_split=2, n_estimators=1800;, score=(train=-0.194, test=-0.308) total time= 1.7min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=5, min_samples_split=5, n_estimators=1000;, score=(train=-0.193, test=-0.314) total time=  54.5s\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=5, min_samples_split=2, n_estimators=2000;, score=(train=-0.189, test=-0.333) total time= 1.9min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=5, min_samples_split=2, n_estimators=2000;, score=(train=-0.194, test=-0.313) total time= 1.8min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=5, min_samples_split=5, n_estimators=1000;, score=(train=-0.194, test=-0.294) total time=  54.7s\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=5, min_samples_split=5, n_estimators=1000;, score=(train=-0.194, test=-0.307) total time=  54.7s\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=5, min_samples_split=2, n_estimators=2000;, score=(train=-0.193, test=-0.314) total time= 1.8min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=5, min_samples_split=2, n_estimators=2000;, score=(train=-0.195, test=-0.294) total time= 1.8min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=5, min_samples_split=2, n_estimators=2000;, score=(train=-0.194, test=-0.307) total time= 1.8min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=5, min_samples_split=5, n_estimators=1200;, score=(train=-0.189, test=-0.332) total time= 1.1min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=5, min_samples_split=5, n_estimators=1200;, score=(train=-0.194, test=-0.311) total time= 1.1min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=5, min_samples_split=5, n_estimators=1200;, score=(train=-0.193, test=-0.314) total time= 1.1min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=5, min_samples_split=5, n_estimators=1200;, score=(train=-0.195, test=-0.293) total time= 1.1min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=5, min_samples_split=5, n_estimators=1200;, score=(train=-0.194, test=-0.307) total time= 1.1min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=5, min_samples_split=5, n_estimators=1400;, score=(train=-0.189, test=-0.333) total time= 1.3min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=5, min_samples_split=5, n_estimators=1400;, score=(train=-0.193, test=-0.311) total time= 1.3min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=5, min_samples_split=5, n_estimators=1400;, score=(train=-0.193, test=-0.314) total time= 1.3min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=5, min_samples_split=5, n_estimators=1400;, score=(train=-0.194, test=-0.294) total time= 1.3min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=5, min_samples_split=5, n_estimators=1400;, score=(train=-0.195, test=-0.306) total time= 1.3min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=5, min_samples_split=5, n_estimators=1600;, score=(train=-0.189, test=-0.333) total time= 1.5min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=5, min_samples_split=5, n_estimators=1600;, score=(train=-0.193, test=-0.312) total time= 1.5min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=5, min_samples_split=5, n_estimators=1600;, score=(train=-0.193, test=-0.314) total time= 1.5min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=5, min_samples_split=5, n_estimators=1600;, score=(train=-0.194, test=-0.307) total time= 1.5min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=5, min_samples_split=5, n_estimators=1600;, score=(train=-0.195, test=-0.294) total time= 1.5min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=5, min_samples_split=5, n_estimators=1800;, score=(train=-0.189, test=-0.333) total time= 1.7min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=5, min_samples_split=5, n_estimators=1800;, score=(train=-0.193, test=-0.311) total time= 1.7min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=5, min_samples_split=5, n_estimators=1800;, score=(train=-0.193, test=-0.314) total time= 1.6min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=5, min_samples_split=5, n_estimators=1800;, score=(train=-0.195, test=-0.294) total time= 1.7min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=5, min_samples_split=5, n_estimators=1800;, score=(train=-0.194, test=-0.307) total time= 1.7min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=5, min_samples_split=8, n_estimators=1000;, score=(train=-0.189, test=-0.332) total time=  57.1s\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=5, min_samples_split=8, n_estimators=1000;, score=(train=-0.193, test=-0.313) total time=  58.2s\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=5, min_samples_split=5, n_estimators=2000;, score=(train=-0.189, test=-0.333) total time= 1.9min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=5, min_samples_split=8, n_estimators=1000;, score=(train=-0.193, test=-0.315) total time=  57.5s\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=5, min_samples_split=5, n_estimators=2000;, score=(train=-0.193, test=-0.312) total time= 1.8min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=5, min_samples_split=8, n_estimators=1000;, score=(train=-0.194, test=-0.294) total time=  54.7s\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=5, min_samples_split=5, n_estimators=2000;, score=(train=-0.193, test=-0.314) total time= 1.8min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=5, min_samples_split=5, n_estimators=2000;, score=(train=-0.194, test=-0.294) total time= 1.8min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=5, min_samples_split=8, n_estimators=1000;, score=(train=-0.194, test=-0.307) total time=  55.2s\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=5, min_samples_split=5, n_estimators=2000;, score=(train=-0.194, test=-0.307) total time= 1.8min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=5, min_samples_split=8, n_estimators=1200;, score=(train=-0.189, test=-0.333) total time= 1.1min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=5, min_samples_split=8, n_estimators=1200;, score=(train=-0.194, test=-0.311) total time= 1.1min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=5, min_samples_split=8, n_estimators=1200;, score=(train=-0.193, test=-0.314) total time= 1.1min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=5, min_samples_split=8, n_estimators=1200;, score=(train=-0.195, test=-0.294) total time= 1.1min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=5, min_samples_split=8, n_estimators=1200;, score=(train=-0.194, test=-0.307) total time= 1.1min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=5, min_samples_split=8, n_estimators=1400;, score=(train=-0.189, test=-0.333) total time= 1.3min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=5, min_samples_split=8, n_estimators=1400;, score=(train=-0.193, test=-0.312) total time= 1.3min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=5, min_samples_split=8, n_estimators=1400;, score=(train=-0.193, test=-0.315) total time= 1.3min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=5, min_samples_split=8, n_estimators=1400;, score=(train=-0.195, test=-0.294) total time= 1.3min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=5, min_samples_split=8, n_estimators=1400;, score=(train=-0.194, test=-0.307) total time= 1.3min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=5, min_samples_split=8, n_estimators=1600;, score=(train=-0.189, test=-0.333) total time= 1.5min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=5, min_samples_split=8, n_estimators=1600;, score=(train=-0.193, test=-0.311) total time= 1.5min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=5, min_samples_split=8, n_estimators=1600;, score=(train=-0.193, test=-0.314) total time= 1.5min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=5, min_samples_split=8, n_estimators=1600;, score=(train=-0.195, test=-0.294) total time= 1.5min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=5, min_samples_split=8, n_estimators=1600;, score=(train=-0.194, test=-0.307) total time= 1.5min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=5, min_samples_split=8, n_estimators=1800;, score=(train=-0.189, test=-0.332) total time= 1.7min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=5, min_samples_split=8, n_estimators=1800;, score=(train=-0.193, test=-0.312) total time= 1.7min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=5, min_samples_split=8, n_estimators=1800;, score=(train=-0.193, test=-0.314) total time= 1.7min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=5, min_samples_split=8, n_estimators=1800;, score=(train=-0.194, test=-0.307) total time= 1.7min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=5, min_samples_split=8, n_estimators=1800;, score=(train=-0.195, test=-0.294) total time= 1.7min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=5, min_samples_split=11, n_estimators=1000;, score=(train=-0.192, test=-0.334) total time=  58.7s\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=5, min_samples_split=11, n_estimators=1000;, score=(train=-0.197, test=-0.311) total time=  56.5s\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=5, min_samples_split=8, n_estimators=2000;, score=(train=-0.189, test=-0.333) total time= 1.9min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=5, min_samples_split=8, n_estimators=2000;, score=(train=-0.193, test=-0.312) total time= 1.9min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=5, min_samples_split=11, n_estimators=1000;, score=(train=-0.197, test=-0.314) total time=  55.0s\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=5, min_samples_split=11, n_estimators=1000;, score=(train=-0.199, test=-0.294) total time=  55.5s\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=5, min_samples_split=8, n_estimators=2000;, score=(train=-0.193, test=-0.314) total time= 1.9min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=5, min_samples_split=8, n_estimators=2000;, score=(train=-0.195, test=-0.294) total time= 1.8min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=5, min_samples_split=11, n_estimators=1000;, score=(train=-0.198, test=-0.307) total time=  55.2s\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=5, min_samples_split=8, n_estimators=2000;, score=(train=-0.194, test=-0.307) total time= 1.8min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=5, min_samples_split=11, n_estimators=1200;, score=(train=-0.193, test=-0.333) total time= 1.1min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=5, min_samples_split=11, n_estimators=1200;, score=(train=-0.197, test=-0.312) total time= 1.1min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=5, min_samples_split=11, n_estimators=1200;, score=(train=-0.196, test=-0.314) total time= 1.1min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=5, min_samples_split=11, n_estimators=1200;, score=(train=-0.198, test=-0.294) total time= 1.1min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=5, min_samples_split=11, n_estimators=1200;, score=(train=-0.198, test=-0.307) total time= 1.1min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=5, min_samples_split=11, n_estimators=1400;, score=(train=-0.193, test=-0.333) total time= 1.3min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=5, min_samples_split=11, n_estimators=1400;, score=(train=-0.197, test=-0.312) total time= 1.3min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=5, min_samples_split=11, n_estimators=1400;, score=(train=-0.197, test=-0.313) total time= 1.3min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=5, min_samples_split=11, n_estimators=1400;, score=(train=-0.198, test=-0.307) total time= 1.3min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=5, min_samples_split=11, n_estimators=1400;, score=(train=-0.198, test=-0.294) total time= 1.3min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=5, min_samples_split=11, n_estimators=1600;, score=(train=-0.192, test=-0.333) total time= 1.5min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=5, min_samples_split=11, n_estimators=1600;, score=(train=-0.197, test=-0.312) total time= 1.5min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=5, min_samples_split=11, n_estimators=1600;, score=(train=-0.196, test=-0.314) total time= 1.5min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=5, min_samples_split=11, n_estimators=1600;, score=(train=-0.198, test=-0.293) total time= 1.5min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=5, min_samples_split=11, n_estimators=1600;, score=(train=-0.198, test=-0.308) total time= 1.5min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=5, min_samples_split=11, n_estimators=1800;, score=(train=-0.192, test=-0.333) total time= 1.7min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=5, min_samples_split=11, n_estimators=1800;, score=(train=-0.197, test=-0.312) total time= 1.7min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=5, min_samples_split=11, n_estimators=1800;, score=(train=-0.196, test=-0.314) total time= 1.5min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=5, min_samples_split=11, n_estimators=1800;, score=(train=-0.198, test=-0.295) total time= 1.6min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=5, min_samples_split=11, n_estimators=1800;, score=(train=-0.198, test=-0.307) total time= 1.6min\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=5, min_samples_split=11, n_estimators=2000;, score=(train=-0.197, test=-0.312) total time= 1.7min\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=5, min_samples_split=11, n_estimators=2000;, score=(train=-0.192, test=-0.334) total time= 1.7min\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=5, min_samples_split=11, n_estimators=2000;, score=(train=-0.197, test=-0.314) total time= 1.6min\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=5, min_samples_split=11, n_estimators=2000;, score=(train=-0.198, test=-0.294) total time= 1.6min\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=5, min_samples_split=11, n_estimators=2000;, score=(train=-0.198, test=-0.307) total time= 1.6min\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-30 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-30 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-30 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-30 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-30 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-30 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-30 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-30 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-30 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-30 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-30 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-30 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-30 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-30 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-30 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-30 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-30 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-30 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-30 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-30 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-30 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-30 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-30 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-30 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-30 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-30 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-30 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-30 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-30 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-30 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-30 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-30 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-30 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-30 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-30 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-30 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-30 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-30 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-30 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-30 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-30 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-30 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-30 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-30\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=RandomForestRegressor(max_features=0.5), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [10, 15, 20, 25, 30],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 3, 5],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 8, 11],\n",
       "                         &#x27;n_estimators&#x27;: [1000, 1200, 1400, 1600, 1800, 2000]},\n",
       "             return_train_score=True, scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-116\" type=\"checkbox\" ><label for=\"sk-estimator-id-116\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=RandomForestRegressor(max_features=0.5), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [10, 15, 20, 25, 30],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 3, 5],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 8, 11],\n",
       "                         &#x27;n_estimators&#x27;: [1000, 1200, 1400, 1600, 1800, 2000]},\n",
       "             return_train_score=True, scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
       "             verbose=3)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-117\" type=\"checkbox\" ><label for=\"sk-estimator-id-117\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: RandomForestRegressor</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(max_depth=15, max_features=0.5, min_samples_leaf=3,\n",
       "                      min_samples_split=8, n_estimators=1800)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-118\" type=\"checkbox\" ><label for=\"sk-estimator-id-118\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(max_depth=15, max_features=0.5, min_samples_leaf=3,\n",
       "                      min_samples_split=8, n_estimators=1800)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=RandomForestRegressor(max_features=0.5), n_jobs=-1,\n",
       "             param_grid={'max_depth': [10, 15, 20, 25, 30],\n",
       "                         'min_samples_leaf': [1, 3, 5],\n",
       "                         'min_samples_split': [2, 5, 8, 11],\n",
       "                         'n_estimators': [1000, 1200, 1400, 1600, 1800, 2000]},\n",
       "             return_train_score=True, scoring='neg_root_mean_squared_error',\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters_to_test = {\n",
    "    \"n_estimators\": [1000, 1200, 1400, 1600, 1800, 2000],\n",
    "    \"max_depth\": [10, 15, 20, 25, 30],\n",
    "    \"min_samples_split\": [2, 5, 8, 11],\n",
    "    \"min_samples_leaf\": [1, 3, 5],\n",
    "}\n",
    "\n",
    "rf_preprocessing_test = RandomForestRegressor(max_features=0.5)\n",
    "\n",
    "grid_search_preprocessing_test = GridSearchCV(\n",
    "    estimator=rf_preprocessing_test,\n",
    "    param_grid=hyperparameters_to_test,\n",
    "    cv=kfold,\n",
    "    return_train_score=True,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    n_jobs=-1,\n",
    "    verbose=3,\n",
    ")\n",
    "\n",
    "grid_search_preprocessing_test.fit(X_final, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.3109312635815472)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-grid_search_preprocessing_test.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 15,\n",
       " 'min_samples_leaf': 3,\n",
       " 'min_samples_split': 8,\n",
       " 'n_estimators': 1800}"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_preprocessing_test.best_params_\n",
    "# {'max_depth': 15,\n",
    "#  'min_samples_leaf': 3,\n",
    "#  'min_samples_split': 8,\n",
    "#  'n_estimators': 1800}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearch isn't the most effective approach to the hyperparameter tuning problem. In the further part of the project I'll use Optuna to tune hyperparameters as it seems to be a more sophisticated and efficient approach. Let's create some methods to make tests easy to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.typing import ArrayLike\n",
    "from optuna import create_study, Study, Trial\n",
    "from optuna.visualization import plot_optimization_history\n",
    "from plotly.io import show\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "\n",
    "kfold = kfold = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "model_parameters = {}\n",
    "\n",
    "\n",
    "def score_trial(\n",
    "    model: BaseEstimator, X: ArrayLike, y: ArrayLike, kfold: KFold\n",
    ") -> float:\n",
    "    return -cross_val_score(\n",
    "        model,\n",
    "        X,\n",
    "        y,\n",
    "        cv=kfold,\n",
    "        scoring=\"neg_root_mean_squared_error\",\n",
    "        n_jobs=-1,\n",
    "    ).mean()\n",
    "\n",
    "\n",
    "def get_objective_func(model_type: type, X: ArrayLike, y: ArrayLike, kfold: KFold):\n",
    "    def objective(trial: Trial) -> float:\n",
    "        params = model_parameters[model_type](trial)\n",
    "\n",
    "        model = model_type(**params)\n",
    "\n",
    "        return score_trial(model, X, y, kfold)\n",
    "\n",
    "    return objective\n",
    "\n",
    "\n",
    "def run_study(\n",
    "    model_type: type,\n",
    "    X: ArrayLike,\n",
    "    y: ArrayLike,\n",
    "    kfold: KFold,\n",
    "    n_trials: int = 100,\n",
    "    plot_opt_history: bool = True,\n",
    ") -> Study:\n",
    "    study = create_study(direction=\"minimize\")\n",
    "    objective_fun = get_objective_func(model_type, X, y, kfold)\n",
    "\n",
    "    study.optimize(objective_fun, n_trials=n_trials, n_jobs=-1, show_progress_bar=True)\n",
    "\n",
    "    print(\"Best parameters:\", study.best_params)\n",
    "    print(\"Best RMSE:\", study.best_value)\n",
    "\n",
    "    if plot_opt_history:\n",
    "        fig = plot_optimization_history(study)\n",
    "        show(fig)\n",
    "\n",
    "    return study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try different models from sklearn to check which one performs the best, in particular we'll use:\n",
    "- RandomForest\n",
    "- ExtraTrees\n",
    "- SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:59:56,183] A new study created in memory with name: no-name-cafdd2cc-b843-4136-b71b-481ccac0c9cd\n",
      "Best trial: 0. Best value: 0.312316:   0%|          | 1/200 [00:40<2:15:13, 40.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:00:36,948] Trial 0 finished with value: 0.3123159316435803 and parameters: {'n_estimators': 575, 'max_depth': 27, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.3123159316435803.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.311333:   1%|          | 2/200 [01:06<1:44:28, 31.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:01:02,234] Trial 1 finished with value: 0.3113326270370818 and parameters: {'n_estimators': 1153, 'max_depth': 17, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.3113326270370818.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.311199:   2%|▏         | 3/200 [01:38<1:44:32, 31.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:01:34,282] Trial 3 finished with value: 0.31119851561135764 and parameters: {'n_estimators': 1130, 'max_depth': 13, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.31119851561135764.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.311199:   2%|▏         | 4/200 [02:09<1:43:57, 31.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:02:06,083] Trial 2 finished with value: 0.31281125638205276 and parameters: {'n_estimators': 951, 'max_depth': 28, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.31119851561135764.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.311199:   2%|▎         | 5/200 [02:43<1:46:01, 32.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:02:40,122] Trial 5 finished with value: 0.31140771445138876 and parameters: {'n_estimators': 1135, 'max_depth': 24, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.31119851561135764.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.311199:   3%|▎         | 6/200 [03:19<1:48:34, 33.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:03:15,567] Trial 4 finished with value: 0.3121424679620722 and parameters: {'n_estimators': 1039, 'max_depth': 23, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.31119851561135764.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.311199:   4%|▎         | 7/200 [03:37<1:31:25, 28.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:03:33,360] Trial 10 finished with value: 0.3116758118350818 and parameters: {'n_estimators': 1733, 'max_depth': 17, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.31119851561135764.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.311199:   4%|▍         | 8/200 [04:03<1:28:50, 27.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:03:59,713] Trial 7 finished with value: 0.31209807028843195 and parameters: {'n_estimators': 736, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.31119851561135764.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.311199:   4%|▍         | 9/200 [04:42<1:39:15, 31.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:04:38,418] Trial 6 finished with value: 0.31162819901248234 and parameters: {'n_estimators': 1506, 'max_depth': 26, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.31119851561135764.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.311199:   5%|▌         | 10/200 [05:16<1:41:24, 32.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:05:12,310] Trial 8 finished with value: 0.3122191315180872 and parameters: {'n_estimators': 537, 'max_depth': 22, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.31119851561135764.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.311199:   6%|▌         | 11/200 [05:30<1:23:48, 26.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:05:26,635] Trial 9 finished with value: 0.3115414539716882 and parameters: {'n_estimators': 1496, 'max_depth': 17, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.31119851561135764.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.311199:   6%|▌         | 12/200 [05:59<1:25:14, 27.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:05:55,209] Trial 12 finished with value: 0.31176946230943425 and parameters: {'n_estimators': 726, 'max_depth': 30, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.31119851561135764.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.311199:   6%|▋         | 13/200 [06:42<1:40:33, 32.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:06:39,125] Trial 11 finished with value: 0.31127282403612805 and parameters: {'n_estimators': 1726, 'max_depth': 21, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.31119851561135764.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.31103:   7%|▋         | 14/200 [07:42<2:05:11, 40.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:07:38,263] Trial 14 finished with value: 0.3110302500094346 and parameters: {'n_estimators': 1482, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 14 with value: 0.3110302500094346.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.31103:   8%|▊         | 15/200 [07:51<1:35:24, 30.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:07:47,342] Trial 13 finished with value: 0.31135380293169057 and parameters: {'n_estimators': 1872, 'max_depth': 25, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 14 with value: 0.3110302500094346.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.31103:   8%|▊         | 16/200 [08:29<1:41:16, 33.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:08:25,198] Trial 15 finished with value: 0.312713624263532 and parameters: {'n_estimators': 1194, 'max_depth': 28, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 14 with value: 0.3110302500094346.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.31103:   8%|▊         | 17/200 [08:39<1:20:04, 26.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:08:35,706] Trial 16 finished with value: 0.31153238659422583 and parameters: {'n_estimators': 1247, 'max_depth': 11, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 14 with value: 0.3110302500094346.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.31103:   9%|▉         | 18/200 [08:55<1:10:30, 23.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:08:51,948] Trial 17 finished with value: 0.31152597916904484 and parameters: {'n_estimators': 603, 'max_depth': 28, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 14 with value: 0.3110302500094346.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.31103:  10%|▉         | 19/200 [09:55<1:42:47, 34.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:09:51,249] Trial 19 finished with value: 0.3115266320358151 and parameters: {'n_estimators': 1494, 'max_depth': 13, 'min_samples_split': 11, 'min_samples_leaf': 4}. Best is trial 14 with value: 0.3110302500094346.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.31103:  10%|█         | 20/200 [10:33<1:46:16, 35.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:10:29,818] Trial 18 finished with value: 0.3124432866585848 and parameters: {'n_estimators': 1826, 'max_depth': 26, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 14 with value: 0.3110302500094346.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.31103:  10%|█         | 21/200 [11:06<1:43:28, 34.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:11:02,784] Trial 20 finished with value: 0.3120396316110664 and parameters: {'n_estimators': 1113, 'max_depth': 23, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 14 with value: 0.3110302500094346.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.31103:  11%|█         | 22/200 [11:26<1:29:56, 30.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:11:22,922] Trial 21 finished with value: 0.31171212755995736 and parameters: {'n_estimators': 1461, 'max_depth': 10, 'min_samples_split': 11, 'min_samples_leaf': 2}. Best is trial 14 with value: 0.3110302500094346.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.31103:  12%|█▏        | 23/200 [11:51<1:24:51, 28.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:11:48,058] Trial 22 finished with value: 0.31142399277548466 and parameters: {'n_estimators': 1290, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 14 with value: 0.3110302500094346.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.31103:  12%|█▏        | 24/200 [12:09<1:14:20, 25.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:12:05,412] Trial 23 finished with value: 0.31133529246022446 and parameters: {'n_estimators': 1394, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 14 with value: 0.3110302500094346.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.31103:  12%|█▎        | 25/200 [12:48<1:25:39, 29.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:12:44,178] Trial 24 finished with value: 0.311697989361281 and parameters: {'n_estimators': 1869, 'max_depth': 10, 'min_samples_split': 11, 'min_samples_leaf': 2}. Best is trial 14 with value: 0.3110302500094346.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.31103:  13%|█▎        | 26/200 [13:35<1:40:56, 34.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:13:31,678] Trial 25 finished with value: 0.3113577324576172 and parameters: {'n_estimators': 1985, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 14 with value: 0.3110302500094346.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.31103:  14%|█▎        | 27/200 [13:53<1:25:34, 29.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:13:49,391] Trial 26 finished with value: 0.3111018137920071 and parameters: {'n_estimators': 1361, 'max_depth': 11, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 14 with value: 0.3110302500094346.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.31103:  14%|█▍        | 28/200 [14:17<1:20:42, 28.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:14:13,991] Trial 27 finished with value: 0.31146732629631274 and parameters: {'n_estimators': 1414, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 14 with value: 0.3110302500094346.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.31103:  14%|█▍        | 29/200 [14:49<1:23:38, 29.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:14:46,114] Trial 28 finished with value: 0.31145659375674234 and parameters: {'n_estimators': 1476, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 14 with value: 0.3110302500094346.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.31103:  15%|█▌        | 30/200 [15:11<1:16:50, 27.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:15:08,037] Trial 29 finished with value: 0.31126003693903065 and parameters: {'n_estimators': 1446, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 14 with value: 0.3110302500094346.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.31103:  16%|█▌        | 31/200 [15:34<1:12:36, 25.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:15:30,684] Trial 30 finished with value: 0.31130074100134786 and parameters: {'n_estimators': 1370, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 14 with value: 0.3110302500094346.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.31103:  16%|█▌        | 32/200 [15:57<1:09:29, 24.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:15:53,262] Trial 31 finished with value: 0.31128560797786126 and parameters: {'n_estimators': 1384, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 14 with value: 0.3110302500094346.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.31103:  16%|█▋        | 33/200 [16:39<1:23:22, 29.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:16:35,201] Trial 32 finished with value: 0.3112408654151385 and parameters: {'n_estimators': 1657, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 14 with value: 0.3110302500094346.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.310907:  17%|█▋        | 34/200 [17:20<1:32:51, 33.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:17:17,175] Trial 33 finished with value: 0.3109070943013822 and parameters: {'n_estimators': 1625, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.3109070943013822.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.310907:  18%|█▊        | 35/200 [17:58<1:35:27, 34.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:17:54,585] Trial 34 finished with value: 0.31103711848826354 and parameters: {'n_estimators': 1671, 'max_depth': 14, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.3109070943013822.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.310907:  18%|█▊        | 36/200 [18:37<1:38:44, 36.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:18:33,997] Trial 35 finished with value: 0.31101766767690836 and parameters: {'n_estimators': 1640, 'max_depth': 14, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.3109070943013822.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.310907:  18%|█▊        | 37/200 [19:15<1:39:06, 36.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:19:11,311] Trial 36 finished with value: 0.3110254130561138 and parameters: {'n_estimators': 1655, 'max_depth': 14, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.3109070943013822.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.310907:  19%|█▉        | 38/200 [19:47<1:35:15, 35.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:19:43,785] Trial 38 finished with value: 0.31096583140864903 and parameters: {'n_estimators': 939, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.3109070943013822.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.310907:  20%|█▉        | 39/200 [19:53<1:10:59, 26.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:19:49,648] Trial 37 finished with value: 0.31093185340600327 and parameters: {'n_estimators': 1644, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.3109070943013822.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.310907:  20%|██        | 40/200 [20:51<1:35:54, 35.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:20:47,806] Trial 39 finished with value: 0.31129630458877217 and parameters: {'n_estimators': 1605, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.3109070943013822.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.310907:  20%|██        | 41/200 [21:05<1:17:23, 29.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:21:01,219] Trial 40 finished with value: 0.31118578362264837 and parameters: {'n_estimators': 1615, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 33 with value: 0.3109070943013822.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.310907:  21%|██        | 42/200 [22:04<1:40:53, 38.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:22:00,803] Trial 41 finished with value: 0.3111797368890698 and parameters: {'n_estimators': 1608, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 33 with value: 0.3109070943013822.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.310907:  22%|██▏       | 43/200 [22:21<1:23:42, 31.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:22:18,030] Trial 42 finished with value: 0.3113018376257056 and parameters: {'n_estimators': 1618, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.3109070943013822.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.310907:  22%|██▏       | 44/200 [23:09<1:35:13, 36.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:23:05,472] Trial 43 finished with value: 0.3111911914665701 and parameters: {'n_estimators': 1626, 'max_depth': 13, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 33 with value: 0.3109070943013822.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.310854:  22%|██▎       | 45/200 [23:44<1:33:38, 36.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:23:40,834] Trial 44 finished with value: 0.31085434345574225 and parameters: {'n_estimators': 1618, 'max_depth': 13, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 44 with value: 0.31085434345574225.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 45. Best value: 0.3108:  23%|██▎       | 46/200 [23:51<1:10:31, 27.48s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:23:47,859] Trial 45 finished with value: 0.3108001782999482 and parameters: {'n_estimators': 1587, 'max_depth': 14, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 45 with value: 0.3108001782999482.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 46. Best value: 0.310792:  24%|██▎       | 47/200 [25:02<1:42:53, 40.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:24:58,241] Trial 46 finished with value: 0.31079175085105015 and parameters: {'n_estimators': 1580, 'max_depth': 14, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 46 with value: 0.31079175085105015.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 46. Best value: 0.310792:  24%|██▍       | 48/200 [25:12<1:19:43, 31.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:25:08,989] Trial 47 finished with value: 0.31104845953110505 and parameters: {'n_estimators': 1643, 'max_depth': 14, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 46 with value: 0.31079175085105015.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 46. Best value: 0.310792:  24%|██▍       | 49/200 [26:10<1:38:44, 39.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:26:06,353] Trial 50 finished with value: 0.3113841013808032 and parameters: {'n_estimators': 858, 'max_depth': 15, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 46 with value: 0.31079175085105015.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 46. Best value: 0.310792:  25%|██▌       | 50/200 [26:15<1:12:26, 28.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:26:11,392] Trial 48 finished with value: 0.3111314780974753 and parameters: {'n_estimators': 1588, 'max_depth': 15, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 46 with value: 0.31079175085105015.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 46. Best value: 0.310792:  26%|██▌       | 51/200 [26:37<1:07:03, 27.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:26:33,789] Trial 49 finished with value: 0.3111278192473072 and parameters: {'n_estimators': 1608, 'max_depth': 15, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 46 with value: 0.31079175085105015.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 46. Best value: 0.310792:  26%|██▌       | 52/200 [26:50<55:59, 22.70s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:26:46,448] Trial 51 finished with value: 0.31160615027246064 and parameters: {'n_estimators': 845, 'max_depth': 16, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 46 with value: 0.31079175085105015.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  26%|██▋       | 53/200 [27:21<1:02:11, 25.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:27:18,089] Trial 52 finished with value: 0.3107851074208501 and parameters: {'n_estimators': 874, 'max_depth': 16, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  27%|██▋       | 54/200 [27:38<55:33, 22.83s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:27:34,980] Trial 53 finished with value: 0.3108580105469796 and parameters: {'n_estimators': 927, 'max_depth': 16, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  28%|██▊       | 55/200 [28:04<57:25, 23.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:28:00,909] Trial 54 finished with value: 0.31089627562092526 and parameters: {'n_estimators': 996, 'max_depth': 16, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  28%|██▊       | 56/200 [28:27<56:22, 23.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:28:23,769] Trial 55 finished with value: 0.31087707005809817 and parameters: {'n_estimators': 922, 'max_depth': 16, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  28%|██▊       | 57/200 [28:46<52:32, 22.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:28:42,442] Trial 56 finished with value: 0.31084580942047285 and parameters: {'n_estimators': 915, 'max_depth': 16, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  29%|██▉       | 58/200 [29:08<52:35, 22.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:29:05,077] Trial 57 finished with value: 0.3107875823138809 and parameters: {'n_estimators': 859, 'max_depth': 16, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  30%|██▉       | 59/200 [30:01<1:13:49, 31.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:29:57,953] Trial 58 finished with value: 0.3108058702244029 and parameters: {'n_estimators': 1551, 'max_depth': 16, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  30%|███       | 60/200 [30:35<1:14:57, 32.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:30:31,712] Trial 59 finished with value: 0.31140750319518884 and parameters: {'n_estimators': 1774, 'max_depth': 16, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  30%|███       | 61/200 [31:39<1:36:18, 41.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:31:35,329] Trial 60 finished with value: 0.3112906776787751 and parameters: {'n_estimators': 1762, 'max_depth': 18, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  31%|███       | 62/200 [32:12<1:29:58, 39.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:32:08,724] Trial 61 finished with value: 0.31137308100422534 and parameters: {'n_estimators': 1762, 'max_depth': 19, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  32%|███▏      | 63/200 [33:14<1:44:37, 45.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:33:10,190] Trial 62 finished with value: 0.31138271616937496 and parameters: {'n_estimators': 1766, 'max_depth': 18, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  32%|███▏      | 64/200 [33:44<1:33:26, 41.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:33:40,689] Trial 63 finished with value: 0.3113598243334756 and parameters: {'n_estimators': 1760, 'max_depth': 18, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  32%|███▎      | 65/200 [34:12<1:23:40, 37.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:34:08,461] Trial 64 finished with value: 0.31135661152448396 and parameters: {'n_estimators': 1783, 'max_depth': 19, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  33%|███▎      | 66/200 [34:58<1:29:19, 39.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:34:55,002] Trial 66 finished with value: 0.3116541999199027 and parameters: {'n_estimators': 991, 'max_depth': 18, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  34%|███▎      | 67/200 [35:05<1:06:43, 30.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:35:02,029] Trial 65 finished with value: 0.3113368359849907 and parameters: {'n_estimators': 1739, 'max_depth': 18, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  34%|███▍      | 68/200 [35:26<59:59, 27.27s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:35:22,668] Trial 67 finished with value: 0.3116556105043289 and parameters: {'n_estimators': 754, 'max_depth': 18, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  34%|███▍      | 69/200 [35:39<50:23, 23.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:35:35,970] Trial 68 finished with value: 0.31187294564633206 and parameters: {'n_estimators': 715, 'max_depth': 19, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  35%|███▌      | 70/200 [35:47<39:53, 18.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:35:43,492] Trial 69 finished with value: 0.3113745350034053 and parameters: {'n_estimators': 725, 'max_depth': 17, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  36%|███▌      | 71/200 [36:19<48:26, 22.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:36:15,647] Trial 70 finished with value: 0.3118872278303052 and parameters: {'n_estimators': 698, 'max_depth': 19, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  36%|███▌      | 72/200 [36:25<37:45, 17.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:36:22,067] Trial 71 finished with value: 0.31157515980581474 and parameters: {'n_estimators': 679, 'max_depth': 18, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  36%|███▋      | 73/200 [36:58<47:13, 22.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:36:55,134] Trial 73 finished with value: 0.31160662118899973 and parameters: {'n_estimators': 692, 'max_depth': 18, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  37%|███▋      | 74/200 [37:00<33:41, 16.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:36:56,549] Trial 72 finished with value: 0.3119018971857394 and parameters: {'n_estimators': 756, 'max_depth': 19, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  38%|███▊      | 75/200 [37:16<33:10, 15.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:37:12,192] Trial 74 finished with value: 0.3111470648637767 and parameters: {'n_estimators': 769, 'max_depth': 12, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  38%|███▊      | 76/200 [37:31<32:21, 15.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:37:27,240] Trial 75 finished with value: 0.31112314943883457 and parameters: {'n_estimators': 656, 'max_depth': 12, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  38%|███▊      | 77/200 [37:43<29:56, 14.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:37:39,387] Trial 76 finished with value: 0.311461466804987 and parameters: {'n_estimators': 706, 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  39%|███▉      | 78/200 [38:04<33:53, 16.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:38:00,856] Trial 77 finished with value: 0.31147508865241746 and parameters: {'n_estimators': 707, 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  40%|███▉      | 79/200 [38:09<26:15, 13.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:38:05,384] Trial 78 finished with value: 0.31112573865138865 and parameters: {'n_estimators': 653, 'max_depth': 12, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  40%|████      | 80/200 [38:30<30:59, 15.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:38:26,641] Trial 79 finished with value: 0.31102444961833153 and parameters: {'n_estimators': 652, 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  40%|████      | 81/200 [39:06<42:40, 21.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:39:02,208] Trial 81 finished with value: 0.31101008709302075 and parameters: {'n_estimators': 1080, 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  41%|████      | 82/200 [39:19<37:41, 19.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:39:15,876] Trial 80 finished with value: 0.31082995933555485 and parameters: {'n_estimators': 1530, 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  42%|████▏     | 83/200 [39:43<39:54, 20.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:39:39,400] Trial 82 finished with value: 0.3114799501986699 and parameters: {'n_estimators': 840, 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  42%|████▏     | 84/200 [39:58<36:43, 19.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:39:54,955] Trial 83 finished with value: 0.3111066721266439 and parameters: {'n_estimators': 882, 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  42%|████▎     | 85/200 [40:41<50:14, 26.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:40:38,018] Trial 85 finished with value: 0.31093490391748146 and parameters: {'n_estimators': 1109, 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  43%|████▎     | 86/200 [40:55<42:32, 22.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:40:51,493] Trial 84 finished with value: 0.3108442089778887 and parameters: {'n_estimators': 1553, 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  44%|████▎     | 87/200 [41:45<57:38, 30.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:41:41,277] Trial 86 finished with value: 0.31083950662029036 and parameters: {'n_estimators': 1540, 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  44%|████▍     | 88/200 [42:04<50:42, 27.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:42:00,393] Trial 87 finished with value: 0.3112646388616242 and parameters: {'n_estimators': 1558, 'max_depth': 15, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  44%|████▍     | 89/200 [42:43<57:14, 30.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:42:40,142] Trial 89 finished with value: 0.3116202137712514 and parameters: {'n_estimators': 837, 'max_depth': 15, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  45%|████▌     | 90/200 [43:05<51:18, 27.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:43:01,240] Trial 88 finished with value: 0.3112770209587392 and parameters: {'n_estimators': 1545, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  46%|████▌     | 91/200 [43:40<55:07, 30.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:43:37,100] Trial 91 finished with value: 0.31141570136726593 and parameters: {'n_estimators': 1082, 'max_depth': 15, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  46%|████▌     | 92/200 [43:53<44:56, 24.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:43:49,504] Trial 90 finished with value: 0.3117293800027427 and parameters: {'n_estimators': 1547, 'max_depth': 17, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  46%|████▋     | 93/200 [44:47<1:00:13, 33.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:44:43,828] Trial 93 finished with value: 0.3114861425141173 and parameters: {'n_estimators': 1312, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  47%|████▋     | 94/200 [44:57<46:49, 26.50s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:44:53,364] Trial 92 finished with value: 0.3108273074375224 and parameters: {'n_estimators': 1539, 'max_depth': 16, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  48%|████▊     | 95/200 [46:03<1:07:08, 38.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:45:59,405] Trial 94 finished with value: 0.3114985854347878 and parameters: {'n_estimators': 1699, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  48%|████▊     | 96/200 [46:14<52:29, 30.29s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:46:10,850] Trial 95 finished with value: 0.3115456190762863 and parameters: {'n_estimators': 1513, 'max_depth': 17, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  48%|████▊     | 97/200 [47:08<1:03:53, 37.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:47:04,229] Trial 96 finished with value: 0.31121446394322627 and parameters: {'n_estimators': 1566, 'max_depth': 15, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  49%|████▉     | 98/200 [47:25<52:59, 31.17s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:47:21,299] Trial 97 finished with value: 0.3115135910514718 and parameters: {'n_estimators': 1515, 'max_depth': 15, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  50%|████▉     | 99/200 [47:50<49:47, 29.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:47:47,155] Trial 98 finished with value: 0.3114419245083869 and parameters: {'n_estimators': 1534, 'max_depth': 15, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  50%|█████     | 100/200 [48:34<56:24, 33.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:48:30,956] Trial 99 finished with value: 0.3114789804452749 and parameters: {'n_estimators': 1690, 'max_depth': 11, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  50%|█████     | 101/200 [48:46<44:45, 27.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:48:42,395] Trial 100 finished with value: 0.3114139142012944 and parameters: {'n_estimators': 1527, 'max_depth': 11, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  51%|█████     | 102/200 [49:40<57:36, 35.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:49:36,691] Trial 101 finished with value: 0.31140562809247924 and parameters: {'n_estimators': 1523, 'max_depth': 11, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  52%|█████▏    | 103/200 [49:53<46:07, 28.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:49:49,482] Trial 102 finished with value: 0.311493516793869 and parameters: {'n_estimators': 1699, 'max_depth': 11, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  52%|█████▏    | 104/200 [50:07<38:57, 24.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:50:04,070] Trial 103 finished with value: 0.31144427808876357 and parameters: {'n_estimators': 1316, 'max_depth': 11, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  52%|█████▎    | 105/200 [50:56<50:16, 31.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:50:53,093] Trial 104 finished with value: 0.31141278257189875 and parameters: {'n_estimators': 1517, 'max_depth': 11, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  53%|█████▎    | 106/200 [51:12<41:56, 26.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:51:08,233] Trial 105 finished with value: 0.311493516793869 and parameters: {'n_estimators': 1699, 'max_depth': 11, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  54%|█████▎    | 107/200 [51:56<49:50, 32.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:51:52,946] Trial 106 finished with value: 0.3112553567895472 and parameters: {'n_estimators': 1436, 'max_depth': 11, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  54%|█████▍    | 108/200 [52:12<41:48, 27.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:52:08,821] Trial 107 finished with value: 0.31149567000218925 and parameters: {'n_estimators': 1447, 'max_depth': 11, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  55%|█████▍    | 109/200 [52:52<47:09, 31.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:52:48,852] Trial 108 finished with value: 0.3115092187162034 and parameters: {'n_estimators': 1429, 'max_depth': 11, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  55%|█████▌    | 110/200 [53:14<42:37, 28.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:53:11,002] Trial 109 finished with value: 0.31151320084734857 and parameters: {'n_estimators': 1416, 'max_depth': 11, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  56%|█████▌    | 111/200 [53:22<33:00, 22.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:53:18,885] Trial 110 finished with value: 0.3115001248505892 and parameters: {'n_estimators': 1441, 'max_depth': 11, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  56%|█████▌    | 112/200 [54:19<47:49, 32.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:54:15,668] Trial 111 finished with value: 0.3109812161314921 and parameters: {'n_estimators': 1438, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  56%|█████▋    | 113/200 [54:36<40:29, 27.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:54:32,650] Trial 112 finished with value: 0.31084499204232874 and parameters: {'n_estimators': 1451, 'max_depth': 14, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  57%|█████▋    | 114/200 [55:22<47:45, 33.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:55:18,569] Trial 113 finished with value: 0.31140610735225044 and parameters: {'n_estimators': 1421, 'max_depth': 13, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  57%|█████▊    | 115/200 [55:47<43:34, 30.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:55:43,355] Trial 114 finished with value: 0.31125836504014404 and parameters: {'n_estimators': 1446, 'max_depth': 14, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  58%|█████▊    | 116/200 [55:59<35:27, 25.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:55:56,014] Trial 115 finished with value: 0.31083497273685246 and parameters: {'n_estimators': 1432, 'max_depth': 14, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  58%|█████▊    | 117/200 [56:59<49:21, 35.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:56:55,840] Trial 116 finished with value: 0.3112467432279155 and parameters: {'n_estimators': 1449, 'max_depth': 14, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  59%|█████▉    | 118/200 [57:06<37:07, 27.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:57:03,128] Trial 117 finished with value: 0.3112497148829319 and parameters: {'n_estimators': 1461, 'max_depth': 14, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  60%|█████▉    | 119/200 [57:52<44:00, 32.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:57:48,413] Trial 118 finished with value: 0.3112989173092483 and parameters: {'n_estimators': 1196, 'max_depth': 14, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  60%|██████    | 120/200 [58:23<42:49, 32.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:58:19,395] Trial 119 finished with value: 0.3108439060824635 and parameters: {'n_estimators': 1480, 'max_depth': 14, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  60%|██████    | 121/200 [58:40<36:23, 27.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:58:36,606] Trial 120 finished with value: 0.3108264183641695 and parameters: {'n_estimators': 1206, 'max_depth': 14, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  61%|██████    | 122/200 [59:13<38:03, 29.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:59:09,701] Trial 121 finished with value: 0.31086932844417786 and parameters: {'n_estimators': 1179, 'max_depth': 14, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  62%|██████▏   | 123/200 [59:48<39:40, 30.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 01:59:44,456] Trial 122 finished with value: 0.31078970334852485 and parameters: {'n_estimators': 1576, 'max_depth': 16, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  62%|██████▏   | 124/200 [1:00:37<45:56, 36.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:00:33,218] Trial 123 finished with value: 0.31080959591715757 and parameters: {'n_estimators': 1586, 'max_depth': 16, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  62%|██████▎   | 125/200 [1:00:57<39:16, 31.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:00:53,329] Trial 124 finished with value: 0.31078661522799655 and parameters: {'n_estimators': 1474, 'max_depth': 13, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.310785:  63%|██████▎   | 126/200 [1:01:29<39:05, 31.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:01:25,643] Trial 125 finished with value: 0.31085042933643425 and parameters: {'n_estimators': 1481, 'max_depth': 14, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 52 with value: 0.3107851074208501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 127. Best value: 0.310763:  64%|██████▎   | 127/200 [1:01:55<36:26, 29.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:01:51,537] Trial 127 finished with value: 0.3107625252994068 and parameters: {'n_estimators': 807, 'max_depth': 16, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 127 with value: 0.3107625252994068.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 127. Best value: 0.310763:  64%|██████▍   | 128/200 [1:02:17<33:15, 27.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:02:14,047] Trial 126 finished with value: 0.3108105581607596 and parameters: {'n_estimators': 1488, 'max_depth': 16, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 127 with value: 0.3107625252994068.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  64%|██████▍   | 129/200 [1:03:02<38:54, 32.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:02:58,963] Trial 129 finished with value: 0.31072782500046336 and parameters: {'n_estimators': 1217, 'max_depth': 16, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  65%|██████▌   | 130/200 [1:03:16<31:43, 27.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:03:12,904] Trial 128 finished with value: 0.31078638315305335 and parameters: {'n_estimators': 1578, 'max_depth': 16, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  66%|██████▌   | 131/200 [1:04:18<43:02, 37.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:04:14,193] Trial 130 finished with value: 0.31082370327013514 and parameters: {'n_estimators': 1578, 'max_depth': 13, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  66%|██████▌   | 132/200 [1:04:31<34:22, 30.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:04:27,983] Trial 131 finished with value: 0.3108023334265913 and parameters: {'n_estimators': 1486, 'max_depth': 16, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  66%|██████▋   | 133/200 [1:05:40<46:49, 41.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:05:36,971] Trial 133 finished with value: 0.31080113324685327 and parameters: {'n_estimators': 1493, 'max_depth': 13, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  67%|██████▋   | 134/200 [1:05:44<33:31, 30.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:05:40,723] Trial 132 finished with value: 0.31080549257692935 and parameters: {'n_estimators': 1587, 'max_depth': 16, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  68%|██████▊   | 135/200 [1:06:15<33:08, 30.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:06:11,599] Trial 134 finished with value: 0.3107846787809184 and parameters: {'n_estimators': 1565, 'max_depth': 16, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  68%|██████▊   | 136/200 [1:07:08<39:45, 37.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:07:04,434] Trial 135 finished with value: 0.3108187929679489 and parameters: {'n_estimators': 1594, 'max_depth': 16, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  68%|██████▊   | 137/200 [1:07:34<35:31, 33.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:07:30,259] Trial 136 finished with value: 0.3107861461944009 and parameters: {'n_estimators': 1570, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  69%|██████▉   | 138/200 [1:08:10<35:38, 34.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:08:06,261] Trial 138 finished with value: 0.31077324807492895 and parameters: {'n_estimators': 806, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  70%|██████▉   | 139/200 [1:08:30<30:52, 30.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:08:27,022] Trial 137 finished with value: 0.31079603614477797 and parameters: {'n_estimators': 1571, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  70%|███████   | 140/200 [1:08:37<23:07, 23.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:08:33,265] Trial 139 finished with value: 0.31077324807492895 and parameters: {'n_estimators': 806, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  70%|███████   | 141/200 [1:09:14<27:03, 27.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:09:11,013] Trial 141 finished with value: 0.3113679683887785 and parameters: {'n_estimators': 791, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  71%|███████   | 142/200 [1:09:18<19:41, 20.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:09:14,693] Trial 140 finished with value: 0.310733657584864 and parameters: {'n_estimators': 1240, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  72%|███████▏  | 143/200 [1:09:59<25:10, 26.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:09:55,481] Trial 143 finished with value: 0.3113679683887785 and parameters: {'n_estimators': 791, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  72%|███████▏  | 144/200 [1:10:34<27:14, 29.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:10:30,969] Trial 142 finished with value: 0.31124707312523026 and parameters: {'n_estimators': 1585, 'max_depth': 17, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  72%|███████▎  | 145/200 [1:10:41<20:27, 22.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:10:37,272] Trial 144 finished with value: 0.3114057610704183 and parameters: {'n_estimators': 810, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  73%|███████▎  | 146/200 [1:10:49<16:24, 18.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:10:45,958] Trial 145 finished with value: 0.3113697555373378 and parameters: {'n_estimators': 783, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  74%|███████▎  | 147/200 [1:11:14<17:44, 20.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:11:10,389] Trial 147 finished with value: 0.311070050422566 and parameters: {'n_estimators': 502, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  74%|███████▍  | 148/200 [1:11:25<15:07, 17.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:11:21,696] Trial 146 finished with value: 0.3113742392575333 and parameters: {'n_estimators': 802, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  74%|███████▍  | 149/200 [1:11:54<17:49, 20.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:11:50,886] Trial 148 finished with value: 0.3113639945740053 and parameters: {'n_estimators': 795, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  75%|███████▌  | 150/200 [1:12:08<15:37, 18.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:12:04,439] Trial 149 finished with value: 0.3114898018916897 and parameters: {'n_estimators': 876, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  76%|███████▌  | 151/200 [1:12:28<15:42, 19.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:12:24,797] Trial 150 finished with value: 0.3113949921412613 and parameters: {'n_estimators': 807, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  76%|███████▌  | 152/200 [1:12:53<16:39, 20.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:12:49,365] Trial 151 finished with value: 0.3114919341834646 and parameters: {'n_estimators': 880, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  76%|███████▋  | 153/200 [1:13:03<13:54, 17.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:12:59,937] Trial 152 finished with value: 0.3113697555373378 and parameters: {'n_estimators': 783, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  77%|███████▋  | 154/200 [1:13:35<16:48, 21.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:13:31,621] Trial 153 finished with value: 0.31139952369637197 and parameters: {'n_estimators': 819, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  78%|███████▊  | 155/200 [1:13:48<14:25, 19.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:13:44,530] Trial 154 finished with value: 0.3115136335819747 and parameters: {'n_estimators': 971, 'max_depth': 17, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  78%|███████▊  | 156/200 [1:14:16<16:06, 21.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:14:12,874] Trial 156 finished with value: 0.3110735377222137 and parameters: {'n_estimators': 501, 'max_depth': 17, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  78%|███████▊  | 157/200 [1:14:21<12:06, 16.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:14:17,971] Trial 155 finished with value: 0.31152340761901465 and parameters: {'n_estimators': 885, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  79%|███████▉  | 158/200 [1:14:31<10:14, 14.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:14:27,340] Trial 157 finished with value: 0.31158063033143546 and parameters: {'n_estimators': 524, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  80%|███████▉  | 159/200 [1:15:10<15:02, 22.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:15:06,541] Trial 158 finished with value: 0.31091946230544104 and parameters: {'n_estimators': 973, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  80%|████████  | 160/200 [1:15:12<10:45, 16.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:15:08,937] Trial 159 finished with value: 0.3108651199852232 and parameters: {'n_estimators': 899, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  80%|████████  | 161/200 [1:15:50<14:40, 22.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:15:46,595] Trial 160 finished with value: 0.31084535101812816 and parameters: {'n_estimators': 884, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  81%|████████  | 162/200 [1:16:21<15:58, 25.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:16:17,976] Trial 161 finished with value: 0.3107383462445898 and parameters: {'n_estimators': 1251, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  82%|████████▏ | 163/200 [1:16:42<14:40, 23.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:16:38,426] Trial 162 finished with value: 0.31089410692714514 and parameters: {'n_estimators': 988, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  82%|████████▏ | 164/200 [1:17:20<16:58, 28.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:17:17,169] Trial 163 finished with value: 0.31075707554578813 and parameters: {'n_estimators': 1254, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  82%|████████▎ | 165/200 [1:17:52<17:06, 29.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:17:48,929] Trial 164 finished with value: 0.3108676332726131 and parameters: {'n_estimators': 1659, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  83%|████████▎ | 166/200 [1:18:13<15:13, 26.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:18:10,033] Trial 165 finished with value: 0.3113953389626166 and parameters: {'n_estimators': 967, 'max_depth': 22, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  84%|████████▎ | 167/200 [1:19:10<19:41, 35.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:19:06,706] Trial 167 finished with value: 0.3107892060865344 and parameters: {'n_estimators': 1347, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  84%|████████▍ | 168/200 [1:19:21<15:06, 28.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:19:17,549] Trial 166 finished with value: 0.31083925999002926 and parameters: {'n_estimators': 1646, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  84%|████████▍ | 169/200 [1:20:07<17:26, 33.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:20:03,968] Trial 168 finished with value: 0.3110369933129101 and parameters: {'n_estimators': 1228, 'max_depth': 21, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  85%|████████▌ | 170/200 [1:20:19<13:38, 27.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:20:16,127] Trial 169 finished with value: 0.3107383462445898 and parameters: {'n_estimators': 1251, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  86%|████████▌ | 171/200 [1:21:13<17:02, 35.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:21:10,070] Trial 170 finished with value: 0.3107383462445898 and parameters: {'n_estimators': 1251, 'max_depth': 16, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  86%|████████▌ | 172/200 [1:21:47<16:12, 34.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:21:43,488] Trial 171 finished with value: 0.31109013704969507 and parameters: {'n_estimators': 1656, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  86%|████████▋ | 173/200 [1:22:01<12:49, 28.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:21:57,483] Trial 172 finished with value: 0.311109212781541 and parameters: {'n_estimators': 1658, 'max_depth': 15, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  87%|████████▋ | 174/200 [1:23:05<17:02, 39.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:23:02,073] Trial 174 finished with value: 0.3110368496518142 and parameters: {'n_estimators': 1254, 'max_depth': 21, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  88%|████████▊ | 175/200 [1:23:15<12:39, 30.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:23:11,572] Trial 173 finished with value: 0.311109212781541 and parameters: {'n_estimators': 1658, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  88%|████████▊ | 176/200 [1:24:09<14:56, 37.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:24:05,270] Trial 175 finished with value: 0.3110942991939206 and parameters: {'n_estimators': 1230, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  88%|████████▊ | 177/200 [1:24:14<10:38, 27.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:24:10,636] Trial 176 finished with value: 0.31105952637418327 and parameters: {'n_estimators': 1266, 'max_depth': 15, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  89%|████████▉ | 178/200 [1:24:44<10:25, 28.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:24:40,605] Trial 177 finished with value: 0.31110600057013016 and parameters: {'n_estimators': 1642, 'max_depth': 15, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  90%|████████▉ | 179/200 [1:25:22<10:57, 31.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:25:18,675] Trial 178 finished with value: 0.31106474611654644 and parameters: {'n_estimators': 1293, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  90%|█████████ | 180/200 [1:25:45<09:34, 28.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:25:41,380] Trial 179 finished with value: 0.31107091730706465 and parameters: {'n_estimators': 1241, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  90%|█████████ | 181/200 [1:26:29<10:36, 33.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:26:25,944] Trial 180 finished with value: 0.311053823118157 and parameters: {'n_estimators': 1280, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  91%|█████████ | 182/200 [1:26:54<09:16, 30.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:26:50,822] Trial 181 finished with value: 0.31108584723185645 and parameters: {'n_estimators': 1305, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  92%|█████████▏| 183/200 [1:27:24<08:39, 30.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:27:20,553] Trial 182 finished with value: 0.3110672328434879 and parameters: {'n_estimators': 1297, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  92%|█████████▏| 184/200 [1:27:43<07:14, 27.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:27:39,779] Trial 183 finished with value: 0.311053823118157 and parameters: {'n_estimators': 1280, 'max_depth': 15, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  92%|█████████▎| 185/200 [1:28:11<06:50, 27.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:28:07,631] Trial 184 finished with value: 0.31105536616516366 and parameters: {'n_estimators': 1263, 'max_depth': 15, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  93%|█████████▎| 186/200 [1:28:51<07:17, 31.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:28:47,893] Trial 185 finished with value: 0.31106181513972614 and parameters: {'n_estimators': 1276, 'max_depth': 15, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  94%|█████████▎| 187/200 [1:29:18<06:30, 30.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:29:15,161] Trial 186 finished with value: 0.3107817595306652 and parameters: {'n_estimators': 1345, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  94%|█████████▍| 188/200 [1:30:03<06:50, 34.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:29:59,190] Trial 187 finished with value: 0.3107713143179587 and parameters: {'n_estimators': 1344, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  94%|█████████▍| 189/200 [1:30:13<04:59, 27.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:30:09,930] Trial 188 finished with value: 0.3108176030786412 and parameters: {'n_estimators': 1356, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  95%|█████████▌| 190/200 [1:30:40<04:30, 27.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:30:36,634] Trial 189 finished with value: 0.31073966032626493 and parameters: {'n_estimators': 1298, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  96%|█████████▌| 191/200 [1:31:29<05:03, 33.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:31:25,941] Trial 190 finished with value: 0.3107814321183949 and parameters: {'n_estimators': 1334, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  96%|█████████▌| 192/200 [1:31:53<04:06, 30.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:31:49,979] Trial 191 finished with value: 0.31082443766866713 and parameters: {'n_estimators': 1363, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  96%|█████████▋| 193/200 [1:32:34<03:57, 33.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:32:31,093] Trial 192 finished with value: 0.31078228439136624 and parameters: {'n_estimators': 1339, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 129. Best value: 0.310728:  97%|█████████▋| 194/200 [1:33:08<03:22, 33.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:33:04,329] Trial 193 finished with value: 0.3108054676296004 and parameters: {'n_estimators': 1371, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 129 with value: 0.31072782500046336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 194. Best value: 0.310721:  98%|█████████▊| 195/200 [1:33:23<02:20, 28.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:33:19,595] Trial 194 finished with value: 0.310721037378484 and parameters: {'n_estimators': 1156, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 194 with value: 0.310721037378484.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 194. Best value: 0.310721:  98%|█████████▊| 196/200 [1:33:51<01:52, 28.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:33:47,553] Trial 195 finished with value: 0.31077136844068576 and parameters: {'n_estimators': 1142, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 194 with value: 0.310721037378484.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 194. Best value: 0.310721:  98%|█████████▊| 197/200 [1:34:05<01:12, 24.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:34:02,113] Trial 196 finished with value: 0.3107311150473962 and parameters: {'n_estimators': 1173, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 194 with value: 0.310721037378484.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 194. Best value: 0.310721:  99%|█████████▉| 198/200 [1:34:47<00:58, 29.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:34:43,757] Trial 197 finished with value: 0.310755484232443 and parameters: {'n_estimators': 1161, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 194 with value: 0.310721037378484.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 194. Best value: 0.310721: 100%|█████████▉| 199/200 [1:35:19<00:29, 29.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:35:15,218] Trial 198 finished with value: 0.31078733918890894 and parameters: {'n_estimators': 1349, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 194 with value: 0.310721037378484.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 194. Best value: 0.310721: 100%|██████████| 200/200 [1:35:44<00:00, 28.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:35:41,032] Trial 199 finished with value: 0.3108182159524868 and parameters: {'n_estimators': 1364, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 194 with value: 0.310721037378484.\n",
      "Best parameters: {'n_estimators': 1156, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 3}\n",
      "Best RMSE: 0.310721037378484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199
         ],
         "y": [
          0.3123159316435803,
          0.3113326270370818,
          0.31281125638205276,
          0.31119851561135764,
          0.3121424679620722,
          0.31140771445138876,
          0.31162819901248234,
          0.31209807028843195,
          0.3122191315180872,
          0.3115414539716882,
          0.3116758118350818,
          0.31127282403612805,
          0.31176946230943425,
          0.31135380293169057,
          0.3110302500094346,
          0.312713624263532,
          0.31153238659422583,
          0.31152597916904484,
          0.3124432866585848,
          0.3115266320358151,
          0.3120396316110664,
          0.31171212755995736,
          0.31142399277548466,
          0.31133529246022446,
          0.311697989361281,
          0.3113577324576172,
          0.3111018137920071,
          0.31146732629631274,
          0.31145659375674234,
          0.31126003693903065,
          0.31130074100134786,
          0.31128560797786126,
          0.3112408654151385,
          0.3109070943013822,
          0.31103711848826354,
          0.31101766767690836,
          0.3110254130561138,
          0.31093185340600327,
          0.31096583140864903,
          0.31129630458877217,
          0.31118578362264837,
          0.3111797368890698,
          0.3113018376257056,
          0.3111911914665701,
          0.31085434345574225,
          0.3108001782999482,
          0.31079175085105015,
          0.31104845953110505,
          0.3111314780974753,
          0.3111278192473072,
          0.3113841013808032,
          0.31160615027246064,
          0.3107851074208501,
          0.3108580105469796,
          0.31089627562092526,
          0.31087707005809817,
          0.31084580942047285,
          0.3107875823138809,
          0.3108058702244029,
          0.31140750319518884,
          0.3112906776787751,
          0.31137308100422534,
          0.31138271616937496,
          0.3113598243334756,
          0.31135661152448396,
          0.3113368359849907,
          0.3116541999199027,
          0.3116556105043289,
          0.31187294564633206,
          0.3113745350034053,
          0.3118872278303052,
          0.31157515980581474,
          0.3119018971857394,
          0.31160662118899973,
          0.3111470648637767,
          0.31112314943883457,
          0.311461466804987,
          0.31147508865241746,
          0.31112573865138865,
          0.31102444961833153,
          0.31082995933555485,
          0.31101008709302075,
          0.3114799501986699,
          0.3111066721266439,
          0.3108442089778887,
          0.31093490391748146,
          0.31083950662029036,
          0.3112646388616242,
          0.3112770209587392,
          0.3116202137712514,
          0.3117293800027427,
          0.31141570136726593,
          0.3108273074375224,
          0.3114861425141173,
          0.3114985854347878,
          0.3115456190762863,
          0.31121446394322627,
          0.3115135910514718,
          0.3114419245083869,
          0.3114789804452749,
          0.3114139142012944,
          0.31140562809247924,
          0.311493516793869,
          0.31144427808876357,
          0.31141278257189875,
          0.311493516793869,
          0.3112553567895472,
          0.31149567000218925,
          0.3115092187162034,
          0.31151320084734857,
          0.3115001248505892,
          0.3109812161314921,
          0.31084499204232874,
          0.31140610735225044,
          0.31125836504014404,
          0.31083497273685246,
          0.3112467432279155,
          0.3112497148829319,
          0.3112989173092483,
          0.3108439060824635,
          0.3108264183641695,
          0.31086932844417786,
          0.31078970334852485,
          0.31080959591715757,
          0.31078661522799655,
          0.31085042933643425,
          0.3108105581607596,
          0.3107625252994068,
          0.31078638315305335,
          0.31072782500046336,
          0.31082370327013514,
          0.3108023334265913,
          0.31080549257692935,
          0.31080113324685327,
          0.3107846787809184,
          0.3108187929679489,
          0.3107861461944009,
          0.31079603614477797,
          0.31077324807492895,
          0.31077324807492895,
          0.310733657584864,
          0.3113679683887785,
          0.31124707312523026,
          0.3113679683887785,
          0.3114057610704183,
          0.3113697555373378,
          0.3113742392575333,
          0.311070050422566,
          0.3113639945740053,
          0.3114898018916897,
          0.3113949921412613,
          0.3114919341834646,
          0.3113697555373378,
          0.31139952369637197,
          0.3115136335819747,
          0.31152340761901465,
          0.3110735377222137,
          0.31158063033143546,
          0.31091946230544104,
          0.3108651199852232,
          0.31084535101812816,
          0.3107383462445898,
          0.31089410692714514,
          0.31075707554578813,
          0.3108676332726131,
          0.3113953389626166,
          0.31083925999002926,
          0.3107892060865344,
          0.3110369933129101,
          0.3107383462445898,
          0.3107383462445898,
          0.31109013704969507,
          0.311109212781541,
          0.311109212781541,
          0.3110368496518142,
          0.3110942991939206,
          0.31105952637418327,
          0.31110600057013016,
          0.31106474611654644,
          0.31107091730706465,
          0.311053823118157,
          0.31108584723185645,
          0.3110672328434879,
          0.311053823118157,
          0.31105536616516366,
          0.31106181513972614,
          0.3107817595306652,
          0.3107713143179587,
          0.3108176030786412,
          0.31073966032626493,
          0.3107814321183949,
          0.31082443766866713,
          0.31078228439136624,
          0.3108054676296004,
          0.310721037378484,
          0.31077136844068576,
          0.3107311150473962,
          0.310755484232443,
          0.31078733918890894,
          0.3108182159524868
         ]
        },
        {
         "mode": "lines",
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199
         ],
         "y": [
          0.3123159316435803,
          0.3113326270370818,
          0.3113326270370818,
          0.31119851561135764,
          0.31119851561135764,
          0.31119851561135764,
          0.31119851561135764,
          0.31119851561135764,
          0.31119851561135764,
          0.31119851561135764,
          0.31119851561135764,
          0.31119851561135764,
          0.31119851561135764,
          0.31119851561135764,
          0.3110302500094346,
          0.3110302500094346,
          0.3110302500094346,
          0.3110302500094346,
          0.3110302500094346,
          0.3110302500094346,
          0.3110302500094346,
          0.3110302500094346,
          0.3110302500094346,
          0.3110302500094346,
          0.3110302500094346,
          0.3110302500094346,
          0.3110302500094346,
          0.3110302500094346,
          0.3110302500094346,
          0.3110302500094346,
          0.3110302500094346,
          0.3110302500094346,
          0.3110302500094346,
          0.3109070943013822,
          0.3109070943013822,
          0.3109070943013822,
          0.3109070943013822,
          0.3109070943013822,
          0.3109070943013822,
          0.3109070943013822,
          0.3109070943013822,
          0.3109070943013822,
          0.3109070943013822,
          0.3109070943013822,
          0.31085434345574225,
          0.3108001782999482,
          0.31079175085105015,
          0.31079175085105015,
          0.31079175085105015,
          0.31079175085105015,
          0.31079175085105015,
          0.31079175085105015,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107851074208501,
          0.3107625252994068,
          0.3107625252994068,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.31072782500046336,
          0.310721037378484,
          0.310721037378484,
          0.310721037378484,
          0.310721037378484,
          0.310721037378484,
          0.310721037378484
         ]
        },
        {
         "marker": {
          "color": "#cccccc"
         },
         "mode": "markers",
         "name": "Infeasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [],
         "y": []
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 'rf_n_estimators': 1862, 'rf_max_depth': 19, 'rf_min_samples_split': 2, 'rf_min_samples_leaf': 3\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "def get_rf_parameters(trial: Trial) -> dict[str, int | float]:\n",
    "    return {\n",
    "        \"max_features\": 0.5,\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 500, 2000),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 10, 30),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 11),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 5),\n",
    "        \"random_state\": RANDOM_STATE,\n",
    "    }\n",
    "\n",
    "\n",
    "model_parameters[RandomForestRegressor] = get_rf_parameters\n",
    "\n",
    "run_study(RandomForestRegressor, X_final, y, kfold, n_trials=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:42:45,216] A new study created in memory with name: no-name-930ca629-6426-44a3-ad03-3fa3dd0b3f47\n",
      "Best trial: 2. Best value: 0.312145:   0%|          | 1/200 [00:06<20:51,  6.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:42:51,502] Trial 2 finished with value: 0.31214503868894133 and parameters: {'n_estimators': 757, 'max_depth': 11, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.31214503868894133.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 0.308821:   1%|          | 2/200 [00:27<50:10, 15.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:43:12,946] Trial 9 finished with value: 0.30882119739413455 and parameters: {'n_estimators': 1522, 'max_depth': 15, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 9 with value: 0.30882119739413455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 0.308821:   2%|▏         | 3/200 [00:33<35:30, 10.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:43:18,543] Trial 7 finished with value: 0.30935818206911647 and parameters: {'n_estimators': 620, 'max_depth': 24, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 9 with value: 0.30882119739413455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 0.308821:   2%|▏         | 4/200 [00:34<22:25,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:43:19,343] Trial 4 finished with value: 0.3100164653971905 and parameters: {'n_estimators': 590, 'max_depth': 24, 'min_samples_split': 11, 'min_samples_leaf': 4}. Best is trial 9 with value: 0.30882119739413455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 0.308821:   2%|▎         | 5/200 [00:36<17:01,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:43:21,693] Trial 5 finished with value: 0.30970729680841885 and parameters: {'n_estimators': 584, 'max_depth': 16, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 9 with value: 0.30882119739413455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 0.308821:   3%|▎         | 6/200 [00:38<13:19,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:43:23,643] Trial 3 finished with value: 0.3090387749852491 and parameters: {'n_estimators': 1154, 'max_depth': 19, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 9 with value: 0.30882119739413455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 0.308821:   4%|▎         | 7/200 [00:40<11:15,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:43:25,868] Trial 10 finished with value: 0.31080587435578655 and parameters: {'n_estimators': 1247, 'max_depth': 15, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 9 with value: 0.30882119739413455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 0.308821:   4%|▍         | 8/200 [00:41<08:53,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:43:27,108] Trial 0 finished with value: 0.31042440091521145 and parameters: {'n_estimators': 1834, 'max_depth': 22, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 9 with value: 0.30882119739413455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:   4%|▍         | 9/200 [00:45<09:58,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:43:31,012] Trial 6 finished with value: 0.3087457976822455 and parameters: {'n_estimators': 920, 'max_depth': 24, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:   5%|▌         | 10/200 [00:47<08:41,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:43:32,890] Trial 11 finished with value: 0.31096932915599995 and parameters: {'n_estimators': 1699, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:   6%|▌         | 11/200 [00:52<10:13,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:43:37,284] Trial 12 finished with value: 0.31155114318384364 and parameters: {'n_estimators': 873, 'max_depth': 13, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:   6%|▌         | 12/200 [00:55<10:25,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:43:40,791] Trial 8 finished with value: 0.309204166888698 and parameters: {'n_estimators': 1210, 'max_depth': 24, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:   6%|▋         | 13/200 [01:00<11:58,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:43:45,815] Trial 1 finished with value: 0.3088381629417076 and parameters: {'n_estimators': 1559, 'max_depth': 29, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:   7%|▋         | 14/200 [01:02<10:26,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:43:48,087] Trial 14 finished with value: 0.31217762803113197 and parameters: {'n_estimators': 1840, 'max_depth': 11, 'min_samples_split': 11, 'min_samples_leaf': 3}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:   8%|▊         | 15/200 [01:06<10:17,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:43:51,357] Trial 13 finished with value: 0.309016561796783 and parameters: {'n_estimators': 1798, 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:   8%|▊         | 16/200 [01:07<08:03,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:43:52,341] Trial 15 finished with value: 0.311000643453763 and parameters: {'n_estimators': 782, 'max_depth': 13, 'min_samples_split': 11, 'min_samples_leaf': 3}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:   8%|▊         | 17/200 [01:15<13:30,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:44:00,965] Trial 16 finished with value: 0.3093624481793943 and parameters: {'n_estimators': 1472, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:   9%|▉         | 18/200 [01:17<11:05,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:44:02,814] Trial 17 finished with value: 0.30927295740407923 and parameters: {'n_estimators': 1362, 'max_depth': 28, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  10%|▉         | 19/200 [01:25<14:53,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:44:10,744] Trial 18 finished with value: 0.3096902169160649 and parameters: {'n_estimators': 1401, 'max_depth': 18, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  10%|█         | 20/200 [01:29<14:18,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:44:15,127] Trial 19 finished with value: 0.3090102739047237 and parameters: {'n_estimators': 1036, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  10%|█         | 21/200 [01:31<10:57,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:44:16,233] Trial 20 finished with value: 0.3105929421834007 and parameters: {'n_estimators': 915, 'max_depth': 27, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  11%|█         | 22/200 [01:33<09:24,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:44:18,246] Trial 21 finished with value: 0.3092952992965464 and parameters: {'n_estimators': 982, 'max_depth': 29, 'min_samples_split': 11, 'min_samples_leaf': 2}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  12%|█▏        | 23/200 [01:42<15:16,  5.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:44:28,099] Trial 22 finished with value: 0.30904463468252114 and parameters: {'n_estimators': 1535, 'max_depth': 29, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  12%|█▏        | 24/200 [01:45<13:20,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:44:31,181] Trial 23 finished with value: 0.30911724186493184 and parameters: {'n_estimators': 1568, 'max_depth': 30, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  12%|█▎        | 25/200 [01:50<13:02,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:44:35,461] Trial 24 finished with value: 0.3090523890659206 and parameters: {'n_estimators': 1021, 'max_depth': 29, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  13%|█▎        | 26/200 [01:56<14:34,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:44:41,780] Trial 25 finished with value: 0.30910811741855504 and parameters: {'n_estimators': 1470, 'max_depth': 30, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  14%|█▎        | 27/200 [02:01<14:36,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:44:46,943] Trial 26 finished with value: 0.3090972823611704 and parameters: {'n_estimators': 1446, 'max_depth': 30, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  14%|█▍        | 28/200 [02:07<14:50,  5.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:44:52,377] Trial 28 finished with value: 0.3090658239486566 and parameters: {'n_estimators': 1025, 'max_depth': 29, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  14%|█▍        | 29/200 [02:09<12:11,  4.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:44:54,566] Trial 27 finished with value: 0.3090421436593399 and parameters: {'n_estimators': 1453, 'max_depth': 29, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  15%|█▌        | 30/200 [02:12<11:23,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:44:57,983] Trial 29 finished with value: 0.30892947710093116 and parameters: {'n_estimators': 981, 'max_depth': 18, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  16%|█▌        | 31/200 [02:16<10:46,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:45:01,354] Trial 30 finished with value: 0.3092710056371465 and parameters: {'n_estimators': 1033, 'max_depth': 27, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  16%|█▌        | 32/200 [02:19<10:33,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:45:05,001] Trial 31 finished with value: 0.3093512745475243 and parameters: {'n_estimators': 1018, 'max_depth': 25, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  16%|█▋        | 33/200 [02:29<15:35,  5.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:45:14,869] Trial 32 finished with value: 0.30909235926481105 and parameters: {'n_estimators': 1593, 'max_depth': 30, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  17%|█▋        | 34/200 [02:33<14:00,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:45:18,676] Trial 33 finished with value: 0.30909711104623555 and parameters: {'n_estimators': 1595, 'max_depth': 30, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  18%|█▊        | 35/200 [02:43<18:20,  6.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:45:29,087] Trial 34 finished with value: 0.3089260345382894 and parameters: {'n_estimators': 1984, 'max_depth': 22, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  18%|█▊        | 36/200 [02:48<16:45,  6.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:45:33,964] Trial 35 finished with value: 0.3090885049589415 and parameters: {'n_estimators': 1965, 'max_depth': 26, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  18%|█▊        | 37/200 [02:56<17:50,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:45:41,547] Trial 36 finished with value: 0.3090796954149303 and parameters: {'n_estimators': 1630, 'max_depth': 26, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  19%|█▉        | 38/200 [03:03<18:28,  6.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:45:49,042] Trial 37 finished with value: 0.3090793606299872 and parameters: {'n_estimators': 1669, 'max_depth': 26, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  20%|█▉        | 39/200 [03:08<16:21,  6.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:45:53,397] Trial 38 finished with value: 0.3088392554588917 and parameters: {'n_estimators': 1697, 'max_depth': 26, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  20%|██        | 40/200 [03:20<21:18,  7.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:46:05,809] Trial 39 finished with value: 0.30886185204272565 and parameters: {'n_estimators': 1983, 'max_depth': 26, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  20%|██        | 41/200 [03:25<18:32,  7.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:46:10,481] Trial 40 finished with value: 0.3088480389786525 and parameters: {'n_estimators': 1702, 'max_depth': 26, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  21%|██        | 42/200 [03:34<20:13,  7.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:46:19,769] Trial 41 finished with value: 0.30882008328291416 and parameters: {'n_estimators': 1692, 'max_depth': 26, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  22%|██▏       | 43/200 [03:38<17:23,  6.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:46:23,988] Trial 42 finished with value: 0.3090829184120009 and parameters: {'n_estimators': 1635, 'max_depth': 22, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  22%|██▏       | 44/200 [03:48<19:40,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:46:33,708] Trial 44 finished with value: 0.30917190193039906 and parameters: {'n_estimators': 1141, 'max_depth': 22, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  22%|██▎       | 45/200 [03:49<14:40,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:46:34,977] Trial 43 finished with value: 0.3090761490707469 and parameters: {'n_estimators': 1645, 'max_depth': 22, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  23%|██▎       | 46/200 [03:51<11:43,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:46:36,958] Trial 45 finished with value: 0.3093831466223124 and parameters: {'n_estimators': 1148, 'max_depth': 21, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  24%|██▎       | 47/200 [04:04<17:42,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:46:49,449] Trial 46 finished with value: 0.30925617616059786 and parameters: {'n_estimators': 1988, 'max_depth': 22, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  24%|██▍       | 48/200 [04:08<15:29,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:46:53,633] Trial 47 finished with value: 0.30925537647540335 and parameters: {'n_estimators': 1995, 'max_depth': 22, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  24%|██▍       | 49/200 [04:19<19:28,  7.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:47:05,161] Trial 49 finished with value: 0.3091527062739684 and parameters: {'n_estimators': 1314, 'max_depth': 22, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  25%|██▌       | 50/200 [04:22<15:09,  6.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:47:07,306] Trial 48 finished with value: 0.30924133829486844 and parameters: {'n_estimators': 1971, 'max_depth': 22, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  26%|██▌       | 51/200 [04:29<15:42,  6.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:47:14,247] Trial 50 finished with value: 0.3091783550258348 and parameters: {'n_estimators': 1156, 'max_depth': 22, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  26%|██▌       | 52/200 [04:35<15:42,  6.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:47:20,724] Trial 51 finished with value: 0.3088941137063261 and parameters: {'n_estimators': 1320, 'max_depth': 23, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  26%|██▋       | 53/200 [04:41<15:07,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:47:26,426] Trial 52 finished with value: 0.3090669152888049 and parameters: {'n_estimators': 1826, 'max_depth': 22, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  27%|██▋       | 54/200 [04:52<19:01,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:47:38,083] Trial 53 finished with value: 0.30906424686376105 and parameters: {'n_estimators': 1780, 'max_depth': 22, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  28%|██▊       | 55/200 [04:54<14:35,  6.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:47:39,969] Trial 54 finished with value: 0.3090054622371266 and parameters: {'n_estimators': 1327, 'max_depth': 23, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  28%|██▊       | 56/200 [05:07<19:32,  8.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:47:53,026] Trial 55 finished with value: 0.30918637094014906 and parameters: {'n_estimators': 1810, 'max_depth': 24, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  28%|██▊       | 57/200 [05:12<17:06,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:47:57,942] Trial 56 finished with value: 0.30919851171091295 and parameters: {'n_estimators': 1768, 'max_depth': 24, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  29%|██▉       | 58/200 [05:16<14:32,  6.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:48:01,673] Trial 57 finished with value: 0.3096032225606648 and parameters: {'n_estimators': 1785, 'max_depth': 24, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  30%|██▉       | 59/200 [05:29<19:15,  8.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:48:14,662] Trial 58 finished with value: 0.30905824384556974 and parameters: {'n_estimators': 1724, 'max_depth': 24, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  30%|███       | 60/200 [05:33<16:08,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:48:18,597] Trial 59 finished with value: 0.3091967169551045 and parameters: {'n_estimators': 1793, 'max_depth': 24, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  30%|███       | 61/200 [05:41<17:06,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:48:27,066] Trial 61 finished with value: 0.31226147143544253 and parameters: {'n_estimators': 1844, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  31%|███       | 62/200 [05:42<12:09,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:48:27,475] Trial 60 finished with value: 0.30911953175754003 and parameters: {'n_estimators': 1807, 'max_depth': 24, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  32%|███▏      | 63/200 [05:50<13:58,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:48:35,524] Trial 63 finished with value: 0.31455878434276524 and parameters: {'n_estimators': 1749, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  32%|███▏      | 64/200 [05:52<10:58,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:48:37,396] Trial 62 finished with value: 0.3095834414343188 and parameters: {'n_estimators': 1751, 'max_depth': 24, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  32%|███▎      | 65/200 [06:03<15:32,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:48:49,109] Trial 64 finished with value: 0.309126080641018 and parameters: {'n_estimators': 1732, 'max_depth': 24, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 6 with value: 0.3087457976822455.\n",
      "[I 2025-01-11 00:48:49,157] Trial 65 finished with value: 0.30959123896458307 and parameters: {'n_estimators': 1733, 'max_depth': 24, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  34%|███▎      | 67/200 [06:15<14:15,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:49:00,884] Trial 66 finished with value: 0.3095940659523195 and parameters: {'n_estimators': 1704, 'max_depth': 25, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  34%|███▍      | 68/200 [06:19<13:00,  5.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:49:05,202] Trial 67 finished with value: 0.30907520605375655 and parameters: {'n_estimators': 1706, 'max_depth': 27, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  34%|███▍      | 69/200 [06:22<11:13,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:49:08,161] Trial 70 finished with value: 0.3140737068709282 and parameters: {'n_estimators': 537, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  35%|███▌      | 70/200 [06:26<10:11,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:49:11,700] Trial 68 finished with value: 0.3090650702903652 and parameters: {'n_estimators': 1731, 'max_depth': 27, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  36%|███▌      | 71/200 [06:28<08:40,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:49:14,030] Trial 69 finished with value: 0.3116727825152037 and parameters: {'n_estimators': 1719, 'max_depth': 11, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  36%|███▌      | 72/200 [06:31<07:35,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:49:16,394] Trial 71 finished with value: 0.3138873150512773 and parameters: {'n_estimators': 1535, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  36%|███▋      | 73/200 [06:35<08:04,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:49:20,831] Trial 73 finished with value: 0.30941134381480767 and parameters: {'n_estimators': 515, 'max_depth': 27, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  37%|███▋      | 74/200 [06:45<11:34,  5.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:49:30,455] Trial 72 finished with value: 0.3092894293547884 and parameters: {'n_estimators': 1898, 'max_depth': 27, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  38%|███▊      | 75/200 [06:49<10:51,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:49:34,932] Trial 74 finished with value: 0.3092959419081927 and parameters: {'n_estimators': 1880, 'max_depth': 28, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  38%|███▊      | 76/200 [06:54<10:32,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:49:39,776] Trial 75 finished with value: 0.3094152948163773 and parameters: {'n_estimators': 1529, 'max_depth': 27, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  38%|███▊      | 77/200 [07:04<13:21,  6.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:49:49,622] Trial 76 finished with value: 0.3092902764315295 and parameters: {'n_estimators': 1909, 'max_depth': 27, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 6 with value: 0.3087457976822455.\n",
      "[I 2025-01-11 00:49:49,671] Trial 78 finished with value: 0.3094199531465435 and parameters: {'n_estimators': 526, 'max_depth': 27, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  40%|███▉      | 79/200 [07:04<07:17,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:49:50,035] Trial 77 finished with value: 0.30942855402855024 and parameters: {'n_estimators': 1520, 'max_depth': 27, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  40%|████      | 80/200 [07:20<13:13,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:50:05,760] Trial 80 finished with value: 0.30883392086177447 and parameters: {'n_estimators': 1522, 'max_depth': 28, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.308746:  40%|████      | 81/200 [07:22<10:52,  5.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:50:08,064] Trial 79 finished with value: 0.3090346303514522 and parameters: {'n_estimators': 1910, 'max_depth': 28, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 6 with value: 0.3087457976822455.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 81. Best value: 0.308725:  41%|████      | 82/200 [07:35<14:30,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:50:20,519] Trial 81 finished with value: 0.30872523854244804 and parameters: {'n_estimators': 1898, 'max_depth': 16, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 81 with value: 0.30872523854244804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pawel/.pyenv/versions/university/lib/python3.13/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning:\n",
      "\n",
      "A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "\n",
      "Best trial: 81. Best value: 0.308725:  42%|████▏     | 83/200 [07:46<16:21,  8.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:50:31,520] Trial 82 finished with value: 0.30915747681769623 and parameters: {'n_estimators': 1894, 'max_depth': 28, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 81 with value: 0.30872523854244804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 81. Best value: 0.308725:  42%|████▏     | 84/200 [07:58<18:17,  9.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:50:43,669] Trial 83 finished with value: 0.30914188889158306 and parameters: {'n_estimators': 1907, 'max_depth': 28, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 81 with value: 0.30872523854244804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 81. Best value: 0.308725:  42%|████▎     | 85/200 [08:04<16:21,  8.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:50:49,926] Trial 84 finished with value: 0.30884035428997186 and parameters: {'n_estimators': 1503, 'max_depth': 25, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 81 with value: 0.30872523854244804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 81. Best value: 0.308725:  43%|████▎     | 86/200 [08:08<13:38,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:50:53,827] Trial 85 finished with value: 0.30910524280284174 and parameters: {'n_estimators': 1499, 'max_depth': 26, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 81 with value: 0.30872523854244804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 81. Best value: 0.308725:  44%|████▎     | 87/200 [08:09<10:09,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:50:54,960] Trial 86 finished with value: 0.3088120099710315 and parameters: {'n_estimators': 751, 'max_depth': 25, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 81 with value: 0.30872523854244804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 81. Best value: 0.308725:  44%|████▍     | 88/200 [08:13<09:02,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:50:58,497] Trial 87 finished with value: 0.30922281990092026 and parameters: {'n_estimators': 703, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 81 with value: 0.30872523854244804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 81. Best value: 0.308725:  44%|████▍     | 89/200 [08:18<09:19,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:51:03,995] Trial 88 finished with value: 0.30889166522730643 and parameters: {'n_estimators': 803, 'max_depth': 25, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 81 with value: 0.30872523854244804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 81. Best value: 0.308725:  45%|████▌     | 90/200 [08:19<06:42,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:51:04,409] Trial 89 finished with value: 0.30876523017337554 and parameters: {'n_estimators': 672, 'max_depth': 25, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 81 with value: 0.30872523854244804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 81. Best value: 0.308725:  46%|████▌     | 91/200 [08:33<12:27,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:51:18,768] Trial 91 finished with value: 0.3088673132338239 and parameters: {'n_estimators': 1400, 'max_depth': 28, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 81 with value: 0.30872523854244804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 81. Best value: 0.308725:  46%|████▌     | 92/200 [08:34<08:58,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:51:19,387] Trial 90 finished with value: 0.3087446861535864 and parameters: {'n_estimators': 1421, 'max_depth': 25, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 81 with value: 0.30872523854244804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 81. Best value: 0.308725:  46%|████▋     | 93/200 [08:45<12:29,  7.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:51:31,103] Trial 93 finished with value: 0.30880149054843564 and parameters: {'n_estimators': 1426, 'max_depth': 16, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 81 with value: 0.30872523854244804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 92. Best value: 0.308638:  47%|████▋     | 94/200 [08:46<08:54,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:51:31,571] Trial 92 finished with value: 0.30863766314970226 and parameters: {'n_estimators': 1422, 'max_depth': 25, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.30863766314970226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 92. Best value: 0.308638:  48%|████▊     | 95/200 [08:50<08:13,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:51:35,461] Trial 95 finished with value: 0.3087372557487231 and parameters: {'n_estimators': 644, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.30863766314970226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 92. Best value: 0.308638:  48%|████▊     | 96/200 [08:56<08:47,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:51:41,387] Trial 94 finished with value: 0.30880560922335165 and parameters: {'n_estimators': 1423, 'max_depth': 16, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.30863766314970226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 92. Best value: 0.308638:  48%|████▊     | 97/200 [08:59<07:43,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:51:44,571] Trial 96 finished with value: 0.3086376796851479 and parameters: {'n_estimators': 1426, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.30863766314970226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 92. Best value: 0.308638:  49%|████▉     | 98/200 [09:03<07:17,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:51:48,366] Trial 98 finished with value: 0.30877663951041767 and parameters: {'n_estimators': 649, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.30863766314970226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 92. Best value: 0.308638:  50%|████▉     | 99/200 [09:04<05:47,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:51:49,828] Trial 97 finished with value: 0.30875021330076363 and parameters: {'n_estimators': 1576, 'max_depth': 16, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.30863766314970226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 92. Best value: 0.308638:  50%|█████     | 100/200 [09:08<05:44,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:51:53,268] Trial 99 finished with value: 0.3089827018710436 and parameters: {'n_estimators': 759, 'max_depth': 16, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.30863766314970226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 92. Best value: 0.308638:  50%|█████     | 101/200 [09:11<05:50,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:51:57,052] Trial 101 finished with value: 0.3091862659312878 and parameters: {'n_estimators': 673, 'max_depth': 17, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.30863766314970226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 92. Best value: 0.308638:  51%|█████     | 102/200 [09:15<06:00,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:52:01,049] Trial 100 finished with value: 0.3087923865216556 and parameters: {'n_estimators': 1414, 'max_depth': 16, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.30863766314970226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 92. Best value: 0.308638:  52%|█████▏    | 103/200 [09:17<05:01,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:52:02,838] Trial 102 finished with value: 0.3091816806260497 and parameters: {'n_estimators': 674, 'max_depth': 17, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.30863766314970226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 92. Best value: 0.308638:  52%|█████▏    | 104/200 [09:20<04:41,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:52:05,333] Trial 103 finished with value: 0.3090145246268124 and parameters: {'n_estimators': 642, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.30863766314970226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 92. Best value: 0.308638:  52%|█████▎    | 105/200 [09:22<04:11,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:52:07,346] Trial 104 finished with value: 0.30900235456906594 and parameters: {'n_estimators': 676, 'max_depth': 16, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.30863766314970226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 92. Best value: 0.308638:  53%|█████▎    | 106/200 [09:24<04:04,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:52:09,823] Trial 105 finished with value: 0.30900315328328354 and parameters: {'n_estimators': 656, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.30863766314970226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 92. Best value: 0.308638:  54%|█████▎    | 107/200 [09:27<04:06,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:52:12,574] Trial 106 finished with value: 0.3088142721461073 and parameters: {'n_estimators': 690, 'max_depth': 15, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.30863766314970226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 92. Best value: 0.308638:  54%|█████▍    | 108/200 [09:29<03:48,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:52:14,677] Trial 107 finished with value: 0.309181713889504 and parameters: {'n_estimators': 677, 'max_depth': 17, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.30863766314970226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 92. Best value: 0.308638:  55%|█████▍    | 109/200 [09:32<04:01,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:52:17,738] Trial 108 finished with value: 0.3090251383395407 and parameters: {'n_estimators': 683, 'max_depth': 16, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.30863766314970226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 92. Best value: 0.308638:  55%|█████▌    | 110/200 [09:34<03:36,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:52:19,543] Trial 109 finished with value: 0.3089892645426584 and parameters: {'n_estimators': 613, 'max_depth': 16, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.30863766314970226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 92. Best value: 0.308638:  56%|█████▌    | 111/200 [09:37<03:48,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:52:22,485] Trial 110 finished with value: 0.3092681217827466 and parameters: {'n_estimators': 644, 'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.30863766314970226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 92. Best value: 0.308638:  56%|█████▌    | 112/200 [09:39<03:24,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:52:24,253] Trial 111 finished with value: 0.308824747316573 and parameters: {'n_estimators': 665, 'max_depth': 15, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.30863766314970226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 92. Best value: 0.308638:  56%|█████▋    | 113/200 [09:45<05:22,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:52:31,198] Trial 112 finished with value: 0.3091773868763412 and parameters: {'n_estimators': 1413, 'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.30863766314970226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 92. Best value: 0.308638:  57%|█████▋    | 114/200 [09:48<04:38,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:52:33,352] Trial 113 finished with value: 0.30914965800828514 and parameters: {'n_estimators': 1280, 'max_depth': 14, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.30863766314970226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 92. Best value: 0.308638:  57%|█████▊    | 115/200 [09:55<06:10,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:52:40,321] Trial 114 finished with value: 0.3091598328439208 and parameters: {'n_estimators': 1249, 'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.30863766314970226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 92. Best value: 0.308638:  58%|█████▊    | 117/200 [09:57<03:44,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:52:42,753] Trial 116 finished with value: 0.3094224152714905 and parameters: {'n_estimators': 582, 'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.30863766314970226.\n",
      "[I 2025-01-11 00:52:42,931] Trial 115 finished with value: 0.3091485134086946 and parameters: {'n_estimators': 1229, 'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.30863766314970226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 92. Best value: 0.308638:  59%|█████▉    | 118/200 [10:02<04:37,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:52:47,907] Trial 117 finished with value: 0.30916454682756794 and parameters: {'n_estimators': 1198, 'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.30863766314970226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 92. Best value: 0.308638:  60%|█████▉    | 119/200 [10:07<05:19,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:52:53,140] Trial 118 finished with value: 0.30871335113576787 and parameters: {'n_estimators': 1380, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.30863766314970226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 92. Best value: 0.308638:  60%|██████    | 120/200 [10:13<05:49,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:52:58,515] Trial 119 finished with value: 0.3091537306970881 and parameters: {'n_estimators': 1272, 'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.30863766314970226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 92. Best value: 0.308638:  60%|██████    | 121/200 [10:17<05:46,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:53:02,951] Trial 120 finished with value: 0.30918523390046315 and parameters: {'n_estimators': 1361, 'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.30863766314970226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 92. Best value: 0.308638:  61%|██████    | 122/200 [10:20<05:11,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:53:06,016] Trial 121 finished with value: 0.3091707344614146 and parameters: {'n_estimators': 1286, 'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.30863766314970226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 92. Best value: 0.308638:  62%|██████▏   | 123/200 [10:27<06:04,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:53:12,495] Trial 122 finished with value: 0.3091769330081484 and parameters: {'n_estimators': 1412, 'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.30863766314970226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 92. Best value: 0.308638:  62%|██████▏   | 124/200 [10:29<05:07,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:53:14,942] Trial 123 finished with value: 0.30917959518276633 and parameters: {'n_estimators': 1414, 'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.30863766314970226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 92. Best value: 0.308638:  62%|██████▎   | 125/200 [10:34<05:10,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:53:19,306] Trial 124 finished with value: 0.3091707344614146 and parameters: {'n_estimators': 1286, 'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.30863766314970226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 92. Best value: 0.308638:  63%|██████▎   | 126/200 [10:39<05:40,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:53:24,949] Trial 125 finished with value: 0.30871335113576787 and parameters: {'n_estimators': 1380, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.30863766314970226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 126. Best value: 0.308474:  64%|██████▎   | 127/200 [10:44<05:29,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:53:29,274] Trial 126 finished with value: 0.30847360580536654 and parameters: {'n_estimators': 1359, 'max_depth': 18, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 126 with value: 0.30847360580536654.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 126. Best value: 0.308474:  64%|██████▍   | 128/200 [10:47<05:10,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:53:33,098] Trial 127 finished with value: 0.30932177224613466 and parameters: {'n_estimators': 1369, 'max_depth': 13, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 126 with value: 0.30847360580536654.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 128. Best value: 0.308401:  64%|██████▍   | 129/200 [10:54<06:03,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:53:40,099] Trial 128 finished with value: 0.30840100414898436 and parameters: {'n_estimators': 1434, 'max_depth': 18, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 128 with value: 0.30840100414898436.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 128. Best value: 0.308401:  65%|██████▌   | 130/200 [10:56<04:39,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:53:41,471] Trial 129 finished with value: 0.30873368459838313 and parameters: {'n_estimators': 1369, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 128 with value: 0.30840100414898436.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 128. Best value: 0.308401:  66%|██████▌   | 132/200 [11:03<03:54,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:53:48,446] Trial 130 finished with value: 0.30873196722439916 and parameters: {'n_estimators': 1370, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 128 with value: 0.30840100414898436.\n",
      "[I 2025-01-11 00:53:48,537] Trial 131 finished with value: 0.30999052315179193 and parameters: {'n_estimators': 1368, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 128 with value: 0.30840100414898436.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 128. Best value: 0.308401:  66%|██████▋   | 133/200 [11:11<05:34,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:53:57,141] Trial 132 finished with value: 0.3086563331144763 and parameters: {'n_estimators': 1415, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 128 with value: 0.30840100414898436.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 128. Best value: 0.308401:  67%|██████▋   | 134/200 [11:13<04:15,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:53:58,379] Trial 133 finished with value: 0.3092778246312642 and parameters: {'n_estimators': 1435, 'max_depth': 13, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 128 with value: 0.30840100414898436.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 128. Best value: 0.308401:  68%|██████▊   | 135/200 [11:20<05:15,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:54:05,520] Trial 134 finished with value: 0.3086428168026088 and parameters: {'n_estimators': 1440, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 128 with value: 0.30840100414898436.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 128. Best value: 0.308401:  68%|██████▊   | 136/200 [11:24<04:55,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:54:09,604] Trial 135 finished with value: 0.3086417966192254 and parameters: {'n_estimators': 1456, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 128 with value: 0.30840100414898436.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 128. Best value: 0.308401:  68%|██████▊   | 137/200 [11:28<04:41,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:54:13,707] Trial 136 finished with value: 0.3086417966192254 and parameters: {'n_estimators': 1456, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 128 with value: 0.30840100414898436.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 128. Best value: 0.308401:  69%|██████▉   | 138/200 [11:33<04:54,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:54:19,115] Trial 137 finished with value: 0.3092686400257659 and parameters: {'n_estimators': 1462, 'max_depth': 13, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 128 with value: 0.30840100414898436.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 128. Best value: 0.308401:  70%|██████▉   | 139/200 [11:37<04:37,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:54:23,182] Trial 138 finished with value: 0.30845641632028425 and parameters: {'n_estimators': 1370, 'max_depth': 18, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 128 with value: 0.30840100414898436.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  70%|███████   | 140/200 [11:43<04:56,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:54:29,051] Trial 139 finished with value: 0.30838567506837683 and parameters: {'n_estimators': 1467, 'max_depth': 18, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  70%|███████   | 141/200 [11:47<04:31,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:54:32,871] Trial 140 finished with value: 0.3086376101227317 and parameters: {'n_estimators': 1455, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  71%|███████   | 142/200 [11:53<04:47,  4.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:54:38,669] Trial 141 finished with value: 0.30847150270846047 and parameters: {'n_estimators': 1358, 'max_depth': 18, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  72%|███████▏  | 143/200 [12:00<05:22,  5.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:54:45,926] Trial 142 finished with value: 0.30856433017865303 and parameters: {'n_estimators': 1472, 'max_depth': 19, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  72%|███████▏  | 144/200 [12:05<04:57,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:54:50,460] Trial 143 finished with value: 0.3085650770774893 and parameters: {'n_estimators': 1466, 'max_depth': 19, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  72%|███████▎  | 145/200 [12:09<04:39,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:54:54,977] Trial 144 finished with value: 0.3086752309412299 and parameters: {'n_estimators': 1469, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  73%|███████▎  | 146/200 [12:15<04:44,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:55:00,674] Trial 145 finished with value: 0.3085595830615805 and parameters: {'n_estimators': 1473, 'max_depth': 19, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  74%|███████▎  | 147/200 [12:20<04:31,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:55:05,453] Trial 146 finished with value: 0.3083864677252535 and parameters: {'n_estimators': 1469, 'max_depth': 18, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  74%|███████▍  | 148/200 [12:27<05:02,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:55:12,886] Trial 147 finished with value: 0.3085660348050367 and parameters: {'n_estimators': 1471, 'max_depth': 19, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  74%|███████▍  | 149/200 [12:31<04:25,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:55:16,649] Trial 148 finished with value: 0.3085650770774893 and parameters: {'n_estimators': 1466, 'max_depth': 19, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  75%|███████▌  | 150/200 [12:38<04:47,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:55:23,675] Trial 149 finished with value: 0.3085766117925246 and parameters: {'n_estimators': 1461, 'max_depth': 19, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  76%|███████▌  | 151/200 [12:41<04:04,  5.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:55:26,922] Trial 150 finished with value: 0.3085538467555329 and parameters: {'n_estimators': 1337, 'max_depth': 19, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  76%|███████▌  | 152/200 [12:47<04:09,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:55:32,614] Trial 151 finished with value: 0.3085595830615805 and parameters: {'n_estimators': 1473, 'max_depth': 19, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  76%|███████▋  | 153/200 [12:54<04:30,  5.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:55:39,674] Trial 152 finished with value: 0.3085616942142436 and parameters: {'n_estimators': 1481, 'max_depth': 19, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  77%|███████▋  | 154/200 [12:58<03:56,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:55:43,367] Trial 153 finished with value: 0.30855864908469427 and parameters: {'n_estimators': 1474, 'max_depth': 19, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  78%|███████▊  | 155/200 [13:05<04:20,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:55:50,690] Trial 154 finished with value: 0.308577389958405 and parameters: {'n_estimators': 1489, 'max_depth': 19, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  78%|███████▊  | 156/200 [13:10<04:03,  5.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:55:55,620] Trial 155 finished with value: 0.3085678030600029 and parameters: {'n_estimators': 1485, 'max_depth': 19, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  78%|███████▊  | 157/200 [13:16<04:06,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:56:01,843] Trial 156 finished with value: 0.3085678030600029 and parameters: {'n_estimators': 1485, 'max_depth': 19, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  79%|███████▉  | 158/200 [13:20<03:34,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:56:05,477] Trial 157 finished with value: 0.308556705578554 and parameters: {'n_estimators': 1331, 'max_depth': 19, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  80%|███████▉  | 159/200 [13:27<03:53,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:56:12,499] Trial 158 finished with value: 0.3085649850215248 and parameters: {'n_estimators': 1476, 'max_depth': 19, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  80%|████████  | 160/200 [13:32<03:35,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:56:17,232] Trial 159 finished with value: 0.30857852672451624 and parameters: {'n_estimators': 1492, 'max_depth': 19, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  80%|████████  | 161/200 [13:38<03:39,  5.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:56:23,428] Trial 160 finished with value: 0.3085842563121917 and parameters: {'n_estimators': 1491, 'max_depth': 19, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  81%|████████  | 162/200 [13:43<03:35,  5.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:56:29,154] Trial 161 finished with value: 0.308577389958405 and parameters: {'n_estimators': 1489, 'max_depth': 19, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  82%|████████▏ | 163/200 [13:48<03:16,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:56:33,666] Trial 162 finished with value: 0.30857981165718645 and parameters: {'n_estimators': 1488, 'max_depth': 19, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  82%|████████▏ | 164/200 [13:55<03:34,  5.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:56:41,151] Trial 163 finished with value: 0.30857981165718645 and parameters: {'n_estimators': 1488, 'max_depth': 19, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  82%|████████▎ | 165/200 [14:00<03:17,  5.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:56:46,010] Trial 164 finished with value: 0.3085781934157466 and parameters: {'n_estimators': 1501, 'max_depth': 19, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  83%|████████▎ | 166/200 [14:05<03:05,  5.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:56:51,025] Trial 165 finished with value: 0.30857844150548913 and parameters: {'n_estimators': 1500, 'max_depth': 19, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  84%|████████▎ | 167/200 [14:11<03:05,  5.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:56:57,031] Trial 166 finished with value: 0.3085735983979018 and parameters: {'n_estimators': 1576, 'max_depth': 19, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  84%|████████▍ | 168/200 [14:18<03:08,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:57:03,607] Trial 167 finished with value: 0.3084105871599781 and parameters: {'n_estimators': 1554, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  84%|████████▍ | 169/200 [14:25<03:10,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:57:10,356] Trial 168 finished with value: 0.30841230755160753 and parameters: {'n_estimators': 1547, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  85%|████████▌ | 170/200 [14:28<02:37,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:57:13,534] Trial 169 finished with value: 0.30842518754721027 and parameters: {'n_estimators': 1533, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  86%|████████▌ | 171/200 [14:33<02:31,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:57:18,614] Trial 170 finished with value: 0.30849652180216847 and parameters: {'n_estimators': 1347, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  86%|████████▌ | 172/200 [14:38<02:21,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:57:23,277] Trial 171 finished with value: 0.30850192174665836 and parameters: {'n_estimators': 1335, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  86%|████████▋ | 173/200 [14:42<02:15,  5.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:57:28,203] Trial 172 finished with value: 0.30849000805133653 and parameters: {'n_estimators': 1333, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  87%|████████▋ | 174/200 [14:50<02:29,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:57:35,624] Trial 173 finished with value: 0.3084207243877629 and parameters: {'n_estimators': 1543, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  88%|████████▊ | 175/200 [14:53<02:06,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:57:39,084] Trial 174 finished with value: 0.3084065637200133 and parameters: {'n_estimators': 1559, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  88%|████████▊ | 176/200 [15:03<02:32,  6.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:57:48,508] Trial 175 finished with value: 0.30840440330739194 and parameters: {'n_estimators': 1560, 'max_depth': 18, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  88%|████████▊ | 177/200 [15:04<01:53,  4.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:57:50,036] Trial 176 finished with value: 0.3084968286809466 and parameters: {'n_estimators': 1324, 'max_depth': 18, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  89%|████████▉ | 178/200 [15:12<02:07,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:57:57,936] Trial 177 finished with value: 0.3084072332947585 and parameters: {'n_estimators': 1553, 'max_depth': 18, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  90%|████████▉ | 179/200 [15:15<01:42,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:58:00,658] Trial 178 finished with value: 0.30849709182516927 and parameters: {'n_estimators': 1326, 'max_depth': 18, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  90%|█████████ | 180/200 [15:23<01:56,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:58:08,716] Trial 179 finished with value: 0.3084205996871425 and parameters: {'n_estimators': 1545, 'max_depth': 18, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  90%|█████████ | 181/200 [15:27<01:42,  5.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:58:13,065] Trial 180 finished with value: 0.308424157817552 and parameters: {'n_estimators': 1544, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  91%|█████████ | 182/200 [15:32<01:31,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:58:17,359] Trial 181 finished with value: 0.3084958185557861 and parameters: {'n_estimators': 1331, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  92%|█████████▏| 183/200 [15:39<01:38,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:58:24,924] Trial 183 finished with value: 0.3084958185557861 and parameters: {'n_estimators': 1331, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  92%|█████████▏| 184/200 [15:40<01:08,  4.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:58:25,580] Trial 182 finished with value: 0.30841588959632155 and parameters: {'n_estimators': 1546, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  92%|█████████▎| 185/200 [15:51<01:32,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:58:36,234] Trial 185 finished with value: 0.30848722560359276 and parameters: {'n_estimators': 1329, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  93%|█████████▎| 186/200 [15:51<01:02,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:58:36,792] Trial 184 finished with value: 0.3084139933821361 and parameters: {'n_estimators': 1549, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 139. Best value: 0.308386:  94%|█████████▎| 187/200 [16:03<01:26,  6.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:58:48,428] Trial 186 finished with value: 0.30841588959632155 and parameters: {'n_estimators': 1546, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 139 with value: 0.30838567506837683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 187. Best value: 0.308374:  94%|█████████▍| 188/200 [16:05<01:02,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:58:50,436] Trial 187 finished with value: 0.3083739671031248 and parameters: {'n_estimators': 1595, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 187 with value: 0.3083739671031248.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 187. Best value: 0.308374:  94%|█████████▍| 189/200 [16:11<01:01,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:58:56,834] Trial 188 finished with value: 0.30839314844182775 and parameters: {'n_estimators': 1613, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 187 with value: 0.3083739671031248.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 187. Best value: 0.308374:  95%|█████████▌| 190/200 [16:18<00:58,  5.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:59:03,230] Trial 189 finished with value: 0.3084111452767982 and parameters: {'n_estimators': 1556, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 187 with value: 0.3083739671031248.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 187. Best value: 0.308374:  96%|█████████▌| 191/200 [16:22<00:47,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:59:07,292] Trial 190 finished with value: 0.3083905764028779 and parameters: {'n_estimators': 1616, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 187 with value: 0.3083739671031248.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 187. Best value: 0.308374:  96%|█████████▌| 192/200 [16:28<00:45,  5.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:59:13,903] Trial 191 finished with value: 0.31062315031116644 and parameters: {'n_estimators': 1612, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 187 with value: 0.3083739671031248.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 187. Best value: 0.308374:  96%|█████████▋| 193/200 [16:33<00:38,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:59:19,148] Trial 192 finished with value: 0.3083866274401612 and parameters: {'n_estimators': 1623, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 187 with value: 0.3083739671031248.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 187. Best value: 0.308374:  97%|█████████▋| 194/200 [16:37<00:30,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:59:22,987] Trial 193 finished with value: 0.3084092782349002 and parameters: {'n_estimators': 1609, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 187 with value: 0.3083739671031248.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 187. Best value: 0.308374:  98%|█████████▊| 195/200 [16:47<00:32,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:59:32,602] Trial 194 finished with value: 0.3083866274401612 and parameters: {'n_estimators': 1623, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 187 with value: 0.3083739671031248.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 187. Best value: 0.308374:  98%|█████████▊| 196/200 [16:50<00:21,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:59:35,273] Trial 195 finished with value: 0.30891468068678307 and parameters: {'n_estimators': 1610, 'max_depth': 17, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 187 with value: 0.3083739671031248.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 187. Best value: 0.308374:  98%|█████████▊| 197/200 [17:00<00:20,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:59:45,602] Trial 196 finished with value: 0.3089108170234143 and parameters: {'n_estimators': 1614, 'max_depth': 17, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 187 with value: 0.3083739671031248.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 187. Best value: 0.308374:  99%|█████████▉| 198/200 [17:01<00:10,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:59:46,515] Trial 197 finished with value: 0.30892454090322136 and parameters: {'n_estimators': 1600, 'max_depth': 17, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 187 with value: 0.3083739671031248.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 187. Best value: 0.308374: 100%|█████████▉| 199/200 [17:07<00:05,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:59:52,627] Trial 198 finished with value: 0.30872384553685234 and parameters: {'n_estimators': 1611, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 187 with value: 0.3083739671031248.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 187. Best value: 0.308374: 100%|██████████| 200/200 [17:10<00:00,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 00:59:56,112] Trial 199 finished with value: 0.3087136184253743 and parameters: {'n_estimators': 1550, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 187 with value: 0.3083739671031248.\n",
      "Best parameters: {'n_estimators': 1595, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 2}\n",
      "Best RMSE: 0.3083739671031248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199
         ],
         "y": [
          0.31042440091521145,
          0.3088381629417076,
          0.31214503868894133,
          0.3090387749852491,
          0.3100164653971905,
          0.30970729680841885,
          0.3087457976822455,
          0.30935818206911647,
          0.309204166888698,
          0.30882119739413455,
          0.31080587435578655,
          0.31096932915599995,
          0.31155114318384364,
          0.309016561796783,
          0.31217762803113197,
          0.311000643453763,
          0.3093624481793943,
          0.30927295740407923,
          0.3096902169160649,
          0.3090102739047237,
          0.3105929421834007,
          0.3092952992965464,
          0.30904463468252114,
          0.30911724186493184,
          0.3090523890659206,
          0.30910811741855504,
          0.3090972823611704,
          0.3090421436593399,
          0.3090658239486566,
          0.30892947710093116,
          0.3092710056371465,
          0.3093512745475243,
          0.30909235926481105,
          0.30909711104623555,
          0.3089260345382894,
          0.3090885049589415,
          0.3090796954149303,
          0.3090793606299872,
          0.3088392554588917,
          0.30886185204272565,
          0.3088480389786525,
          0.30882008328291416,
          0.3090829184120009,
          0.3090761490707469,
          0.30917190193039906,
          0.3093831466223124,
          0.30925617616059786,
          0.30925537647540335,
          0.30924133829486844,
          0.3091527062739684,
          0.3091783550258348,
          0.3088941137063261,
          0.3090669152888049,
          0.30906424686376105,
          0.3090054622371266,
          0.30918637094014906,
          0.30919851171091295,
          0.3096032225606648,
          0.30905824384556974,
          0.3091967169551045,
          0.30911953175754003,
          0.31226147143544253,
          0.3095834414343188,
          0.31455878434276524,
          0.309126080641018,
          0.30959123896458307,
          0.3095940659523195,
          0.30907520605375655,
          0.3090650702903652,
          0.3116727825152037,
          0.3140737068709282,
          0.3138873150512773,
          0.3092894293547884,
          0.30941134381480767,
          0.3092959419081927,
          0.3094152948163773,
          0.3092902764315295,
          0.30942855402855024,
          0.3094199531465435,
          0.3090346303514522,
          0.30883392086177447,
          0.30872523854244804,
          0.30915747681769623,
          0.30914188889158306,
          0.30884035428997186,
          0.30910524280284174,
          0.3088120099710315,
          0.30922281990092026,
          0.30889166522730643,
          0.30876523017337554,
          0.3087446861535864,
          0.3088673132338239,
          0.30863766314970226,
          0.30880149054843564,
          0.30880560922335165,
          0.3087372557487231,
          0.3086376796851479,
          0.30875021330076363,
          0.30877663951041767,
          0.3089827018710436,
          0.3087923865216556,
          0.3091862659312878,
          0.3091816806260497,
          0.3090145246268124,
          0.30900235456906594,
          0.30900315328328354,
          0.3088142721461073,
          0.309181713889504,
          0.3090251383395407,
          0.3089892645426584,
          0.3092681217827466,
          0.308824747316573,
          0.3091773868763412,
          0.30914965800828514,
          0.3091598328439208,
          0.3091485134086946,
          0.3094224152714905,
          0.30916454682756794,
          0.30871335113576787,
          0.3091537306970881,
          0.30918523390046315,
          0.3091707344614146,
          0.3091769330081484,
          0.30917959518276633,
          0.3091707344614146,
          0.30871335113576787,
          0.30847360580536654,
          0.30932177224613466,
          0.30840100414898436,
          0.30873368459838313,
          0.30873196722439916,
          0.30999052315179193,
          0.3086563331144763,
          0.3092778246312642,
          0.3086428168026088,
          0.3086417966192254,
          0.3086417966192254,
          0.3092686400257659,
          0.30845641632028425,
          0.30838567506837683,
          0.3086376101227317,
          0.30847150270846047,
          0.30856433017865303,
          0.3085650770774893,
          0.3086752309412299,
          0.3085595830615805,
          0.3083864677252535,
          0.3085660348050367,
          0.3085650770774893,
          0.3085766117925246,
          0.3085538467555329,
          0.3085595830615805,
          0.3085616942142436,
          0.30855864908469427,
          0.308577389958405,
          0.3085678030600029,
          0.3085678030600029,
          0.308556705578554,
          0.3085649850215248,
          0.30857852672451624,
          0.3085842563121917,
          0.308577389958405,
          0.30857981165718645,
          0.30857981165718645,
          0.3085781934157466,
          0.30857844150548913,
          0.3085735983979018,
          0.3084105871599781,
          0.30841230755160753,
          0.30842518754721027,
          0.30849652180216847,
          0.30850192174665836,
          0.30849000805133653,
          0.3084207243877629,
          0.3084065637200133,
          0.30840440330739194,
          0.3084968286809466,
          0.3084072332947585,
          0.30849709182516927,
          0.3084205996871425,
          0.308424157817552,
          0.3084958185557861,
          0.30841588959632155,
          0.3084958185557861,
          0.3084139933821361,
          0.30848722560359276,
          0.30841588959632155,
          0.3083739671031248,
          0.30839314844182775,
          0.3084111452767982,
          0.3083905764028779,
          0.31062315031116644,
          0.3083866274401612,
          0.3084092782349002,
          0.3083866274401612,
          0.30891468068678307,
          0.3089108170234143,
          0.30892454090322136,
          0.30872384553685234,
          0.3087136184253743
         ]
        },
        {
         "mode": "lines",
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199
         ],
         "y": [
          0.31042440091521145,
          0.3088381629417076,
          0.3088381629417076,
          0.3088381629417076,
          0.3088381629417076,
          0.3088381629417076,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.3087457976822455,
          0.30872523854244804,
          0.30872523854244804,
          0.30872523854244804,
          0.30872523854244804,
          0.30872523854244804,
          0.30872523854244804,
          0.30872523854244804,
          0.30872523854244804,
          0.30872523854244804,
          0.30872523854244804,
          0.30872523854244804,
          0.30863766314970226,
          0.30863766314970226,
          0.30863766314970226,
          0.30863766314970226,
          0.30863766314970226,
          0.30863766314970226,
          0.30863766314970226,
          0.30863766314970226,
          0.30863766314970226,
          0.30863766314970226,
          0.30863766314970226,
          0.30863766314970226,
          0.30863766314970226,
          0.30863766314970226,
          0.30863766314970226,
          0.30863766314970226,
          0.30863766314970226,
          0.30863766314970226,
          0.30863766314970226,
          0.30863766314970226,
          0.30863766314970226,
          0.30863766314970226,
          0.30863766314970226,
          0.30863766314970226,
          0.30863766314970226,
          0.30863766314970226,
          0.30863766314970226,
          0.30863766314970226,
          0.30863766314970226,
          0.30863766314970226,
          0.30863766314970226,
          0.30863766314970226,
          0.30863766314970226,
          0.30863766314970226,
          0.30847360580536654,
          0.30847360580536654,
          0.30840100414898436,
          0.30840100414898436,
          0.30840100414898436,
          0.30840100414898436,
          0.30840100414898436,
          0.30840100414898436,
          0.30840100414898436,
          0.30840100414898436,
          0.30840100414898436,
          0.30840100414898436,
          0.30840100414898436,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.30838567506837683,
          0.3083739671031248,
          0.3083739671031248,
          0.3083739671031248,
          0.3083739671031248,
          0.3083739671031248,
          0.3083739671031248,
          0.3083739671031248,
          0.3083739671031248,
          0.3083739671031248,
          0.3083739671031248,
          0.3083739671031248,
          0.3083739671031248,
          0.3083739671031248
         ]
        },
        {
         "marker": {
          "color": "#cccccc"
         },
         "mode": "markers",
         "name": "Infeasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [],
         "y": []
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 'et_n_estimators': 1244, 'et_max_depth': 27, 'et_min_samples_split': 5, 'et_min_samples_leaf': 2 - 0.3081084996280383\n",
    "# 'et_n_estimators': 1931, 'et_max_depth': 26, 'et_min_samples_split': 4, 'et_min_samples_leaf': 2 - 0.3081757201790431\n",
    "# 'et_n_estimators': 1121, 'et_max_depth': 17, 'et_min_samples_split': 2, 'et_min_samples_leaf': 2 - 0.30813124682434545\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "\n",
    "def get_et_parameters(trial: Trial) -> dict[str, int | float]:\n",
    "    return {\n",
    "        \"max_features\": 0.5,\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 500, 2000),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 10, 30),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 11),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 5),\n",
    "        \"random_state\": RANDOM_STATE,\n",
    "    }\n",
    "\n",
    "\n",
    "model_parameters[ExtraTreesRegressor] = get_et_parameters\n",
    "\n",
    "run_study(ExtraTreesRegressor, X_final, y, kfold, n_trials=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:35:41,071] A new study created in memory with name: no-name-a5aa8e8b-1551-431b-854e-7cf403eba76d\n",
      "Best trial: 1. Best value: 0.331546:   0%|          | 1/200 [00:05<16:52,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:35:46,152] Trial 1 finished with value: 0.3315464480627991 and parameters: {'C': 13.98297631716617, 'epsilon': 0.07122291712709387, 'kernel': 'rbf'}. Best is trial 1 with value: 0.3315464480627991.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.331546:   1%|          | 2/200 [00:05<08:12,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:35:46,819] Trial 5 finished with value: 0.34555452488601235 and parameters: {'C': 28.890412257298664, 'epsilon': 0.28673697577264196, 'kernel': 'rbf'}. Best is trial 1 with value: 0.3315464480627991.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.331546:   2%|▏         | 3/200 [03:38<5:23:12, 98.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:39:19,444] Trial 7 finished with value: 0.3646153557769808 and parameters: {'C': 90.1830823818988, 'epsilon': 0.32622136607759045, 'kernel': 'rbf'}. Best is trial 1 with value: 0.3315464480627991.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.331546:   2%|▏         | 4/200 [03:55<3:37:14, 66.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:39:36,988] Trial 4 finished with value: 0.37456561296540725 and parameters: {'C': 96.54604215430469, 'epsilon': 0.6913570393688361, 'kernel': 'linear'}. Best is trial 1 with value: 0.3315464480627991.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.331546:   2%|▎         | 5/200 [04:06<2:30:01, 46.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:39:47,072] Trial 11 finished with value: 0.3887531066565858 and parameters: {'C': 12.332821896007387, 'epsilon': 0.8072316812549972, 'kernel': 'linear'}. Best is trial 1 with value: 0.3315464480627991.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.331546:   3%|▎         | 6/200 [04:09<1:42:03, 31.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:39:50,318] Trial 6 finished with value: 0.37394795524155605 and parameters: {'C': 15.713768213312573, 'epsilon': 0.5696174781930338, 'kernel': 'rbf'}. Best is trial 1 with value: 0.3315464480627991.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.325368:   4%|▎         | 7/200 [04:09<1:08:54, 21.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:39:50,848] Trial 2 finished with value: 0.3253679572585008 and parameters: {'C': 8.969429009812496, 'epsilon': 0.07393237634576455, 'kernel': 'rbf'}. Best is trial 2 with value: 0.3253679572585008.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.325368:   4%|▍         | 8/200 [06:12<2:52:03, 53.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:41:53,878] Trial 8 finished with value: 0.3553724689551026 and parameters: {'C': 27.019535163500784, 'epsilon': 0.549931433877801, 'kernel': 'linear'}. Best is trial 2 with value: 0.3253679572585008.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.325368:   4%|▍         | 9/200 [06:23<2:08:35, 40.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:42:04,859] Trial 10 finished with value: 0.5629665397946878 and parameters: {'C': 23.471238424104826, 'epsilon': 0.8371391585617721, 'kernel': 'poly'}. Best is trial 2 with value: 0.3253679572585008.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.325368:   5%|▌         | 10/200 [06:34<1:39:09, 31.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:42:15,836] Trial 12 finished with value: 0.890073841839472 and parameters: {'C': 41.39045358230991, 'epsilon': 0.2177869787455073, 'kernel': 'poly'}. Best is trial 2 with value: 0.3253679572585008.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.325368:   6%|▌         | 11/200 [06:50<1:23:27, 26.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:42:31,421] Trial 0 finished with value: 0.34379558851448644 and parameters: {'C': 96.14812309929532, 'epsilon': 0.3445596639145485, 'kernel': 'linear'}. Best is trial 2 with value: 0.3253679572585008.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.325368:   6%|▌         | 12/200 [12:06<5:59:31, 114.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:47:47,993] Trial 13 finished with value: 0.3520061063405501 and parameters: {'C': 58.64979536465051, 'epsilon': 0.48093445430428644, 'kernel': 'linear'}. Best is trial 2 with value: 0.3253679572585008.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.325368:   6%|▋         | 13/200 [12:24<4:25:55, 85.33s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:48:05,628] Trial 15 finished with value: 0.37955587823058073 and parameters: {'C': 71.65611564421897, 'epsilon': 0.5352222332853842, 'kernel': 'rbf'}. Best is trial 2 with value: 0.3253679572585008.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.325368:   7%|▋         | 14/200 [12:37<3:16:47, 63.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:48:18,627] Trial 14 finished with value: 0.3838601928136994 and parameters: {'C': 19.968704812694696, 'epsilon': 0.7447761225484757, 'kernel': 'linear'}. Best is trial 2 with value: 0.3253679572585008.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.325368:   8%|▊         | 15/200 [13:42<3:17:05, 63.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:49:23,580] Trial 17 finished with value: 0.44615911134166397 and parameters: {'C': 8.252891054598509, 'epsilon': 0.7227799475496216, 'kernel': 'rbf'}. Best is trial 2 with value: 0.3253679572585008.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.325368:   8%|▊         | 16/200 [13:44<2:19:12, 45.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:49:25,945] Trial 16 finished with value: 0.3955975421179099 and parameters: {'C': 48.103710439678316, 'epsilon': 0.820045343441582, 'kernel': 'linear'}. Best is trial 2 with value: 0.3253679572585008.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.325368:   8%|▊         | 17/200 [14:57<2:43:29, 53.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:50:38,644] Trial 19 finished with value: 0.6623900067309771 and parameters: {'C': 62.45645336987998, 'epsilon': 0.970196341242333, 'kernel': 'poly'}. Best is trial 2 with value: 0.3253679572585008.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.325368:   9%|▉         | 18/200 [15:37<2:29:51, 49.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:51:18,268] Trial 18 finished with value: 0.35220539639315407 and parameters: {'C': 28.491350042703203, 'epsilon': 0.48916087516830714, 'kernel': 'linear'}. Best is trial 2 with value: 0.3253679572585008.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.325368:  10%|▉         | 19/200 [15:47<1:53:39, 37.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:51:28,621] Trial 20 finished with value: 0.38848763285312093 and parameters: {'C': 20.723227840630535, 'epsilon': 0.8047287560940058, 'kernel': 'linear'}. Best is trial 2 with value: 0.3253679572585008.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.325368:  10%|█         | 20/200 [15:49<1:20:31, 26.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:51:30,209] Trial 21 finished with value: 0.3761283016169589 and parameters: {'C': 63.72311825580065, 'epsilon': 0.009072205973221323, 'kernel': 'rbf'}. Best is trial 2 with value: 0.3253679572585008.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.316563:  10%|█         | 21/200 [15:51<57:41, 19.34s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:51:32,051] Trial 23 finished with value: 0.316563044921561 and parameters: {'C': 1.8657746903258143, 'epsilon': 0.0016237998396219921, 'kernel': 'rbf'}. Best is trial 23 with value: 0.316563044921561.\n",
      "[I 2025-01-11 02:51:32,076] Trial 22 finished with value: 0.36439598754435 and parameters: {'C': 59.71330927594454, 'epsilon': 0.09394058872499472, 'kernel': 'rbf'}. Best is trial 23 with value: 0.316563044921561.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.316563:  12%|█▏        | 23/200 [15:52<31:47, 10.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:51:33,640] Trial 24 finished with value: 0.32211906921127603 and parameters: {'C': 4.646334529011964, 'epsilon': 0.0011252917221988845, 'kernel': 'rbf'}. Best is trial 23 with value: 0.316563044921561.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 25. Best value: 0.314167:  12%|█▏        | 24/200 [15:53<24:19,  8.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:51:34,402] Trial 25 finished with value: 0.3141670055412939 and parameters: {'C': 1.1991591728192095, 'epsilon': 0.02476952946889529, 'kernel': 'rbf'}. Best is trial 25 with value: 0.3141670055412939.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  12%|█▎        | 25/200 [15:54<18:26,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:51:35,156] Trial 26 finished with value: 0.3124535372379237 and parameters: {'C': 1.5814693384474836, 'epsilon': 0.08731807780519488, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  13%|█▎        | 26/200 [15:55<14:36,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:51:36,763] Trial 27 finished with value: 0.32363606451568827 and parameters: {'C': 5.92846121662337, 'epsilon': 0.01000095797070194, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  14%|█▎        | 27/200 [15:56<11:14,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:51:37,742] Trial 28 finished with value: 0.3150865944541073 and parameters: {'C': 1.121968251243004, 'epsilon': 0.010166973833035331, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  14%|█▍        | 28/200 [15:57<08:58,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:51:38,938] Trial 29 finished with value: 0.31751706456072415 and parameters: {'C': 2.3709409877597505, 'epsilon': 0.0033753911751680243, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  14%|█▍        | 29/200 [15:59<07:30,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:51:40,361] Trial 30 finished with value: 0.3220059998740401 and parameters: {'C': 4.95793150126935, 'epsilon': 0.010280853885912697, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  15%|█▌        | 30/200 [16:00<06:03,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:51:41,305] Trial 31 finished with value: 0.3165454402394893 and parameters: {'C': 2.4225656423304347, 'epsilon': 0.022008125015707446, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  16%|█▌        | 31/200 [16:01<05:03,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:51:42,278] Trial 32 finished with value: 0.3184457388787324 and parameters: {'C': 4.21221002834902, 'epsilon': 0.06221085984224106, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  16%|█▌        | 32/200 [16:01<03:44,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:51:42,529] Trial 33 finished with value: 0.3126411512348401 and parameters: {'C': 1.2308865700694278, 'epsilon': 0.12448079842733244, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  16%|█▋        | 33/200 [16:01<03:02,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:51:43,032] Trial 34 finished with value: 0.3143693654525268 and parameters: {'C': 1.616494130621301, 'epsilon': 0.15300936512960972, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  17%|█▋        | 34/200 [16:02<02:25,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:51:43,417] Trial 35 finished with value: 0.3140315557369302 and parameters: {'C': 1.0734324768603827, 'epsilon': 0.1828461897494384, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  18%|█▊        | 35/200 [16:02<02:02,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:51:43,848] Trial 36 finished with value: 0.3141868443253112 and parameters: {'C': 1.208710660656488, 'epsilon': 0.1803891746413224, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  18%|█▊        | 36/200 [16:04<02:26,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:51:45,089] Trial 37 finished with value: 0.34667148211763427 and parameters: {'C': 35.88979048445043, 'epsilon': 0.19030599293851866, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  18%|█▊        | 37/200 [16:05<02:59,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:51:46,678] Trial 38 finished with value: 0.3476676459378598 and parameters: {'C': 37.06601610711789, 'epsilon': 0.17376786470694355, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  19%|█▉        | 38/200 [16:08<04:29,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:51:49,649] Trial 39 finished with value: 0.8870661061296822 and parameters: {'C': 35.779812431680476, 'epsilon': 0.17912474515824844, 'kernel': 'poly'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  20%|█▉        | 39/200 [16:11<05:28,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:51:52,575] Trial 40 finished with value: 0.8810672069313521 and parameters: {'C': 35.32865715483927, 'epsilon': 0.18168687872839578, 'kernel': 'poly'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  20%|██        | 40/200 [16:14<05:56,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:51:55,238] Trial 41 finished with value: 0.9008892676589249 and parameters: {'C': 37.214223178456265, 'epsilon': 0.17696207471104486, 'kernel': 'poly'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  20%|██        | 41/200 [16:14<04:37,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:51:55,855] Trial 42 finished with value: 0.33418479914767846 and parameters: {'C': 16.863766547029922, 'epsilon': 0.1649936386398914, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  21%|██        | 42/200 [16:15<03:59,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:51:56,843] Trial 43 finished with value: 0.33333975690915907 and parameters: {'C': 15.906905632943113, 'epsilon': 0.16456001658335961, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  22%|██▏       | 43/200 [16:18<04:47,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:51:59,411] Trial 44 finished with value: 0.8938356022672499 and parameters: {'C': 34.99838905487277, 'epsilon': 0.16169076863148024, 'kernel': 'poly'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  22%|██▏       | 44/200 [16:20<05:12,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:52:01,825] Trial 45 finished with value: 0.8906368605651304 and parameters: {'C': 36.97504450254184, 'epsilon': 0.18752838160791163, 'kernel': 'poly'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  22%|██▎       | 45/200 [16:22<05:00,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:52:03,600] Trial 46 finished with value: 0.8101866595127142 and parameters: {'C': 37.45576242122344, 'epsilon': 0.25218165873398907, 'kernel': 'poly'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  23%|██▎       | 46/200 [16:23<04:02,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:52:04,327] Trial 47 finished with value: 0.6007471300730911 and parameters: {'C': 15.057818452618704, 'epsilon': 0.2626662029833482, 'kernel': 'poly'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  24%|██▎       | 47/200 [16:24<03:27,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:52:05,178] Trial 48 finished with value: 0.5848140368718813 and parameters: {'C': 14.125955732934331, 'epsilon': 0.2691444361355583, 'kernel': 'poly'}. Best is trial 26 with value: 0.3124535372379237.\n",
      "[I 2025-01-11 02:52:05,215] Trial 49 finished with value: 0.34932008161730327 and parameters: {'C': 16.494793105031324, 'epsilon': 0.4101210219232383, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  24%|██▍       | 49/200 [16:24<02:00,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:52:05,476] Trial 50 finished with value: 0.34805904962008044 and parameters: {'C': 13.743761696746548, 'epsilon': 0.40800152057003536, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  25%|██▌       | 50/200 [16:24<01:47,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:52:05,938] Trial 51 finished with value: 0.3364714745788507 and parameters: {'C': 13.975832888418314, 'epsilon': 0.266035780855679, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  26%|██▌       | 51/200 [16:25<01:39,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:52:06,463] Trial 52 finished with value: 0.33431531431434125 and parameters: {'C': 11.626400310975258, 'epsilon': 0.25967883918477785, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  26%|██▌       | 52/200 [16:25<01:27,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:52:06,864] Trial 53 finished with value: 0.3344469805900456 and parameters: {'C': 10.372655607509326, 'epsilon': 0.2764264572307095, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  26%|██▋       | 53/200 [16:26<01:22,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:52:07,327] Trial 54 finished with value: 0.3339825684346675 and parameters: {'C': 10.57155905690685, 'epsilon': 0.26756848659746, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  27%|██▋       | 54/200 [16:26<01:17,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:52:07,804] Trial 55 finished with value: 0.33462946491836704 and parameters: {'C': 11.697594619045324, 'epsilon': 0.26386102255353794, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  28%|██▊       | 55/200 [16:26<01:04,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:52:08,022] Trial 56 finished with value: 0.3454090707341303 and parameters: {'C': 10.975336067093632, 'epsilon': 0.3939408607323089, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  28%|██▊       | 56/200 [16:27<00:54,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:52:08,260] Trial 57 finished with value: 0.3459824611041881 and parameters: {'C': 11.437141992446955, 'epsilon': 0.3969227400984661, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  28%|██▊       | 57/200 [16:27<00:49,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:52:08,517] Trial 58 finished with value: 0.343516218639291 and parameters: {'C': 9.863650578989366, 'epsilon': 0.379766388222153, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  29%|██▉       | 58/200 [16:28<01:28,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:52:09,798] Trial 59 finished with value: 0.3263441682017614 and parameters: {'C': 10.087150111227505, 'epsilon': 0.09618448886704847, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  30%|██▉       | 59/200 [16:29<01:53,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:52:11,043] Trial 60 finished with value: 0.326834351236071 and parameters: {'C': 10.28000262838813, 'epsilon': 0.1167715835223562, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  30%|███       | 60/200 [16:31<02:11,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:52:12,302] Trial 61 finished with value: 0.32555239665322555 and parameters: {'C': 9.462689232581234, 'epsilon': 0.0924135250593907, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  30%|███       | 61/200 [16:32<02:34,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:52:13,818] Trial 62 finished with value: 0.3266682506829396 and parameters: {'C': 10.368640220184426, 'epsilon': 0.10145498788826549, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  31%|███       | 62/200 [16:34<02:41,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:52:15,133] Trial 63 finished with value: 0.32472316179293803 and parameters: {'C': 8.812749231837705, 'epsilon': 0.0925094555046126, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  32%|███▏      | 63/200 [16:38<04:46,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:52:19,373] Trial 64 finished with value: 0.3757475086587935 and parameters: {'C': 89.41394389278413, 'epsilon': 0.09864919466754077, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  32%|███▏      | 64/200 [16:42<05:50,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:52:23,079] Trial 65 finished with value: 0.3700773349801119 and parameters: {'C': 78.54709778479554, 'epsilon': 0.11022633953260992, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  32%|███▎      | 65/200 [16:45<06:35,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:52:26,840] Trial 66 finished with value: 0.3720879849228513 and parameters: {'C': 82.27289970530244, 'epsilon': 0.10566993095349247, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  33%|███▎      | 66/200 [16:49<07:10,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:52:30,709] Trial 67 finished with value: 0.37374357235943545 and parameters: {'C': 88.67387662510018, 'epsilon': 0.10993028203854378, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  34%|███▎      | 67/200 [16:51<05:56,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:52:32,137] Trial 68 finished with value: 0.3409896940920009 and parameters: {'C': 24.181693825589807, 'epsilon': 0.11395680211225565, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  34%|███▍      | 68/200 [16:58<08:46,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:52:39,181] Trial 3 finished with value: 0.3425113396358256 and parameters: {'C': 59.23106255903037, 'epsilon': 0.015375390611880074, 'kernel': 'linear'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  34%|███▍      | 69/200 [21:33<3:06:36, 85.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 02:57:14,842] Trial 69 finished with value: 0.3405705024357567 and parameters: {'C': 23.03158762234849, 'epsilon': 0.11932553422820397, 'kernel': 'linear'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  35%|███▌      | 70/200 [24:22<3:59:04, 110.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:00:03,230] Trial 9 finished with value: 0.3418323643216665 and parameters: {'C': 76.74508662043922, 'epsilon': 0.0657072986578436, 'kernel': 'linear'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  36%|███▌      | 71/200 [24:53<3:06:33, 86.77s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:00:34,987] Trial 71 finished with value: 0.34204731629785856 and parameters: {'C': 25.8884547461646, 'epsilon': 0.3196396318452141, 'kernel': 'linear'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  36%|███▌      | 72/200 [26:02<2:53:08, 81.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:01:43,068] Trial 72 finished with value: 0.34242327688709173 and parameters: {'C': 5.97495981711086, 'epsilon': 0.0441941093251938, 'kernel': 'linear'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  36%|███▋      | 73/200 [27:00<2:37:16, 74.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:02:41,363] Trial 75 finished with value: 0.3216000187820224 and parameters: {'C': 5.906303796360821, 'epsilon': 0.049529395678255546, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  37%|███▋      | 74/200 [27:21<2:02:28, 58.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:03:02,401] Trial 74 finished with value: 0.3424592419838703 and parameters: {'C': 1.4252908070973271, 'epsilon': 0.049418801242906624, 'kernel': 'linear'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  38%|███▊      | 75/200 [28:25<2:04:51, 59.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:04:06,094] Trial 76 finished with value: 0.34228748492584377 and parameters: {'C': 1.5566019295125275, 'epsilon': 0.05424874242079211, 'kernel': 'linear'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  38%|███▊      | 76/200 [32:43<4:06:57, 119.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:08:24,579] Trial 78 finished with value: 0.33975370817717365 and parameters: {'C': 1.2935638862112424, 'epsilon': 0.22141543593874669, 'kernel': 'linear'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  38%|███▊      | 77/200 [33:10<3:08:07, 91.76s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:08:51,636] Trial 77 finished with value: 0.3421754162436149 and parameters: {'C': 5.9783204687802005, 'epsilon': 0.05545905385848628, 'kernel': 'linear'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  39%|███▉      | 78/200 [33:41<2:29:32, 73.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:09:22,656] Trial 79 finished with value: 0.34236972647830016 and parameters: {'C': 1.0514746393366987, 'epsilon': 0.043357557301900496, 'kernel': 'linear'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  40%|███▉      | 79/200 [35:14<2:39:59, 79.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:10:55,518] Trial 81 finished with value: 0.322479227528901 and parameters: {'C': 6.658111308294771, 'epsilon': 0.05841618532124406, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  40%|████      | 80/200 [35:16<1:52:02, 56.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:10:57,136] Trial 82 finished with value: 0.3125093067828878 and parameters: {'C': 1.065414061980124, 'epsilon': 0.05029218387436257, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  40%|████      | 81/200 [35:18<1:18:59, 39.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:10:59,191] Trial 83 finished with value: 0.3132740638343762 and parameters: {'C': 1.5558862530381405, 'epsilon': 0.05381772158994774, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  41%|████      | 82/200 [35:18<55:13, 28.08s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:10:59,866] Trial 84 finished with value: 0.3216309351217724 and parameters: {'C': 2.6896044575603018, 'epsilon': 0.2174535549612549, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  42%|████▏     | 83/200 [35:19<38:34, 19.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:11:00,271] Trial 85 finished with value: 0.3195449744971802 and parameters: {'C': 1.3380635021684704, 'epsilon': 0.22880274034847622, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  42%|████▏     | 84/200 [35:20<27:12, 14.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:11:01,045] Trial 86 finished with value: 0.3244108281524383 and parameters: {'C': 4.247280243792242, 'epsilon': 0.22118420176782377, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n",
      "[I 2025-01-11 03:11:01,077] Trial 87 finished with value: 0.3909104462861459 and parameters: {'C': 6.731908722495734, 'epsilon': 0.61849610033167, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  43%|████▎     | 86/200 [35:21<15:02,  7.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:11:02,477] Trial 89 finished with value: 0.38973444005715496 and parameters: {'C': 7.24810480233286, 'epsilon': 0.6165945927065002, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n",
      "[I 2025-01-11 03:11:02,679] Trial 88 finished with value: 0.3198008563246126 and parameters: {'C': 4.546830145586272, 'epsilon': 0.13993654006637818, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  44%|████▍     | 88/200 [35:23<09:03,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:11:04,283] Trial 90 finished with value: 0.31839389000880736 and parameters: {'C': 3.711196044172702, 'epsilon': 0.1423589031142262, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  45%|████▌     | 90/200 [35:25<05:28,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:11:06,284] Trial 92 finished with value: 0.407572631177202 and parameters: {'C': 4.679046133340162, 'epsilon': 0.6474157254938533, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n",
      "[I 2025-01-11 03:11:06,481] Trial 91 finished with value: 0.33726928129874095 and parameters: {'C': 20.371117530937635, 'epsilon': 0.14783596473005592, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  46%|████▌     | 91/200 [35:26<04:32,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:11:07,748] Trial 93 finished with value: 0.31956004137737454 and parameters: {'C': 4.388561377401107, 'epsilon': 0.14088605251711317, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  46%|████▌     | 92/200 [35:28<03:53,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:11:09,098] Trial 94 finished with value: 0.31858321086152697 and parameters: {'C': 3.8090755619822243, 'epsilon': 0.14291646660613513, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  46%|████▋     | 93/200 [35:30<03:50,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:11:11,227] Trial 95 finished with value: 0.3359637288225827 and parameters: {'C': 18.98628606804552, 'epsilon': 0.1554278422049504, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  47%|████▋     | 94/200 [35:32<04:04,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:11:13,911] Trial 96 finished with value: 0.3355741404373755 and parameters: {'C': 18.434940160165908, 'epsilon': 0.14021147748159993, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  48%|████▊     | 95/200 [35:34<03:27,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:11:15,088] Trial 97 finished with value: 0.319351646951773 and parameters: {'C': 4.145943432572951, 'epsilon': 0.03087144643516973, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  48%|████▊     | 96/200 [35:35<03:04,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:11:16,404] Trial 98 finished with value: 0.31956601115756456 and parameters: {'C': 4.40764629791725, 'epsilon': 0.13954904875854182, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  48%|████▊     | 97/200 [35:40<04:32,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:11:21,082] Trial 99 finished with value: 0.3403884951717747 and parameters: {'C': 20.536866266455213, 'epsilon': 0.026998438334555445, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  49%|████▉     | 98/200 [35:41<04:08,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:11:23,044] Trial 100 finished with value: 0.3344500947624883 and parameters: {'C': 17.254030444529956, 'epsilon': 0.14177144103349285, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  50%|████▉     | 99/200 [35:43<03:37,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:11:24,539] Trial 101 finished with value: 0.31891440695115764 and parameters: {'C': 3.8920950794906046, 'epsilon': 0.03061717649153224, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  50%|█████     | 100/200 [35:46<03:51,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:11:27,236] Trial 102 finished with value: 0.32522488630955815 and parameters: {'C': 7.751660842581519, 'epsilon': 0.027364517934402692, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  50%|█████     | 101/200 [35:54<06:53,  4.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:11:35,776] Trial 103 finished with value: 0.36505868252843166 and parameters: {'C': 49.28131009510911, 'epsilon': 0.03118768993517753, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  51%|█████     | 102/200 [35:55<05:18,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:11:36,859] Trial 104 finished with value: 0.3249246045035311 and parameters: {'C': 8.569002869562578, 'epsilon': 0.07161263691552396, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  52%|█████▏    | 103/200 [36:04<07:45,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:11:45,264] Trial 105 finished with value: 0.36742893405958116 and parameters: {'C': 53.48041994180946, 'epsilon': 0.03290837031917222, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  52%|█████▏    | 104/200 [36:10<08:14,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:11:51,238] Trial 106 finished with value: 0.3581427813718702 and parameters: {'C': 44.80574644192815, 'epsilon': 0.0790907441883408, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  52%|█████▎    | 105/200 [36:10<05:56,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:11:51,735] Trial 107 finished with value: 0.32264362463716384 and parameters: {'C': 7.142601650424458, 'epsilon': 0.07982197395432925, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  53%|█████▎    | 106/200 [36:12<05:01,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:11:53,648] Trial 108 finished with value: 0.32400325071275454 and parameters: {'C': 7.9938524342818855, 'epsilon': 0.07523892298026046, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  54%|█████▎    | 107/200 [36:14<04:23,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:11:55,637] Trial 109 finished with value: 0.3240043861172808 and parameters: {'C': 7.902653854875937, 'epsilon': 0.07129405019113977, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  54%|█████▍    | 108/200 [36:21<06:14,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:02,585] Trial 110 finished with value: 0.3628912641474586 and parameters: {'C': 52.72331099147334, 'epsilon': 0.0742459072411889, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  55%|█████▍    | 109/200 [36:28<07:34,  5.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:09,749] Trial 111 finished with value: 0.36330304127272595 and parameters: {'C': 52.70541543311858, 'epsilon': 0.07024507670532898, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.312454:  55%|█████▌    | 110/200 [36:32<06:48,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:13,232] Trial 112 finished with value: 0.35839822221649553 and parameters: {'C': 44.4310854933567, 'epsilon': 0.07328062561637724, 'kernel': 'rbf'}. Best is trial 26 with value: 0.3124535372379237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  56%|█████▌    | 111/200 [36:33<05:08,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:14,179] Trial 113 finished with value: 0.3115198260917337 and parameters: {'C': 1.1067880216045107, 'epsilon': 0.07789192087624382, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  56%|█████▌    | 112/200 [36:34<04:01,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:15,253] Trial 114 finished with value: 0.3115783477264712 and parameters: {'C': 1.1152736466989006, 'epsilon': 0.07594275959053987, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  56%|█████▋    | 113/200 [36:34<03:01,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:15,790] Trial 80 finished with value: 0.3424007807239353 and parameters: {'C': 5.801153264217485, 'epsilon': 0.04427200384868041, 'kernel': 'linear'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  57%|█████▋    | 114/200 [36:36<03:03,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:18,031] Trial 115 finished with value: 0.33051787722948117 and parameters: {'C': 13.12377588228237, 'epsilon': 0.07385808254122926, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  57%|█████▊    | 115/200 [36:37<02:29,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:18,928] Trial 116 finished with value: 0.3174672305484515 and parameters: {'C': 2.533186534664025, 'epsilon': 0.009591821188361169, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  58%|█████▊    | 116/200 [36:41<03:25,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:22,987] Trial 117 finished with value: 0.3339460277989942 and parameters: {'C': 13.471599583899883, 'epsilon': 0.004094133370440206, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  58%|█████▊    | 117/200 [36:44<03:22,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:25,397] Trial 118 finished with value: 0.3332121762009426 and parameters: {'C': 13.304114258945381, 'epsilon': 0.01197796240430411, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  59%|█████▉    | 118/200 [36:47<03:36,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:28,495] Trial 119 finished with value: 0.3334518582553463 and parameters: {'C': 12.885461733447949, 'epsilon': 0.0019678821443654643, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  60%|█████▉    | 119/200 [36:49<03:29,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:30,947] Trial 120 finished with value: 0.33321536516620365 and parameters: {'C': 12.951128181223895, 'epsilon': 0.006193455779611935, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  60%|██████    | 120/200 [36:53<03:53,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:34,634] Trial 121 finished with value: 0.8051286001652536 and parameters: {'C': 12.832690622190826, 'epsilon': 0.00941065505954889, 'kernel': 'poly'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  60%|██████    | 121/200 [36:54<03:04,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:35,641] Trial 122 finished with value: 0.31729574920303816 and parameters: {'C': 2.251864834359762, 'epsilon': 0.002458066967938659, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  61%|██████    | 122/200 [36:57<03:21,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:38,790] Trial 123 finished with value: 0.3334148785139893 and parameters: {'C': 12.963810176785957, 'epsilon': 0.0035841362651547314, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  62%|██████▏   | 123/200 [36:57<02:24,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:39,008] Trial 126 finished with value: 0.6787807425206107 and parameters: {'C': 1.0313766480073705, 'epsilon': 0.9934776843689077, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n",
      "[I 2025-01-11 03:12:39,059] Trial 124 finished with value: 0.3166980399881256 and parameters: {'C': 2.1657707507107036, 'epsilon': 0.00987058754289803, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  62%|██████▎   | 125/200 [36:58<01:21,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:39,318] Trial 125 finished with value: 0.3186538788771181 and parameters: {'C': 2.3431326687387437, 'epsilon': 0.1972907627888599, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  63%|██████▎   | 126/200 [36:58<01:08,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:39,770] Trial 127 finished with value: 0.4217533372356638 and parameters: {'C': 1.2219581583824735, 'epsilon': 0.2027535769979622, 'kernel': 'poly'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  64%|██████▎   | 127/200 [36:59<00:55,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:40,095] Trial 128 finished with value: 0.4133873741444097 and parameters: {'C': 2.2332372312513513, 'epsilon': 0.31058084258896645, 'kernel': 'poly'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  64%|██████▍   | 128/200 [36:59<00:51,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:40,667] Trial 129 finished with value: 0.4570249590259703 and parameters: {'C': 2.7866091184855892, 'epsilon': 0.19915096604700222, 'kernel': 'poly'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  64%|██████▍   | 129/200 [36:59<00:40,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:40,880] Trial 130 finished with value: 0.42404102294624824 and parameters: {'C': 1.1291634625310274, 'epsilon': 0.18565144360751343, 'kernel': 'poly'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  65%|██████▌   | 130/200 [37:00<00:33,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:41,122] Trial 131 finished with value: 0.31684717058628487 and parameters: {'C': 1.490102205104104, 'epsilon': 0.20222190043736465, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  66%|██████▌   | 131/200 [37:00<00:32,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:41,579] Trial 132 finished with value: 0.316717153944581 and parameters: {'C': 1.7130183809457658, 'epsilon': 0.19450340096759877, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  66%|██████▌   | 132/200 [37:00<00:29,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:41,941] Trial 133 finished with value: 0.315131845030715 and parameters: {'C': 1.304767320873214, 'epsilon': 0.1909167305693217, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  66%|██████▋   | 133/200 [37:01<00:25,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:42,174] Trial 134 finished with value: 0.3185395171435216 and parameters: {'C': 2.7285947143003124, 'epsilon': 0.18508083067801934, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  67%|██████▋   | 134/200 [37:01<00:24,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:42,521] Trial 136 finished with value: 0.5843010097782315 and parameters: {'C': 5.599904798275807, 'epsilon': 0.9061603712297416, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  68%|██████▊   | 135/200 [37:01<00:25,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:42,940] Trial 135 finished with value: 0.3162763353560126 and parameters: {'C': 3.0164229113679197, 'epsilon': 0.11933264818773184, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  68%|██████▊   | 136/200 [37:02<00:36,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:43,939] Trial 137 finished with value: 0.322448415614689 and parameters: {'C': 6.687864042579973, 'epsilon': 0.12322564931733847, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n",
      "[I 2025-01-11 03:12:44,000] Trial 139 finished with value: 0.5892119410285148 and parameters: {'C': 5.875152184360388, 'epsilon': 0.912520695990106, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  69%|██████▉   | 138/200 [37:03<00:33,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:44,923] Trial 138 finished with value: 0.3211939169449426 and parameters: {'C': 5.7809095263243755, 'epsilon': 0.12425156959526897, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  70%|███████   | 140/200 [37:04<00:28,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:45,687] Trial 140 finished with value: 0.32079831781241513 and parameters: {'C': 5.508235638275384, 'epsilon': 0.1239267572727179, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n",
      "[I 2025-01-11 03:12:45,851] Trial 142 finished with value: 0.5586357838933863 and parameters: {'C': 68.61333948553245, 'epsilon': 0.8886576024722839, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  70%|███████   | 141/200 [37:05<00:29,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:46,420] Trial 141 finished with value: 0.320893006804576 and parameters: {'C': 5.613620471148762, 'epsilon': 0.12130645595723968, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  71%|███████   | 142/200 [37:06<00:33,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:47,174] Trial 143 finished with value: 0.32086618517352217 and parameters: {'C': 5.676234964524236, 'epsilon': 0.11615623560687197, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  72%|███████▏  | 143/200 [37:07<00:38,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:48,089] Trial 144 finished with value: 0.3221874250811321 and parameters: {'C': 6.521199566885476, 'epsilon': 0.12252497869475502, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  72%|███████▏  | 144/200 [37:07<00:40,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:48,929] Trial 145 finished with value: 0.3213910962641576 and parameters: {'C': 5.8947771078517395, 'epsilon': 0.12643541444116999, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  72%|███████▎  | 145/200 [37:08<00:43,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:49,879] Trial 146 finished with value: 0.3213794419349731 and parameters: {'C': 6.102736063602235, 'epsilon': 0.11043585440508459, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  73%|███████▎  | 146/200 [37:09<00:36,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:50,308] Trial 148 finished with value: 0.3502600250561634 and parameters: {'C': 9.198153247893988, 'epsilon': 0.44698998544101487, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  74%|███████▎  | 147/200 [37:09<00:30,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:50,626] Trial 147 finished with value: 0.3204495926461709 and parameters: {'C': 5.3421923689459225, 'epsilon': 0.11965805668211746, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  74%|███████▍  | 148/200 [37:10<00:34,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:51,529] Trial 149 finished with value: 0.3249050820897062 and parameters: {'C': 8.967771530299363, 'epsilon': 0.09547447151468781, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  74%|███████▍  | 149/200 [37:11<00:37,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:52,400] Trial 150 finished with value: 0.31765582001190185 and parameters: {'C': 3.923012907198313, 'epsilon': 0.10671242084938962, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  75%|███████▌  | 150/200 [37:12<00:43,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:53,600] Trial 151 finished with value: 0.3254690766799134 and parameters: {'C': 9.401116966273037, 'epsilon': 0.09590353208683619, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  76%|███████▌  | 151/200 [37:13<00:47,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:54,799] Trial 152 finished with value: 0.3251596480020509 and parameters: {'C': 9.154357847198995, 'epsilon': 0.09242330902096292, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  76%|███████▌  | 152/200 [37:14<00:48,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:55,865] Trial 153 finished with value: 0.3248098475961779 and parameters: {'C': 8.889595243123011, 'epsilon': 0.09730337662432645, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  76%|███████▋  | 153/200 [37:15<00:41,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:56,447] Trial 154 finished with value: 0.32530267449226724 and parameters: {'C': 9.27320264223983, 'epsilon': 0.0959046643104741, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  77%|███████▋  | 154/200 [37:16<00:38,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:57,176] Trial 155 finished with value: 0.3271736672331927 and parameters: {'C': 9.469474635963238, 'epsilon': 0.16560990630832767, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  78%|███████▊  | 155/200 [37:17<00:38,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:12:58,123] Trial 156 finished with value: 0.32529344112219205 and parameters: {'C': 9.257517392716062, 'epsilon': 0.09298262761421654, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  78%|███████▊  | 156/200 [37:19<01:00,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:00,709] Trial 157 finished with value: 0.3487791439396407 and parameters: {'C': 32.51532788136126, 'epsilon': 0.0920568510543337, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  78%|███████▊  | 157/200 [37:20<00:47,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:01,143] Trial 158 finished with value: 0.3445223463569329 and parameters: {'C': 31.00953420143707, 'epsilon': 0.23913113491388321, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  79%|███████▉  | 158/200 [37:20<00:39,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:01,745] Trial 159 finished with value: 0.3179627045452574 and parameters: {'C': 3.677980503106892, 'epsilon': 0.047839817878967676, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  80%|███████▉  | 159/200 [37:21<00:37,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:02,555] Trial 160 finished with value: 0.31746422135394037 and parameters: {'C': 3.4909999536632075, 'epsilon': 0.053041833983865895, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  80%|████████  | 160/200 [37:22<00:35,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:03,439] Trial 161 finished with value: 0.31748150799689806 and parameters: {'C': 3.428675263378003, 'epsilon': 0.046723590892083874, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  80%|████████  | 161/200 [37:23<00:34,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:04,306] Trial 162 finished with value: 0.31733115734439 and parameters: {'C': 3.219514444544914, 'epsilon': 0.0377195646351699, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  81%|████████  | 162/200 [37:23<00:31,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:04,959] Trial 163 finished with value: 0.31662311489714107 and parameters: {'C': 3.0915921210504584, 'epsilon': 0.053410560418747685, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  82%|████████▏ | 163/200 [37:24<00:27,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:05,543] Trial 164 finished with value: 0.3175457966245906 and parameters: {'C': 3.4101986370166872, 'epsilon': 0.04357211954033703, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  82%|████████▏ | 164/200 [37:25<00:26,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:06,233] Trial 165 finished with value: 0.31744935629852183 and parameters: {'C': 3.436405268452269, 'epsilon': 0.04885113671995159, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  82%|████████▎ | 165/200 [37:26<00:27,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:07,124] Trial 166 finished with value: 0.31799330579986174 and parameters: {'C': 3.6003127728343722, 'epsilon': 0.03903450547095756, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  83%|████████▎ | 166/200 [37:26<00:26,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:07,904] Trial 167 finished with value: 0.3176024409952614 and parameters: {'C': 3.505328750317663, 'epsilon': 0.048179198110663915, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  84%|████████▎ | 167/200 [37:27<00:27,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:08,872] Trial 168 finished with value: 0.3174442406851947 and parameters: {'C': 3.4518413474088945, 'epsilon': 0.0504866329484902, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  84%|████████▍ | 168/200 [37:28<00:26,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:09,692] Trial 169 finished with value: 0.3177338795883067 and parameters: {'C': 3.259714568865252, 'epsilon': 0.030651456339870046, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  84%|████████▍ | 169/200 [37:29<00:23,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:10,272] Trial 170 finished with value: 0.3181950184466528 and parameters: {'C': 3.428660206040701, 'epsilon': 0.027689620762997944, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  85%|████████▌ | 170/200 [37:29<00:22,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:11,038] Trial 171 finished with value: 0.31447245459854445 and parameters: {'C': 1.1549675764502065, 'epsilon': 0.020428828241779773, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  86%|████████▌ | 171/200 [37:30<00:19,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:11,475] Trial 172 finished with value: 0.31396689684338575 and parameters: {'C': 1.1447941149365684, 'epsilon': 0.027127348792520534, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  86%|████████▌ | 172/200 [37:31<00:19,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:12,302] Trial 173 finished with value: 0.3166965038778751 and parameters: {'C': 3.203228448030491, 'epsilon': 0.059158178891756036, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  86%|████████▋ | 173/200 [37:31<00:18,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:12,880] Trial 174 finished with value: 0.31384913578941215 and parameters: {'C': 1.0153599860717433, 'epsilon': 0.028306195175870172, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  87%|████████▋ | 174/200 [37:32<00:17,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:13,499] Trial 175 finished with value: 0.31422092749337577 and parameters: {'C': 1.413770403929175, 'epsilon': 0.026901398484476605, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  88%|████████▊ | 175/200 [37:33<00:16,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:14,104] Trial 176 finished with value: 0.3143586385497159 and parameters: {'C': 1.0675107741668703, 'epsilon': 0.02087626689733574, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  88%|████████▊ | 176/200 [37:33<00:15,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:14,707] Trial 177 finished with value: 0.312404612033568 and parameters: {'C': 1.370495392047036, 'epsilon': 0.0675224055745933, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  88%|████████▊ | 177/200 [37:34<00:13,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:15,270] Trial 178 finished with value: 0.3145484253943149 and parameters: {'C': 1.322243772759294, 'epsilon': 0.02134749332641389, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  89%|████████▉ | 178/200 [37:35<00:14,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:16,038] Trial 179 finished with value: 0.31490701214338734 and parameters: {'C': 1.8151891713665007, 'epsilon': 0.027193192906337968, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n",
      "[I 2025-01-11 03:13:16,083] Trial 180 finished with value: 0.3133921511289332 and parameters: {'C': 1.018484526049229, 'epsilon': 0.16496232490497337, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  90%|█████████ | 180/200 [37:37<00:18,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:18,436] Trial 182 finished with value: 0.3136640303755425 and parameters: {'C': 1.2561899865246577, 'epsilon': 0.157357040699605, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  90%|█████████ | 181/200 [37:39<00:21,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:20,155] Trial 70 finished with value: 0.3404673510581024 and parameters: {'C': 88.87293322303637, 'epsilon': 0.1206938505358916, 'kernel': 'linear'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  91%|█████████ | 182/200 [37:39<00:18,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:21,049] Trial 183 finished with value: 0.31160873770473324 and parameters: {'C': 1.0388379230892684, 'epsilon': 0.06926795167666734, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  92%|█████████▏| 183/200 [37:42<00:22,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:23,186] Trial 181 finished with value: 0.3826596433614639 and parameters: {'C': 93.8442456927156, 'epsilon': 0.06594173831197032, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  92%|█████████▏| 184/200 [37:43<00:20,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:24,357] Trial 185 finished with value: 0.31403037833269587 and parameters: {'C': 1.3364606827682481, 'epsilon': 0.1634342683806767, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  92%|█████████▎| 185/200 [37:44<00:18,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:25,451] Trial 186 finished with value: 0.31453708714485407 and parameters: {'C': 1.5778877855608007, 'epsilon': 0.1618651337302689, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  93%|█████████▎| 186/200 [37:46<00:21,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:27,593] Trial 187 finished with value: 0.3143140449145627 and parameters: {'C': 1.0138058837620874, 'epsilon': 0.020950042302329712, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  94%|█████████▎| 187/200 [37:47<00:19,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:29,023] Trial 188 finished with value: 0.31428892047845985 and parameters: {'C': 1.007898049327491, 'epsilon': 0.021456526395612765, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  94%|█████████▍| 188/200 [37:48<00:14,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:29,492] Trial 184 finished with value: 0.3914355634729962 and parameters: {'C': 98.63550427222562, 'epsilon': 0.024373530851080003, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  95%|█████████▌| 190/200 [37:48<00:07,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:29,855] Trial 189 finished with value: 0.31323879194866755 and parameters: {'C': 1.8065239603529113, 'epsilon': 0.07143916039313655, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n",
      "[I 2025-01-11 03:13:30,048] Trial 190 finished with value: 0.31238319012333193 and parameters: {'C': 1.520334162621248, 'epsilon': 0.0792927681289067, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  96%|█████████▌| 191/200 [37:49<00:05,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:30,543] Trial 191 finished with value: 0.31245747287470793 and parameters: {'C': 1.4927715981686402, 'epsilon': 0.07286385986821067, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  96%|█████████▌| 192/200 [37:49<00:04,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:30,937] Trial 192 finished with value: 0.31360803282120453 and parameters: {'C': 1.1613743636864786, 'epsilon': 0.1627779463015114, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  97%|█████████▋| 194/200 [37:50<00:02,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:31,266] Trial 193 finished with value: 0.31332521100099187 and parameters: {'C': 1.0209801683971362, 'epsilon': 0.16204081670101722, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n",
      "[I 2025-01-11 03:13:31,411] Trial 194 finished with value: 0.3134626706566595 and parameters: {'C': 1.045963658186956, 'epsilon': 0.16589685800624981, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  98%|█████████▊| 195/200 [37:50<00:02,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:31,847] Trial 195 finished with value: 0.31290225681290934 and parameters: {'C': 1.0169251751942738, 'epsilon': 0.14708387870296313, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  98%|█████████▊| 197/200 [37:51<00:01,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:32,251] Trial 196 finished with value: 0.31348906364010837 and parameters: {'C': 1.1334556096059683, 'epsilon': 0.160171061488728, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n",
      "[I 2025-01-11 03:13:32,436] Trial 197 finished with value: 0.3115605896327466 and parameters: {'C': 1.1646556010651334, 'epsilon': 0.08222347811807655, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 113. Best value: 0.31152:  99%|█████████▉| 198/200 [37:51<00:00,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:32,867] Trial 199 finished with value: 0.3607880913663716 and parameters: {'C': 1.052933132020577, 'epsilon': 0.5141680205070723, 'kernel': 'rbf'}. Best is trial 113 with value: 0.3115198260917337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 198. Best value: 0.311499: 100%|█████████▉| 199/200 [37:52<00:00,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:13:33,119] Trial 198 finished with value: 0.3114988969103492 and parameters: {'C': 1.1194242850747391, 'epsilon': 0.07979877228746339, 'kernel': 'rbf'}. Best is trial 198 with value: 0.3114988969103492.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 198. Best value: 0.311499: 100%|██████████| 200/200 [43:45<00:00, 13.13s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 03:19:26,339] Trial 73 finished with value: 0.3423409669700594 and parameters: {'C': 90.28170970964041, 'epsilon': 0.04760520344764148, 'kernel': 'linear'}. Best is trial 198 with value: 0.3114988969103492.\n",
      "Best parameters: {'C': 1.1194242850747391, 'epsilon': 0.07979877228746339, 'kernel': 'rbf'}\n",
      "Best RMSE: 0.3114988969103492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199
         ],
         "y": [
          0.34379558851448644,
          0.3315464480627991,
          0.3253679572585008,
          0.3425113396358256,
          0.37456561296540725,
          0.34555452488601235,
          0.37394795524155605,
          0.3646153557769808,
          0.3553724689551026,
          0.3418323643216665,
          0.5629665397946878,
          0.3887531066565858,
          0.890073841839472,
          0.3520061063405501,
          0.3838601928136994,
          0.37955587823058073,
          0.3955975421179099,
          0.44615911134166397,
          0.35220539639315407,
          0.6623900067309771,
          0.38848763285312093,
          0.3761283016169589,
          0.36439598754435,
          0.316563044921561,
          0.32211906921127603,
          0.3141670055412939,
          0.3124535372379237,
          0.32363606451568827,
          0.3150865944541073,
          0.31751706456072415,
          0.3220059998740401,
          0.3165454402394893,
          0.3184457388787324,
          0.3126411512348401,
          0.3143693654525268,
          0.3140315557369302,
          0.3141868443253112,
          0.34667148211763427,
          0.3476676459378598,
          0.8870661061296822,
          0.8810672069313521,
          0.9008892676589249,
          0.33418479914767846,
          0.33333975690915907,
          0.8938356022672499,
          0.8906368605651304,
          0.8101866595127142,
          0.6007471300730911,
          0.5848140368718813,
          0.34932008161730327,
          0.34805904962008044,
          0.3364714745788507,
          0.33431531431434125,
          0.3344469805900456,
          0.3339825684346675,
          0.33462946491836704,
          0.3454090707341303,
          0.3459824611041881,
          0.343516218639291,
          0.3263441682017614,
          0.326834351236071,
          0.32555239665322555,
          0.3266682506829396,
          0.32472316179293803,
          0.3757475086587935,
          0.3700773349801119,
          0.3720879849228513,
          0.37374357235943545,
          0.3409896940920009,
          0.3405705024357567,
          0.3404673510581024,
          0.34204731629785856,
          0.34242327688709173,
          0.3423409669700594,
          0.3424592419838703,
          0.3216000187820224,
          0.34228748492584377,
          0.3421754162436149,
          0.33975370817717365,
          0.34236972647830016,
          0.3424007807239353,
          0.322479227528901,
          0.3125093067828878,
          0.3132740638343762,
          0.3216309351217724,
          0.3195449744971802,
          0.3244108281524383,
          0.3909104462861459,
          0.3198008563246126,
          0.38973444005715496,
          0.31839389000880736,
          0.33726928129874095,
          0.407572631177202,
          0.31956004137737454,
          0.31858321086152697,
          0.3359637288225827,
          0.3355741404373755,
          0.319351646951773,
          0.31956601115756456,
          0.3403884951717747,
          0.3344500947624883,
          0.31891440695115764,
          0.32522488630955815,
          0.36505868252843166,
          0.3249246045035311,
          0.36742893405958116,
          0.3581427813718702,
          0.32264362463716384,
          0.32400325071275454,
          0.3240043861172808,
          0.3628912641474586,
          0.36330304127272595,
          0.35839822221649553,
          0.3115198260917337,
          0.3115783477264712,
          0.33051787722948117,
          0.3174672305484515,
          0.3339460277989942,
          0.3332121762009426,
          0.3334518582553463,
          0.33321536516620365,
          0.8051286001652536,
          0.31729574920303816,
          0.3334148785139893,
          0.3166980399881256,
          0.3186538788771181,
          0.6787807425206107,
          0.4217533372356638,
          0.4133873741444097,
          0.4570249590259703,
          0.42404102294624824,
          0.31684717058628487,
          0.316717153944581,
          0.315131845030715,
          0.3185395171435216,
          0.3162763353560126,
          0.5843010097782315,
          0.322448415614689,
          0.3211939169449426,
          0.5892119410285148,
          0.32079831781241513,
          0.320893006804576,
          0.5586357838933863,
          0.32086618517352217,
          0.3221874250811321,
          0.3213910962641576,
          0.3213794419349731,
          0.3204495926461709,
          0.3502600250561634,
          0.3249050820897062,
          0.31765582001190185,
          0.3254690766799134,
          0.3251596480020509,
          0.3248098475961779,
          0.32530267449226724,
          0.3271736672331927,
          0.32529344112219205,
          0.3487791439396407,
          0.3445223463569329,
          0.3179627045452574,
          0.31746422135394037,
          0.31748150799689806,
          0.31733115734439,
          0.31662311489714107,
          0.3175457966245906,
          0.31744935629852183,
          0.31799330579986174,
          0.3176024409952614,
          0.3174442406851947,
          0.3177338795883067,
          0.3181950184466528,
          0.31447245459854445,
          0.31396689684338575,
          0.3166965038778751,
          0.31384913578941215,
          0.31422092749337577,
          0.3143586385497159,
          0.312404612033568,
          0.3145484253943149,
          0.31490701214338734,
          0.3133921511289332,
          0.3826596433614639,
          0.3136640303755425,
          0.31160873770473324,
          0.3914355634729962,
          0.31403037833269587,
          0.31453708714485407,
          0.3143140449145627,
          0.31428892047845985,
          0.31323879194866755,
          0.31238319012333193,
          0.31245747287470793,
          0.31360803282120453,
          0.31332521100099187,
          0.3134626706566595,
          0.31290225681290934,
          0.31348906364010837,
          0.3115605896327466,
          0.3114988969103492,
          0.3607880913663716
         ]
        },
        {
         "mode": "lines",
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199
         ],
         "y": [
          0.34379558851448644,
          0.3315464480627991,
          0.3253679572585008,
          0.3253679572585008,
          0.3253679572585008,
          0.3253679572585008,
          0.3253679572585008,
          0.3253679572585008,
          0.3253679572585008,
          0.3253679572585008,
          0.3253679572585008,
          0.3253679572585008,
          0.3253679572585008,
          0.3253679572585008,
          0.3253679572585008,
          0.3253679572585008,
          0.3253679572585008,
          0.3253679572585008,
          0.3253679572585008,
          0.3253679572585008,
          0.3253679572585008,
          0.3253679572585008,
          0.3253679572585008,
          0.316563044921561,
          0.316563044921561,
          0.3141670055412939,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3124535372379237,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3115198260917337,
          0.3114988969103492,
          0.3114988969103492
         ]
        },
        {
         "marker": {
          "color": "#cccccc"
         },
         "mode": "markers",
         "name": "Infeasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [],
         "y": []
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "def get_svr_parameters(trial: Trial) -> dict[str, int | float | str]:\n",
    "    return {\n",
    "        \"C\": trial.suggest_float(\"C\", 1, 1e2),\n",
    "        \"epsilon\": trial.suggest_float(\"epsilon\", 1e-3, 1),\n",
    "        \"kernel\": trial.suggest_categorical(\"kernel\", [\"linear\", \"poly\", \"rbf\"]),\n",
    "    }\n",
    "\n",
    "\n",
    "model_parameters[SVR] = get_svr_parameters\n",
    "\n",
    "run_study(SVR, X_final, y, kfold, n_trials=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try a bit different approach, i.e. I'll try to use the XGBoost algorithm, which is known to be probably the most robust and easy to use approach in the classical machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Using cached xgboost-2.1.3-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from xgboost) (2.2.1)\n",
      "Collecting nvidia-nccl-cu12 (from xgboost)\n",
      "  Downloading nvidia_nccl_cu12-2.24.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: scipy in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from xgboost) (1.15.1)\n",
      "Using cached xgboost-2.1.3-py3-none-manylinux_2_28_x86_64.whl (153.9 MB)\n",
      "Downloading nvidia_nccl_cu12-2.24.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nccl-cu12, xgboost\n",
      "Successfully installed nvidia-nccl-cu12-2.24.3 xgboost-2.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:12:55,641] A new study created in memory with name: no-name-4a3f7896-0163-45a9-b8be-5e1b11ff4f80\n",
      "Best trial: 0. Best value: 0.323345:   1%|          | 1/100 [00:05<09:30,  5.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:13:01,409] Trial 0 finished with value: 0.32334473207729647 and parameters: {'tree_method': 'approx', 'max_depth': 3, 'learning_rate': 0.07643285303533266, 'subsample': 0.8370930654749396, 'colsample_bytree': 0.9481006764557574, 'min_child_weight': 29, 'gamma': 0.0040170253335600785, 'reg_alpha': 0.01919243855187923, 'reg_lambda': 0.005839723043457576}. Best is trial 0 with value: 0.32334473207729647.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.319352:   2%|▏         | 2/100 [00:24<21:32, 13.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:13:19,792] Trial 1 finished with value: 0.31935186848795827 and parameters: {'tree_method': 'approx', 'max_depth': 9, 'learning_rate': 0.01686364419659088, 'subsample': 0.7586309781635494, 'colsample_bytree': 0.6216720730487001, 'min_child_weight': 81, 'gamma': 0.0006139599205270051, 'reg_alpha': 0.0380118973296019, 'reg_lambda': 0.07347823128979257}. Best is trial 1 with value: 0.31935186848795827.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.319352:   3%|▎         | 3/100 [00:29<15:18,  9.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:13:24,848] Trial 2 finished with value: 0.3369766355700639 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'learning_rate': 0.06344126469437032, 'subsample': 0.548197202519114, 'colsample_bytree': 0.7947613494083534, 'min_child_weight': 239, 'gamma': 7.892084110995709e-07, 'reg_alpha': 0.1835857607991787, 'reg_lambda': 0.02546727349731931}. Best is trial 1 with value: 0.31935186848795827.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.319352:   4%|▍         | 4/100 [00:35<13:06,  8.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:13:31,085] Trial 3 finished with value: 0.3224974795295562 and parameters: {'tree_method': 'hist', 'max_depth': 3, 'learning_rate': 0.05167268033551108, 'subsample': 0.854115877229914, 'colsample_bytree': 0.992439538982006, 'min_child_weight': 206, 'gamma': 0.008546705776450763, 'reg_alpha': 0.005977141166068439, 'reg_lambda': 0.001392164811714943}. Best is trial 1 with value: 0.31935186848795827.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.319352:   5%|▌         | 5/100 [00:52<18:05, 11.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:13:48,246] Trial 4 finished with value: 0.32548212547511063 and parameters: {'tree_method': 'approx', 'max_depth': 12, 'learning_rate': 0.012074090750814772, 'subsample': 0.7041933598938004, 'colsample_bytree': 0.9022549989109966, 'min_child_weight': 27, 'gamma': 6.9836247861997035e-06, 'reg_alpha': 15.74433336011914, 'reg_lambda': 18.755915493729507}. Best is trial 1 with value: 0.31935186848795827.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.319352:   6%|▌         | 6/100 [01:02<16:57, 10.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:13:57,897] Trial 5 finished with value: 0.32111593759386886 and parameters: {'tree_method': 'approx', 'max_depth': 6, 'learning_rate': 0.016787740225611154, 'subsample': 0.9578710293887087, 'colsample_bytree': 0.5052974604971381, 'min_child_weight': 122, 'gamma': 6.939113073383641e-08, 'reg_alpha': 0.036450908967961944, 'reg_lambda': 3.0013065729223176}. Best is trial 1 with value: 0.31935186848795827.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.319352:   7%|▋         | 7/100 [01:09<14:44,  9.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:14:04,690] Trial 6 finished with value: 0.3304460608542004 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'learning_rate': 0.09919063571017979, 'subsample': 0.907387299294906, 'colsample_bytree': 0.6085078551939707, 'min_child_weight': 185, 'gamma': 3.9246422375710566e-07, 'reg_alpha': 0.09268733289746194, 'reg_lambda': 0.0019858365014464177}. Best is trial 1 with value: 0.31935186848795827.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.319352:   8%|▊         | 8/100 [01:17<14:00,  9.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:14:13,028] Trial 7 finished with value: 0.3395567529083829 and parameters: {'tree_method': 'approx', 'max_depth': 10, 'learning_rate': 0.22886254394294678, 'subsample': 0.7041215119871351, 'colsample_bytree': 0.9680451124985447, 'min_child_weight': 200, 'gamma': 0.0002944130083806254, 'reg_alpha': 0.739912388916959, 'reg_lambda': 5.221581541606372}. Best is trial 1 with value: 0.31935186848795827.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.319352:   9%|▉         | 9/100 [01:22<11:44,  7.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:14:17,706] Trial 8 finished with value: 0.32600964406996835 and parameters: {'tree_method': 'hist', 'max_depth': 4, 'learning_rate': 0.015826058201027577, 'subsample': 0.8939223394034892, 'colsample_bytree': 0.6568174569432341, 'min_child_weight': 203, 'gamma': 2.632923470385733e-08, 'reg_alpha': 0.002948985552864805, 'reg_lambda': 0.05545005645157414}. Best is trial 1 with value: 0.31935186848795827.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.319352:  10%|█         | 10/100 [01:35<14:10,  9.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:14:30,993] Trial 9 finished with value: 0.32185976785480597 and parameters: {'tree_method': 'approx', 'max_depth': 9, 'learning_rate': 0.010100918832198665, 'subsample': 0.7157893956710657, 'colsample_bytree': 0.8487832138676464, 'min_child_weight': 75, 'gamma': 0.0017946196047710535, 'reg_alpha': 7.1921068771971095, 'reg_lambda': 0.014777274646433575}. Best is trial 1 with value: 0.31935186848795827.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.319352:  11%|█         | 11/100 [01:47<15:08, 10.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:14:42,913] Trial 10 finished with value: 0.32098266930466296 and parameters: {'tree_method': 'approx', 'max_depth': 8, 'learning_rate': 0.030229818999868496, 'subsample': 0.5778282019486348, 'colsample_bytree': 0.660576026491359, 'min_child_weight': 109, 'gamma': 0.1415900902390534, 'reg_alpha': 0.001188490937675006, 'reg_lambda': 0.44460638447756085}. Best is trial 1 with value: 0.31935186848795827.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.319352:  12%|█▏        | 12/100 [01:57<15:08, 10.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:14:53,490] Trial 11 finished with value: 0.32000707704337666 and parameters: {'tree_method': 'approx', 'max_depth': 8, 'learning_rate': 0.029706901983307176, 'subsample': 0.5755627756762307, 'colsample_bytree': 0.6726126562895235, 'min_child_weight': 109, 'gamma': 0.27813407659133205, 'reg_alpha': 0.0013592322237688283, 'reg_lambda': 0.21327523372531315}. Best is trial 1 with value: 0.31935186848795827.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.319352:  13%|█▎        | 13/100 [02:02<12:19,  8.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:14:57,801] Trial 12 finished with value: 0.3247738622312258 and parameters: {'tree_method': 'approx', 'max_depth': 7, 'learning_rate': 0.027648428780016485, 'subsample': 0.6320627228164366, 'colsample_bytree': 0.730720451778667, 'min_child_weight': 77, 'gamma': 0.9784230756787679, 'reg_alpha': 1.4682671929858655, 'reg_lambda': 0.2677016218715943}. Best is trial 1 with value: 0.31935186848795827.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.319352:  14%|█▍        | 14/100 [02:13<13:28,  9.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:15:09,290] Trial 13 finished with value: 0.32330064340275233 and parameters: {'tree_method': 'approx', 'max_depth': 12, 'learning_rate': 0.028979629622247947, 'subsample': 0.7879850819009048, 'colsample_bytree': 0.5410584907908023, 'min_child_weight': 148, 'gamma': 7.242617922540822e-05, 'reg_alpha': 0.009042670162847979, 'reg_lambda': 0.8023771169803163}. Best is trial 1 with value: 0.31935186848795827.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.319352:  15%|█▌        | 15/100 [02:26<14:42, 10.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:15:21,947] Trial 14 finished with value: 0.32272581375686527 and parameters: {'tree_method': 'approx', 'max_depth': 9, 'learning_rate': 0.03989789657762377, 'subsample': 0.5091952708459195, 'colsample_bytree': 0.7205139852092484, 'min_child_weight': 76, 'gamma': 0.07693934170393602, 'reg_alpha': 0.002241942441920803, 'reg_lambda': 0.0888628016277653}. Best is trial 1 with value: 0.31935186848795827.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.319352:  16%|█▌        | 16/100 [02:35<13:58,  9.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:15:31,016] Trial 15 finished with value: 0.32403095671044924 and parameters: {'tree_method': 'approx', 'max_depth': 8, 'learning_rate': 0.01791291670084939, 'subsample': 0.6504766434254823, 'colsample_bytree': 0.5925113513654076, 'min_child_weight': 157, 'gamma': 3.142383126575271e-05, 'reg_alpha': 0.20174996570355896, 'reg_lambda': 1.1891660345284916}. Best is trial 1 with value: 0.31935186848795827.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.319352:  17%|█▋        | 17/100 [02:44<13:22,  9.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:15:39,937] Trial 16 finished with value: 0.3394228967099335 and parameters: {'tree_method': 'approx', 'max_depth': 6, 'learning_rate': 0.14324751587625836, 'subsample': 0.7867650719262432, 'colsample_bytree': 0.6753379055744473, 'min_child_weight': 91, 'gamma': 0.03527498059703691, 'reg_alpha': 0.039383915030452375, 'reg_lambda': 0.20081216219622175}. Best is trial 1 with value: 0.31935186848795827.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.317751:  18%|█▊        | 18/100 [03:06<18:14, 13.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:16:01,835] Trial 17 finished with value: 0.31775130621528846 and parameters: {'tree_method': 'approx', 'max_depth': 10, 'learning_rate': 0.023852137158469986, 'subsample': 0.6314231482146775, 'colsample_bytree': 0.7975503214389646, 'min_child_weight': 50, 'gamma': 0.00037529610460553816, 'reg_alpha': 0.6850195369063116, 'reg_lambda': 0.04418190704330143}. Best is trial 17 with value: 0.31775130621528846.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.317751:  19%|█▉        | 19/100 [03:47<29:23, 21.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:16:43,223] Trial 18 finished with value: 0.32518493660317926 and parameters: {'tree_method': 'hist', 'max_depth': 11, 'learning_rate': 0.022039624975638984, 'subsample': 0.644198689150525, 'colsample_bytree': 0.8074517765149979, 'min_child_weight': 2, 'gamma': 0.0005747648857208897, 'reg_alpha': 0.710284690820783, 'reg_lambda': 0.012429509479094126}. Best is trial 17 with value: 0.31775130621528846.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.317751:  20%|██        | 20/100 [04:11<29:42, 22.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:17:06,699] Trial 19 finished with value: 0.3211330770849111 and parameters: {'tree_method': 'approx', 'max_depth': 10, 'learning_rate': 0.043554096556758924, 'subsample': 0.7550070117935889, 'colsample_bytree': 0.7858453486395157, 'min_child_weight': 48, 'gamma': 5.615683597786256e-06, 'reg_alpha': 2.1431309341812437, 'reg_lambda': 0.061951856495120514}. Best is trial 17 with value: 0.31775130621528846.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 20. Best value: 0.314721:  21%|██        | 21/100 [04:33<29:25, 22.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:17:29,203] Trial 20 finished with value: 0.3147211366256484 and parameters: {'tree_method': 'approx', 'max_depth': 11, 'learning_rate': 0.013467741773936382, 'subsample': 0.6208822675989658, 'colsample_bytree': 0.8847004256876512, 'min_child_weight': 53, 'gamma': 0.000442309805000992, 'reg_alpha': 0.1179393460101407, 'reg_lambda': 0.004821353711735757}. Best is trial 20 with value: 0.3147211366256484.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.313767:  22%|██▏       | 22/100 [04:56<29:18, 22.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:17:52,226] Trial 21 finished with value: 0.31376660254463834 and parameters: {'tree_method': 'approx', 'max_depth': 11, 'learning_rate': 0.013224804042342534, 'subsample': 0.6179102142064016, 'colsample_bytree': 0.8703539039477454, 'min_child_weight': 47, 'gamma': 0.0004879466820607224, 'reg_alpha': 0.364546856930029, 'reg_lambda': 0.0034836182238898597}. Best is trial 21 with value: 0.31376660254463834.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.313767:  23%|██▎       | 23/100 [05:19<29:05, 22.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:18:15,178] Trial 22 finished with value: 0.3144455919820876 and parameters: {'tree_method': 'approx', 'max_depth': 11, 'learning_rate': 0.011450699792804888, 'subsample': 0.6134886259625691, 'colsample_bytree': 0.8816570383326559, 'min_child_weight': 47, 'gamma': 1.5471023924987237e-05, 'reg_alpha': 0.41949318227558935, 'reg_lambda': 0.003188659324128774}. Best is trial 21 with value: 0.31376660254463834.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.313767:  24%|██▍       | 24/100 [06:33<48:04, 37.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:19:28,800] Trial 23 finished with value: 0.3163847189725407 and parameters: {'tree_method': 'approx', 'max_depth': 11, 'learning_rate': 0.012467515546004795, 'subsample': 0.5919211259858963, 'colsample_bytree': 0.9007581498101411, 'min_child_weight': 6, 'gamma': 2.0804973696491155e-05, 'reg_alpha': 0.30833150843654944, 'reg_lambda': 0.004606891575839851}. Best is trial 21 with value: 0.31376660254463834.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.313767:  25%|██▌       | 25/100 [06:47<38:33, 30.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:19:43,042] Trial 24 finished with value: 0.31724914425588474 and parameters: {'tree_method': 'approx', 'max_depth': 11, 'learning_rate': 0.010492677835739303, 'subsample': 0.5115337610544449, 'colsample_bytree': 0.8769477365931401, 'min_child_weight': 53, 'gamma': 0.014510248330614635, 'reg_alpha': 3.043354935895613, 'reg_lambda': 0.0034266576814546753}. Best is trial 21 with value: 0.31376660254463834.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.313767:  26%|██▌       | 26/100 [07:15<37:01, 30.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:20:11,159] Trial 25 finished with value: 0.3158841557495281 and parameters: {'tree_method': 'approx', 'max_depth': 12, 'learning_rate': 0.014193177542734081, 'subsample': 0.6732248480378862, 'colsample_bytree': 0.8527942704374719, 'min_child_weight': 36, 'gamma': 2.3092475523756074e-06, 'reg_alpha': 0.10586023167734175, 'reg_lambda': 0.0010040186804622935}. Best is trial 21 with value: 0.31376660254463834.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.313767:  27%|██▋       | 27/100 [07:25<29:02, 23.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:20:20,679] Trial 26 finished with value: 0.3165200213226652 and parameters: {'tree_method': 'hist', 'max_depth': 11, 'learning_rate': 0.018411174511120863, 'subsample': 0.608693374743899, 'colsample_bytree': 0.9302538248290346, 'min_child_weight': 61, 'gamma': 9.659997711254582e-05, 'reg_alpha': 0.34250969068885695, 'reg_lambda': 0.008253429236844044}. Best is trial 21 with value: 0.31376660254463834.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.313767:  28%|██▊       | 28/100 [08:19<39:34, 32.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:21:14,891] Trial 27 finished with value: 0.3150803614821058 and parameters: {'tree_method': 'approx', 'max_depth': 12, 'learning_rate': 0.012607828851372228, 'subsample': 0.5511496951879274, 'colsample_bytree': 0.8353408624709651, 'min_child_weight': 12, 'gamma': 0.002048915882793915, 'reg_alpha': 0.0768381857678421, 'reg_lambda': 0.0026392927146179864}. Best is trial 21 with value: 0.31376660254463834.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.313767:  29%|██▉       | 29/100 [08:56<40:32, 34.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:21:52,145] Trial 28 finished with value: 0.3162823593618934 and parameters: {'tree_method': 'approx', 'max_depth': 11, 'learning_rate': 0.021645274696036228, 'subsample': 0.6759566982250329, 'colsample_bytree': 0.8811802128196722, 'min_child_weight': 25, 'gamma': 2.05020624136075e-05, 'reg_alpha': 0.4412692675147455, 'reg_lambda': 0.018252851906706655}. Best is trial 21 with value: 0.31376660254463834.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.313767:  30%|███       | 30/100 [09:19<35:53, 30.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:22:14,767] Trial 29 finished with value: 0.3360131109160217 and parameters: {'tree_method': 'approx', 'max_depth': 9, 'learning_rate': 0.11107968738190449, 'subsample': 0.5404060191932122, 'colsample_bytree': 0.92535618081, 'min_child_weight': 35, 'gamma': 0.004255482483982391, 'reg_alpha': 0.012791616054422063, 'reg_lambda': 0.008556872144848399}. Best is trial 21 with value: 0.31376660254463834.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.313767:  31%|███       | 31/100 [09:33<29:37, 25.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:22:28,851] Trial 30 finished with value: 0.3688871784165211 and parameters: {'tree_method': 'approx', 'max_depth': 10, 'learning_rate': 0.2885284594620072, 'subsample': 0.604538495355984, 'colsample_bytree': 0.7532953085130024, 'min_child_weight': 102, 'gamma': 0.00017582305161708108, 'reg_alpha': 0.02270066100039853, 'reg_lambda': 0.0047211855167320045}. Best is trial 21 with value: 0.31376660254463834.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.313767:  32%|███▏      | 32/100 [10:14<34:19, 30.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:23:09,709] Trial 31 finished with value: 0.3157818500621848 and parameters: {'tree_method': 'approx', 'max_depth': 12, 'learning_rate': 0.013175205016592157, 'subsample': 0.5543268092170872, 'colsample_bytree': 0.8270257813587922, 'min_child_weight': 17, 'gamma': 0.0018587586411245203, 'reg_alpha': 0.0794476753875417, 'reg_lambda': 0.0023157066185293816}. Best is trial 21 with value: 0.31376660254463834.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.313767:  33%|███▎      | 33/100 [10:34<30:35, 27.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:23:30,326] Trial 32 finished with value: 0.31571056571794837 and parameters: {'tree_method': 'approx', 'max_depth': 12, 'learning_rate': 0.01181158145171243, 'subsample': 0.5381171197526224, 'colsample_bytree': 0.8565368058325955, 'min_child_weight': 65, 'gamma': 0.0012964932022116234, 'reg_alpha': 0.0685498579021463, 'reg_lambda': 0.002981950894838583}. Best is trial 21 with value: 0.31376660254463834.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.313767:  34%|███▍      | 34/100 [10:57<28:45, 26.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:23:53,551] Trial 33 finished with value: 0.31516922678040016 and parameters: {'tree_method': 'approx', 'max_depth': 11, 'learning_rate': 0.013955487301716455, 'subsample': 0.6090790575269596, 'colsample_bytree': 0.9449099609347835, 'min_child_weight': 41, 'gamma': 7.025871706444218e-05, 'reg_alpha': 0.16205858262286243, 'reg_lambda': 0.03053530067583278}. Best is trial 21 with value: 0.31376660254463834.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.313767:  35%|███▌      | 35/100 [11:40<33:36, 31.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:24:35,990] Trial 34 finished with value: 0.31706057945010424 and parameters: {'tree_method': 'approx', 'max_depth': 12, 'learning_rate': 0.019447847001119897, 'subsample': 0.6663608177616375, 'colsample_bytree': 0.7705822444541478, 'min_child_weight': 15, 'gamma': 0.0065191784678267865, 'reg_alpha': 1.3247034090974705, 'reg_lambda': 0.00603773475013478}. Best is trial 21 with value: 0.31376660254463834.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.313767:  36%|███▌      | 36/100 [11:49<26:07, 24.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:24:45,231] Trial 35 finished with value: 0.31804028261939987 and parameters: {'tree_method': 'hist', 'max_depth': 11, 'learning_rate': 0.014990290261563668, 'subsample': 0.5648967301259493, 'colsample_bytree': 0.9932814209499015, 'min_child_weight': 92, 'gamma': 0.0008907067944650737, 'reg_alpha': 0.04977962229731595, 'reg_lambda': 0.0013811981842616965}. Best is trial 21 with value: 0.31376660254463834.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 36. Best value: 0.313653:  37%|███▋      | 37/100 [12:13<25:23, 24.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:25:08,673] Trial 36 finished with value: 0.31365268583086586 and parameters: {'tree_method': 'approx', 'max_depth': 9, 'learning_rate': 0.010057288179471064, 'subsample': 0.5026166137771517, 'colsample_bytree': 0.8189453971126579, 'min_child_weight': 21, 'gamma': 0.019625740926553288, 'reg_alpha': 0.24427185889616607, 'reg_lambda': 0.0020695972021501884}. Best is trial 36 with value: 0.31365268583086586.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 36. Best value: 0.313653:  38%|███▊      | 38/100 [12:32<23:29, 22.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:25:28,024] Trial 37 finished with value: 0.31524668653738347 and parameters: {'tree_method': 'approx', 'max_depth': 9, 'learning_rate': 0.011266781005668157, 'subsample': 0.7257297806912888, 'colsample_bytree': 0.9136872332524559, 'min_child_weight': 63, 'gamma': 0.01529519776110307, 'reg_alpha': 0.231683440349629, 'reg_lambda': 0.0010771830231694015}. Best is trial 36 with value: 0.31365268583086586.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 36. Best value: 0.313653:  39%|███▉      | 39/100 [12:46<20:32, 20.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:25:42,325] Trial 38 finished with value: 0.31495887454815075 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'learning_rate': 0.010245693734331915, 'subsample': 0.5112134155068833, 'colsample_bytree': 0.9607381146733539, 'min_child_weight': 31, 'gamma': 4.1515810682376615e-07, 'reg_alpha': 0.5613827096130227, 'reg_lambda': 0.00843610225925053}. Best is trial 36 with value: 0.31365268583086586.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 36. Best value: 0.313653:  40%|████      | 40/100 [12:55<16:40, 16.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:25:50,799] Trial 39 finished with value: 0.323432960110844 and parameters: {'tree_method': 'approx', 'max_depth': 7, 'learning_rate': 0.01657878184435421, 'subsample': 0.832233992333798, 'colsample_bytree': 0.8829289707364671, 'min_child_weight': 249, 'gamma': 1.6920190873165309e-06, 'reg_alpha': 0.13689031974095733, 'reg_lambda': 0.00202157904361134}. Best is trial 36 with value: 0.31365268583086586.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 36. Best value: 0.313653:  41%|████      | 41/100 [13:05<14:30, 14.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:26:01,067] Trial 40 finished with value: 0.3269284790553225 and parameters: {'tree_method': 'approx', 'max_depth': 9, 'learning_rate': 0.07354658087683542, 'subsample': 0.6814186221930769, 'colsample_bytree': 0.8166466351916318, 'min_child_weight': 124, 'gamma': 5.948563291203835e-06, 'reg_alpha': 1.1397162490745802, 'reg_lambda': 0.021971726983203016}. Best is trial 36 with value: 0.31365268583086586.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 36. Best value: 0.313653:  42%|████▏     | 42/100 [13:20<14:23, 14.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:26:16,255] Trial 41 finished with value: 0.3151615906908484 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'learning_rate': 0.010110162400026464, 'subsample': 0.5032101535635887, 'colsample_bytree': 0.9597183317774113, 'min_child_weight': 28, 'gamma': 2.3194732323771584e-07, 'reg_alpha': 0.4470119953623202, 'reg_lambda': 0.00918257798789464}. Best is trial 36 with value: 0.31365268583086586.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 36. Best value: 0.313653:  43%|████▎     | 43/100 [13:33<13:27, 14.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:26:28,750] Trial 42 finished with value: 0.3182667634934018 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'learning_rate': 0.010054674135038908, 'subsample': 0.5287293251381505, 'colsample_bytree': 0.9769733621906889, 'min_child_weight': 23, 'gamma': 8.213371758607133e-08, 'reg_alpha': 4.30350497944916, 'reg_lambda': 0.005042518108454154}. Best is trial 36 with value: 0.31365268583086586.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 36. Best value: 0.313653:  44%|████▍     | 44/100 [13:43<12:14, 13.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:26:39,384] Trial 43 finished with value: 0.3157152647263469 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'learning_rate': 0.015593056846021162, 'subsample': 0.5863488083879556, 'colsample_bytree': 0.8679633879710007, 'min_child_weight': 41, 'gamma': 1.9584673682151305e-08, 'reg_alpha': 0.598193415943759, 'reg_lambda': 0.0016476376396213595}. Best is trial 36 with value: 0.31365268583086586.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 36. Best value: 0.313653:  45%|████▌     | 45/100 [13:54<11:16, 12.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:26:49,774] Trial 44 finished with value: 0.31581299456897066 and parameters: {'tree_method': 'hist', 'max_depth': 9, 'learning_rate': 0.012847441818062948, 'subsample': 0.5218033697357604, 'colsample_bytree': 0.9010265451197167, 'min_child_weight': 60, 'gamma': 9.18075291109651e-07, 'reg_alpha': 0.3206606956635347, 'reg_lambda': 0.010929263991717985}. Best is trial 36 with value: 0.31365268583086586.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 36. Best value: 0.313653:  46%|████▌     | 46/100 [14:00<09:35, 10.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:26:56,604] Trial 45 finished with value: 0.3238921670676878 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'learning_rate': 0.019686051326661836, 'subsample': 0.6225857059613766, 'colsample_bytree': 0.9473732874710404, 'min_child_weight': 87, 'gamma': 0.00019867688625498786, 'reg_alpha': 13.494808411866824, 'reg_lambda': 0.0035434494369220243}. Best is trial 36 with value: 0.31365268583086586.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 36. Best value: 0.313653:  47%|████▋     | 47/100 [14:07<08:13,  9.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:27:02,777] Trial 46 finished with value: 0.3161233810464261 and parameters: {'tree_method': 'hist', 'max_depth': 4, 'learning_rate': 0.0253577816304131, 'subsample': 0.5731195610725844, 'colsample_bytree': 0.8438535698901084, 'min_child_weight': 1, 'gamma': 4.0193190323292995e-07, 'reg_alpha': 0.024841439963344394, 'reg_lambda': 0.0064518245694905095}. Best is trial 36 with value: 0.31365268583086586.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 36. Best value: 0.313653:  48%|████▊     | 48/100 [14:29<11:28, 13.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:27:25,175] Trial 47 finished with value: 0.31494388359231473 and parameters: {'tree_method': 'approx', 'max_depth': 11, 'learning_rate': 0.011905747881504171, 'subsample': 0.7339430150284733, 'colsample_bytree': 0.8966109689883697, 'min_child_weight': 69, 'gamma': 1.3491320532106945e-05, 'reg_alpha': 0.14026266609324392, 'reg_lambda': 0.0302580450095399}. Best is trial 36 with value: 0.31365268583086586.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 36. Best value: 0.313653:  49%|████▉     | 49/100 [14:53<13:51, 16.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:27:48,649] Trial 48 finished with value: 0.32006463736774265 and parameters: {'tree_method': 'approx', 'max_depth': 11, 'learning_rate': 0.03570924257338501, 'subsample': 0.975446440234318, 'colsample_bytree': 0.893795636140835, 'min_child_weight': 71, 'gamma': 3.4535634984384715e-05, 'reg_alpha': 0.1218088240816843, 'reg_lambda': 24.969758080340096}. Best is trial 36 with value: 0.31365268583086586.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 36. Best value: 0.313653:  50%|█████     | 50/100 [15:02<11:49, 14.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:27:57,915] Trial 49 finished with value: 0.3188653664946638 and parameters: {'tree_method': 'approx', 'max_depth': 8, 'learning_rate': 0.015692388729704417, 'subsample': 0.7252273365758016, 'colsample_bytree': 0.9204623068547857, 'min_child_weight': 144, 'gamma': 1.3699575894137425e-05, 'reg_alpha': 0.22105707356029444, 'reg_lambda': 0.03133890777665213}. Best is trial 36 with value: 0.31365268583086586.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 36. Best value: 0.313653:  51%|█████     | 51/100 [15:24<13:35, 16.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:28:20,242] Trial 50 finished with value: 0.3163982274032553 and parameters: {'tree_method': 'approx', 'max_depth': 11, 'learning_rate': 0.013850608471335749, 'subsample': 0.7010987299197758, 'colsample_bytree': 0.7726755441895503, 'min_child_weight': 50, 'gamma': 0.03982291055810183, 'reg_alpha': 0.05168513228302293, 'reg_lambda': 6.10052110798487}. Best is trial 36 with value: 0.31365268583086586.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 36. Best value: 0.313653:  52%|█████▏    | 52/100 [15:56<17:05, 21.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:28:52,622] Trial 51 finished with value: 0.3164262909011262 and parameters: {'tree_method': 'approx', 'max_depth': 10, 'learning_rate': 0.011471229228332044, 'subsample': 0.7825115403858657, 'colsample_bytree': 0.9419637653523635, 'min_child_weight': 29, 'gamma': 3.6670344440143075e-06, 'reg_alpha': 1.0349985580411312, 'reg_lambda': 0.019004361641375665}. Best is trial 36 with value: 0.31365268583086586.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 36. Best value: 0.313653:  53%|█████▎    | 53/100 [16:11<15:07, 19.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:29:07,126] Trial 52 finished with value: 0.31650638126626757 and parameters: {'tree_method': 'approx', 'max_depth': 11, 'learning_rate': 0.011369977399939151, 'subsample': 0.8303231872982644, 'colsample_bytree': 0.9827722131926779, 'min_child_weight': 41, 'gamma': 0.4498845221076591, 'reg_alpha': 0.4430762527947514, 'reg_lambda': 0.01360103291589175}. Best is trial 36 with value: 0.31365268583086586.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 36. Best value: 0.313653:  54%|█████▍    | 54/100 [16:33<15:24, 20.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:29:29,114] Trial 53 finished with value: 0.324958272064416 and parameters: {'tree_method': 'approx', 'max_depth': 12, 'learning_rate': 0.05469067725043802, 'subsample': 0.8869627606978165, 'colsample_bytree': 0.8615200191228829, 'min_child_weight': 82, 'gamma': 9.231513703301062e-06, 'reg_alpha': 0.18958090564051758, 'reg_lambda': 0.003890872196620506}. Best is trial 36 with value: 0.31365268583086586.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 36. Best value: 0.313653:  55%|█████▌    | 55/100 [16:55<15:35, 20.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:29:51,467] Trial 54 finished with value: 0.31585262959523275 and parameters: {'tree_method': 'approx', 'max_depth': 10, 'learning_rate': 0.011527570876122762, 'subsample': 0.6494235446527246, 'colsample_bytree': 0.8215468743463961, 'min_child_weight': 54, 'gamma': 4.742692022384682e-05, 'reg_alpha': 0.7839601511580466, 'reg_lambda': 0.09200198262531559}. Best is trial 36 with value: 0.31365268583086586.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 36. Best value: 0.313653:  56%|█████▌    | 56/100 [17:04<12:39, 17.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:30:00,549] Trial 55 finished with value: 0.3175027315457969 and parameters: {'tree_method': 'hist', 'max_depth': 11, 'learning_rate': 0.01717967659969577, 'subsample': 0.5617219538760869, 'colsample_bytree': 0.9071828737449107, 'min_child_weight': 71, 'gamma': 0.0004751405144868403, 'reg_alpha': 1.8854655282924393, 'reg_lambda': 0.0017178527022251244}. Best is trial 36 with value: 0.31365268583086586.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  57%|█████▋    | 57/100 [17:14<10:46, 15.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:30:10,363] Trial 56 finished with value: 0.3115224689889944 and parameters: {'tree_method': 'approx', 'max_depth': 5, 'learning_rate': 0.014280147810503038, 'subsample': 0.5008021123851977, 'colsample_bytree': 0.9568077987463945, 'min_child_weight': 18, 'gamma': 3.873147430650413e-08, 'reg_alpha': 0.27208402493696243, 'reg_lambda': 0.006748786929496429}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  58%|█████▊    | 58/100 [17:26<09:47, 13.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:30:21,912] Trial 57 finished with value: 0.3124049907427591 and parameters: {'tree_method': 'approx', 'max_depth': 5, 'learning_rate': 0.01969552673865649, 'subsample': 0.7400208332782715, 'colsample_bytree': 0.8889519300513496, 'min_child_weight': 18, 'gamma': 0.00015785985884938253, 'reg_alpha': 0.269645259377621, 'reg_lambda': 0.0024933979961946095}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  59%|█████▉    | 59/100 [17:38<09:09, 13.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:30:33,909] Trial 58 finished with value: 0.31584706133239043 and parameters: {'tree_method': 'approx', 'max_depth': 5, 'learning_rate': 0.020949617296559614, 'subsample': 0.9385697904903613, 'colsample_bytree': 0.8003313953516988, 'min_child_weight': 12, 'gamma': 0.000159537785610427, 'reg_alpha': 0.270559458421262, 'reg_lambda': 0.002505250708825831}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  60%|██████    | 60/100 [17:49<08:24, 12.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:30:44,713] Trial 59 finished with value: 0.3158882088508603 and parameters: {'tree_method': 'approx', 'max_depth': 5, 'learning_rate': 0.03314829347566689, 'subsample': 0.6914311789595122, 'colsample_bytree': 0.8393977817023349, 'min_child_weight': 19, 'gamma': 6.985426298257886e-08, 'reg_alpha': 0.9672262353868482, 'reg_lambda': 0.0014697431568064456}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  61%|██████    | 61/100 [17:56<07:11, 11.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:30:52,168] Trial 60 finished with value: 0.3205564849662373 and parameters: {'tree_method': 'approx', 'max_depth': 5, 'learning_rate': 0.024611159205199636, 'subsample': 0.5985180342711411, 'colsample_bytree': 0.8742191949755632, 'min_child_weight': 179, 'gamma': 0.000291209412269756, 'reg_alpha': 0.3372687644964121, 'reg_lambda': 0.006124103925610881}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  62%|██████▏   | 62/100 [18:01<05:51,  9.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:30:57,144] Trial 61 finished with value: 0.3156278486392562 and parameters: {'tree_method': 'approx', 'max_depth': 3, 'learning_rate': 0.014263777323513718, 'subsample': 0.7730010301879049, 'colsample_bytree': 0.8906318946551114, 'min_child_weight': 9, 'gamma': 0.000944487661876973, 'reg_alpha': 0.13615495258759436, 'reg_lambda': 0.003241269790355335}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  63%|██████▎   | 63/100 [18:08<05:19,  8.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:31:04,403] Trial 62 finished with value: 0.31487177178709813 and parameters: {'tree_method': 'approx', 'max_depth': 4, 'learning_rate': 0.01753631946645099, 'subsample': 0.7448518250177392, 'colsample_bytree': 0.9291524232666476, 'min_child_weight': 47, 'gamma': 6.769718915194344e-05, 'reg_alpha': 0.15080924494911982, 'reg_lambda': 0.12854125366402663}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  64%|██████▍   | 64/100 [18:14<04:44,  7.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:31:10,589] Trial 63 finished with value: 0.31410986411595704 and parameters: {'tree_method': 'approx', 'max_depth': 4, 'learning_rate': 0.01775503343705909, 'subsample': 0.7505566820526264, 'colsample_bytree': 0.9196310759643287, 'min_child_weight': 42, 'gamma': 0.00011568130496803411, 'reg_alpha': 0.08770055979617919, 'reg_lambda': 0.8217467512623574}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  65%|██████▌   | 65/100 [18:28<05:33,  9.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:31:23,942] Trial 64 finished with value: 0.3217888713418148 and parameters: {'tree_method': 'approx', 'max_depth': 6, 'learning_rate': 0.045487484947554016, 'subsample': 0.8011998479014582, 'colsample_bytree': 0.9162022537021194, 'min_child_weight': 38, 'gamma': 0.003875870277899711, 'reg_alpha': 0.09250728475140176, 'reg_lambda': 3.889097653859703}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  66%|██████▌   | 66/100 [18:34<04:46,  8.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:31:29,729] Trial 65 finished with value: 0.31533031255492044 and parameters: {'tree_method': 'approx', 'max_depth': 3, 'learning_rate': 0.01849279665758437, 'subsample': 0.8134065061569478, 'colsample_bytree': 0.8591118036492938, 'min_child_weight': 21, 'gamma': 0.0028436786327083008, 'reg_alpha': 0.031393995396134765, 'reg_lambda': 1.1318106639410106}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  67%|██████▋   | 67/100 [18:41<04:23,  7.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:31:36,674] Trial 66 finished with value: 0.31771526257935523 and parameters: {'tree_method': 'approx', 'max_depth': 4, 'learning_rate': 0.015050401411832974, 'subsample': 0.6261324219115273, 'colsample_bytree': 0.7217750626905319, 'min_child_weight': 56, 'gamma': 0.00014930466736464627, 'reg_alpha': 0.062099319972690484, 'reg_lambda': 0.35549637871992706}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  68%|██████▊   | 68/100 [18:48<04:14,  7.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:31:44,534] Trial 67 finished with value: 0.31570875868174375 and parameters: {'tree_method': 'approx', 'max_depth': 5, 'learning_rate': 0.013546322779063539, 'subsample': 0.5282383460040192, 'colsample_bytree': 0.9319129815600651, 'min_child_weight': 45, 'gamma': 0.0002881587725307541, 'reg_alpha': 0.23333597588850014, 'reg_lambda': 10.026129209956387}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  69%|██████▉   | 69/100 [18:57<04:09,  8.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:31:52,853] Trial 68 finished with value: 0.32947592662376807 and parameters: {'tree_method': 'approx', 'max_depth': 7, 'learning_rate': 0.02278941240956715, 'subsample': 0.7120410287174266, 'colsample_bytree': 0.5033054981337068, 'min_child_weight': 228, 'gamma': 0.0007087461420179663, 'reg_alpha': 0.09876667546412397, 'reg_lambda': 0.001170931547825678}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  70%|███████   | 70/100 [19:04<03:55,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:32:00,273] Trial 69 finished with value: 0.33990631596996385 and parameters: {'tree_method': 'approx', 'max_depth': 4, 'learning_rate': 0.16717121334898605, 'subsample': 0.6605864437318392, 'colsample_bytree': 0.873881559938201, 'min_child_weight': 30, 'gamma': 1.147939779638616e-08, 'reg_alpha': 0.41840668872814313, 'reg_lambda': 0.6092284364489683}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  71%|███████   | 71/100 [19:15<04:16,  8.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:32:11,370] Trial 70 finished with value: 0.3165907587476354 and parameters: {'tree_method': 'approx', 'max_depth': 6, 'learning_rate': 0.026287405546081437, 'subsample': 0.757156690858962, 'colsample_bytree': 0.6927787028595918, 'min_child_weight': 7, 'gamma': 0.12322409427707998, 'reg_alpha': 0.19126009560647148, 'reg_lambda': 1.5890819250539594}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  72%|███████▏  | 72/100 [19:23<04:00,  8.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:32:19,407] Trial 71 finished with value: 0.31674664482218934 and parameters: {'tree_method': 'approx', 'max_depth': 4, 'learning_rate': 0.017313664666059506, 'subsample': 0.8576896313692347, 'colsample_bytree': 0.9339896074091331, 'min_child_weight': 47, 'gamma': 5.5537403061841655e-05, 'reg_alpha': 0.15659383441823907, 'reg_lambda': 1.9217089920118708}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  73%|███████▎  | 73/100 [19:33<04:05,  9.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:32:29,603] Trial 72 finished with value: 0.31455181166525564 and parameters: {'tree_method': 'approx', 'max_depth': 5, 'learning_rate': 0.020175927319913228, 'subsample': 0.7449315024881706, 'colsample_bytree': 0.962938949058898, 'min_child_weight': 34, 'gamma': 8.425613335052646e-05, 'reg_alpha': 0.2616265644892968, 'reg_lambda': 0.14454493384195294}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  74%|███████▍  | 74/100 [19:43<04:00,  9.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:32:39,281] Trial 73 finished with value: 0.3151385148047975 and parameters: {'tree_method': 'approx', 'max_depth': 5, 'learning_rate': 0.020479213373293875, 'subsample': 0.7734827693052004, 'colsample_bytree': 0.9651374860384719, 'min_child_weight': 32, 'gamma': 0.00012188173152470257, 'reg_alpha': 0.5456305312836581, 'reg_lambda': 0.002186061576951545}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  75%|███████▌  | 75/100 [19:54<04:02,  9.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:32:49,968] Trial 74 finished with value: 0.31337432215858485 and parameters: {'tree_method': 'approx', 'max_depth': 5, 'learning_rate': 0.013291889517799485, 'subsample': 0.7437196375429388, 'colsample_bytree': 0.9517790038284278, 'min_child_weight': 24, 'gamma': 2.594877147324631e-05, 'reg_alpha': 0.28404950772498716, 'reg_lambda': 0.004150909345380893}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  76%|███████▌  | 76/100 [20:05<04:01, 10.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:33:00,952] Trial 75 finished with value: 0.3143898985574996 and parameters: {'tree_method': 'approx', 'max_depth': 5, 'learning_rate': 0.012519420869462748, 'subsample': 0.7498243552590476, 'colsample_bytree': 0.9950398591580694, 'min_child_weight': 18, 'gamma': 3.310373951864455e-05, 'reg_alpha': 0.8035528928791338, 'reg_lambda': 0.002696909286279298}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  77%|███████▋  | 77/100 [20:23<04:46, 12.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:33:19,033] Trial 76 finished with value: 0.3155905603141781 and parameters: {'tree_method': 'approx', 'max_depth': 6, 'learning_rate': 0.010806139437454246, 'subsample': 0.8037485321126978, 'colsample_bytree': 0.9764344707302746, 'min_child_weight': 17, 'gamma': 3.007165579696334e-05, 'reg_alpha': 0.8201392599722688, 'reg_lambda': 0.004270102346534477}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  78%|███████▊  | 78/100 [20:34<04:26, 12.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:33:30,332] Trial 77 finished with value: 0.31492401351364185 and parameters: {'tree_method': 'approx', 'max_depth': 5, 'learning_rate': 0.012855188277641557, 'subsample': 0.7677416239900517, 'colsample_bytree': 0.9940287570810682, 'min_child_weight': 24, 'gamma': 1.3308519179881817e-05, 'reg_alpha': 2.0233181256087573, 'reg_lambda': 0.002747293478180372}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  79%|███████▉  | 79/100 [21:13<07:02, 20.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:34:09,109] Trial 78 finished with value: 0.3179843463128667 and parameters: {'tree_method': 'approx', 'max_depth': 7, 'learning_rate': 0.014940742176224696, 'subsample': 0.6894768302657452, 'colsample_bytree': 0.954031826202954, 'min_child_weight': 3, 'gamma': 2.5708610665972374e-05, 'reg_alpha': 0.383073741297638, 'reg_lambda': 0.007544310877644316}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  80%|████████  | 80/100 [21:22<05:35, 16.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:34:18,154] Trial 79 finished with value: 0.31383087274696136 and parameters: {'tree_method': 'approx', 'max_depth': 4, 'learning_rate': 0.01216070515590424, 'subsample': 0.7350019085770113, 'colsample_bytree': 0.9984030958522149, 'min_child_weight': 11, 'gamma': 2.0654542052178105e-06, 'reg_alpha': 1.5419269585765796, 'reg_lambda': 0.0020389388608852855}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  81%|████████  | 81/100 [21:28<04:18, 13.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:34:24,237] Trial 80 finished with value: 0.3181917784162221 and parameters: {'tree_method': 'approx', 'max_depth': 3, 'learning_rate': 0.01263921411544056, 'subsample': 0.7294072479413163, 'colsample_bytree': 0.9977019660621529, 'min_child_weight': 13, 'gamma': 2.8318475427074813e-06, 'reg_alpha': 4.788237505631242, 'reg_lambda': 0.001832041703405215}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  82%|████████▏ | 82/100 [21:37<03:41, 12.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:34:33,531] Trial 81 finished with value: 0.31475073614098703 and parameters: {'tree_method': 'approx', 'max_depth': 4, 'learning_rate': 0.016109830634772126, 'subsample': 0.7124514228753158, 'colsample_bytree': 0.9805306124706331, 'min_child_weight': 25, 'gamma': 8.918820877053735e-07, 'reg_alpha': 0.5421999721155182, 'reg_lambda': 0.0013864946988242698}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  83%|████████▎ | 83/100 [21:58<04:09, 14.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:34:53,820] Trial 82 finished with value: 0.3148235642823923 and parameters: {'tree_method': 'approx', 'max_depth': 6, 'learning_rate': 0.012236413146180737, 'subsample': 0.7425020746350973, 'colsample_bytree': 0.9417107569916234, 'min_child_weight': 8, 'gamma': 4.692621337171783e-06, 'reg_alpha': 1.4765714547038942, 'reg_lambda': 0.0031600587824635444}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  84%|████████▍ | 84/100 [22:05<03:18, 12.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:35:00,978] Trial 83 finished with value: 0.3139582272928641 and parameters: {'tree_method': 'approx', 'max_depth': 4, 'learning_rate': 0.010833719430448903, 'subsample': 0.7561006853778397, 'colsample_bytree': 0.973055575640428, 'min_child_weight': 17, 'gamma': 1.3233246336882174e-07, 'reg_alpha': 0.7874121682768761, 'reg_lambda': 0.002274709883337498}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  85%|████████▌ | 85/100 [22:13<02:45, 11.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:35:08,784] Trial 84 finished with value: 0.3157496787028782 and parameters: {'tree_method': 'approx', 'max_depth': 4, 'learning_rate': 0.010736915342460967, 'subsample': 0.7604831482756175, 'colsample_bytree': 0.973644190598299, 'min_child_weight': 15, 'gamma': 4.312708658267124e-08, 'reg_alpha': 2.4072929086722286, 'reg_lambda': 0.0021553405790755084}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  86%|████████▌ | 86/100 [22:26<02:42, 11.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:35:21,725] Trial 85 finished with value: 0.32381633103581225 and parameters: {'tree_method': 'approx', 'max_depth': 5, 'learning_rate': 0.06416038235721241, 'subsample': 0.7991664165882763, 'colsample_bytree': 0.9860868092036408, 'min_child_weight': 1, 'gamma': 1.5343357778965319e-07, 'reg_alpha': 0.8107315900076576, 'reg_lambda': 0.0011422734694545081}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  87%|████████▋ | 87/100 [22:32<02:09,  9.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:35:27,815] Trial 86 finished with value: 0.31512389807158725 and parameters: {'tree_method': 'approx', 'max_depth': 3, 'learning_rate': 0.014494090624095448, 'subsample': 0.500010554312414, 'colsample_bytree': 0.954140780140202, 'min_child_weight': 19, 'gamma': 1.4504882911670863e-07, 'reg_alpha': 1.5226858796521796, 'reg_lambda': 0.005584733519901944}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  88%|████████▊ | 88/100 [22:39<01:51,  9.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:35:35,636] Trial 87 finished with value: 0.3163691600260178 and parameters: {'tree_method': 'approx', 'max_depth': 4, 'learning_rate': 0.013400383663102554, 'subsample': 0.7865464252175512, 'colsample_bytree': 0.9093587217125494, 'min_child_weight': 37, 'gamma': 3.183286480995502e-08, 'reg_alpha': 3.069247796884526, 'reg_lambda': 0.004093102003124529}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  89%|████████▉ | 89/100 [22:48<01:40,  9.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:35:44,397] Trial 88 finished with value: 0.31760703564349135 and parameters: {'tree_method': 'approx', 'max_depth': 5, 'learning_rate': 0.010052438536063085, 'subsample': 0.7188232207213783, 'colsample_bytree': 0.5667624405566882, 'min_child_weight': 24, 'gamma': 2.0178802519873662e-06, 'reg_alpha': 0.610628645020179, 'reg_lambda': 0.0018469128094300692}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  90%|█████████ | 90/100 [22:56<01:27,  8.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:35:52,146] Trial 89 finished with value: 0.31387715205365935 and parameters: {'tree_method': 'approx', 'max_depth': 4, 'learning_rate': 0.018640350428080443, 'subsample': 0.7331032684398168, 'colsample_bytree': 0.968644042960891, 'min_child_weight': 8, 'gamma': 1.2730821418415404e-06, 'reg_alpha': 0.2863433643046922, 'reg_lambda': 0.010941475533650248}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  91%|█████████ | 91/100 [23:03<01:13,  8.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:35:58,856] Trial 90 finished with value: 0.31355434013120004 and parameters: {'tree_method': 'approx', 'max_depth': 4, 'learning_rate': 0.016358550080477437, 'subsample': 0.701383205621953, 'colsample_bytree': 0.9379058678429893, 'min_child_weight': 8, 'gamma': 1.3349257457138125e-06, 'reg_alpha': 0.2996449568753962, 'reg_lambda': 0.0091896027303487}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  92%|█████████▏| 92/100 [23:11<01:05,  8.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:36:07,027] Trial 91 finished with value: 0.31419329624478276 and parameters: {'tree_method': 'approx', 'max_depth': 4, 'learning_rate': 0.01646476441110293, 'subsample': 0.7677589659771169, 'colsample_bytree': 0.9418125053963925, 'min_child_weight': 10, 'gamma': 4.938960599293643e-07, 'reg_alpha': 0.29750943473877056, 'reg_lambda': 0.009547129275215177}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  93%|█████████▎| 93/100 [23:16<00:50,  7.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:36:11,897] Trial 92 finished with value: 0.314556687272378 and parameters: {'tree_method': 'approx', 'max_depth': 3, 'learning_rate': 0.01856908556483574, 'subsample': 0.7338333121787746, 'colsample_bytree': 0.9690248471035312, 'min_child_weight': 9, 'gamma': 1.2746901555245218e-06, 'reg_alpha': 0.19308407613177495, 'reg_lambda': 0.01071090716315561}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  94%|█████████▍| 94/100 [23:23<00:42,  7.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:36:18,919] Trial 93 finished with value: 0.3137511852015545 and parameters: {'tree_method': 'approx', 'max_depth': 4, 'learning_rate': 0.010926434038389558, 'subsample': 0.6991665325250507, 'colsample_bytree': 0.9199768731051603, 'min_child_weight': 28, 'gamma': 1.0214153925858661e-07, 'reg_alpha': 0.36633944817125463, 'reg_lambda': 0.006812774073895182}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  95%|█████████▌| 95/100 [23:31<00:37,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:36:27,240] Trial 94 finished with value: 0.31471980922118936 and parameters: {'tree_method': 'approx', 'max_depth': 4, 'learning_rate': 0.010888438052759693, 'subsample': 0.7000849732006016, 'colsample_bytree': 0.9560520739621169, 'min_child_weight': 29, 'gamma': 2.591522866671347e-07, 'reg_alpha': 0.3474253681399184, 'reg_lambda': 0.015424978197018763}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  96%|█████████▌| 96/100 [23:36<00:27,  6.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:36:32,400] Trial 95 finished with value: 0.31487718764848327 and parameters: {'tree_method': 'approx', 'max_depth': 3, 'learning_rate': 0.011939178754625903, 'subsample': 0.639026664188625, 'colsample_bytree': 0.9366616658503097, 'min_child_weight': 4, 'gamma': 1.4641685989763268e-07, 'reg_alpha': 0.45419939538352583, 'reg_lambda': 0.00716830163139842}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  97%|█████████▋| 97/100 [23:45<00:22,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:36:41,020] Trial 96 finished with value: 0.31378776654319324 and parameters: {'tree_method': 'approx', 'max_depth': 4, 'learning_rate': 0.014004542904567733, 'subsample': 0.6838212022740309, 'colsample_bytree': 0.949736058171925, 'min_child_weight': 15, 'gamma': 4.7045933371837814e-08, 'reg_alpha': 1.1191033054073318, 'reg_lambda': 0.0049403753478389255}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  98%|█████████▊| 98/100 [24:11<00:25, 12.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:37:06,710] Trial 97 finished with value: 0.31501273827324977 and parameters: {'tree_method': 'approx', 'max_depth': 8, 'learning_rate': 0.015749375806122002, 'subsample': 0.6844744360896144, 'colsample_bytree': 0.9224596194711738, 'min_child_weight': 23, 'gamma': 1.3924823647721643e-08, 'reg_alpha': 1.1971444224875447, 'reg_lambda': 0.005035974495425546}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522:  99%|█████████▉| 99/100 [24:21<00:11, 11.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:37:16,732] Trial 98 finished with value: 0.311937495347612 and parameters: {'tree_method': 'approx', 'max_depth': 4, 'learning_rate': 0.014641156525839036, 'subsample': 0.6626608454862588, 'colsample_bytree': 0.9044128217707972, 'min_child_weight': 13, 'gamma': 2.531342128537524e-08, 'reg_alpha': 0.260543842006073, 'reg_lambda': 0.015619633473139624}. Best is trial 56 with value: 0.3115224689889944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.311522: 100%|██████████| 100/100 [24:32<00:00, 14.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 12:37:27,875] Trial 99 finished with value: 0.31355896055169363 and parameters: {'tree_method': 'approx', 'max_depth': 5, 'learning_rate': 0.014122177105514722, 'subsample': 0.6654602155876579, 'colsample_bytree': 0.9009958139501727, 'min_child_weight': 33, 'gamma': 4.863680473205684e-08, 'reg_alpha': 0.2593063291245241, 'reg_lambda': 0.003919407656691035}. Best is trial 56 with value: 0.3115224689889944.\n",
      "Best parameters: {'tree_method': 'approx', 'max_depth': 5, 'learning_rate': 0.014280147810503038, 'subsample': 0.5008021123851977, 'colsample_bytree': 0.9568077987463945, 'min_child_weight': 18, 'gamma': 3.873147430650413e-08, 'reg_alpha': 0.27208402493696243, 'reg_lambda': 0.006748786929496429}\n",
      "Best RMSE: 0.3115224689889944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "\n",
    "def objective(trial: Trial):\n",
    "    params = {\n",
    "        # ranges inspired by the articles found on the Internet\n",
    "        \"tree_method\": trial.suggest_categorical(\"tree_method\", [\"approx\", \"hist\"]),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 250),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.001, 25, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.001, 25, log=True),\n",
    "        \"seed\": RANDOM_STATE,\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"eval_metric\": \"rmse\",\n",
    "        \"nthread\": -1,\n",
    "    }\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_final):\n",
    "        X_train_fold = X_final[train_idx]\n",
    "        y_train_fold = y[train_idx]\n",
    "\n",
    "        X_val_fold = X_final[val_idx]\n",
    "        y_val_fold = y[val_idx]\n",
    "\n",
    "        dtrain = xgb.DMatrix(X_train_fold, label=y_train_fold)\n",
    "        dval = xgb.DMatrix(X_val_fold, label=y_val_fold)\n",
    "\n",
    "        model = xgb.train(\n",
    "            params,\n",
    "            dtrain,\n",
    "            evals=[(dval, \"validation\")],\n",
    "            verbose_eval=False,\n",
    "        )\n",
    "\n",
    "        val_pred = model.predict(dval)\n",
    "        fold_rmse = root_mean_squared_error(y_val_fold, val_pred)\n",
    "        scores.append(fold_rmse)\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "study = create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=True)\n",
    "\n",
    "print(\"Best parameters:\", study.best_params)\n",
    "print(\"Best RMSE:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's try a totally different approach, i.e. AutoML methods.\n",
    "\n",
    "There was recently published a new 2.0 version of the TabPFN framework, which looks very promising and I'd like to try it out in this project :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tabpfn\n",
      "  Downloading tabpfn-2.0.3-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting torch>=2.1 (from tabpfn)\n",
      "  Downloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: scikit-learn>=1 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from tabpfn) (1.6.1)\n",
      "Requirement already satisfied: typing_extensions in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from tabpfn) (4.12.2)\n",
      "Requirement already satisfied: scipy in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from tabpfn) (1.15.1)\n",
      "Requirement already satisfied: pandas in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from tabpfn) (2.2.3)\n",
      "Collecting einops (from tabpfn)\n",
      "  Using cached einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting huggingface-hub (from tabpfn)\n",
      "  Using cached huggingface_hub-0.27.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from scikit-learn>=1->tabpfn) (2.2.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from scikit-learn>=1->tabpfn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from scikit-learn>=1->tabpfn) (3.5.0)\n",
      "Collecting filelock (from torch>=2.1->tabpfn)\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting networkx (from torch>=2.1->tabpfn)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch>=2.1->tabpfn)\n",
      "  Using cached jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fsspec (from torch>=2.1->tabpfn)\n",
      "  Using cached fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.1->tabpfn)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.1->tabpfn)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.1->tabpfn)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.1->tabpfn)\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.1->tabpfn)\n",
      "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.1->tabpfn)\n",
      "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.1->tabpfn)\n",
      "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.1->tabpfn)\n",
      "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.1->tabpfn)\n",
      "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=2.1->tabpfn)\n",
      "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch>=2.1->tabpfn)\n",
      "  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.1->tabpfn)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.1.0 (from torch>=2.1->tabpfn)\n",
      "  Downloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting sympy==1.13.1 (from torch>=2.1->tabpfn)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=2.1->tabpfn)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from huggingface-hub->tabpfn) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from huggingface-hub->tabpfn) (6.0.2)\n",
      "Collecting requests (from huggingface-hub->tabpfn)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from huggingface-hub->tabpfn) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from pandas->tabpfn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from pandas->tabpfn) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from pandas->tabpfn) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->tabpfn) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from jinja2->torch>=2.1->tabpfn) (3.0.2)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->huggingface-hub->tabpfn)\n",
      "  Downloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->huggingface-hub->tabpfn)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->huggingface-hub->tabpfn)\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->huggingface-hub->tabpfn)\n",
      "  Using cached certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)\n",
      "Downloading tabpfn-2.0.3-py3-none-any.whl (104 kB)\n",
      "Downloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.5/906.5 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Downloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "Using cached huggingface_hub-0.27.1-py3-none-any.whl (450 kB)\n",
      "Using cached fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Installing collected packages: mpmath, urllib3, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, jinja2, idna, fsspec, filelock, einops, charset-normalizer, certifi, triton, requests, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, huggingface-hub, torch, tabpfn\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.24.3\n",
      "    Uninstalling nvidia-nccl-cu12-2.24.3:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.24.3\n",
      "Successfully installed certifi-2024.12.14 charset-normalizer-3.4.1 einops-0.8.0 filelock-3.16.1 fsspec-2024.12.0 huggingface-hub-0.27.1 idna-3.10 jinja2-3.1.5 mpmath-1.3.0 networkx-3.4.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 requests-2.32.3 sympy-1.13.1 tabpfn-2.0.3 torch-2.5.1 triton-3.1.0 urllib3-2.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tabpfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 13:20:51,757] A new study created in memory with name: no-name-e5a4a4c0-ad8c-4a04-a5d5-43646530b737\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "Best trial: 0. Best value: 0.304246: 100%|██████████| 1/1 [18:09<00:00, 1089.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-18 13:39:00,862] Trial 0 finished with value: 0.30424631376788913 and parameters: {}. Best is trial 0 with value: 0.30424631376788913.\n",
      "Best parameters: {}\n",
      "Best RMSE: 0.30424631376788913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tabpfn import TabPFNRegressor\n",
    "\n",
    "model_parameters[TabPFNRegressor] = lambda _: {\"device\": \"cpu\"}\n",
    "\n",
    "tabpfn_study = run_study(\n",
    "    TabPFNRegressor, X_final, y, kfold, n_trials=1, plot_opt_history=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I managed to get a really great result, better than any value I obtained from the classical models.\n",
    "\n",
    "I'd like to try one more framework, which from my experience can also give outstanding results - AutoGluon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting autogluon\n",
      "  Downloading autogluon-1.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting autogluon.core==1.2 (from autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading autogluon.core-1.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting autogluon.features==1.2 (from autogluon)\n",
      "  Downloading autogluon.features-1.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting autogluon.tabular==1.2 (from autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading autogluon.tabular-1.2-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting autogluon.multimodal==1.2 (from autogluon)\n",
      "  Downloading autogluon.multimodal-1.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting autogluon.timeseries==1.2 (from autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading autogluon.timeseries-1.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting numpy<2.1.4,>=1.25.0 (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading numpy-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: scipy<1.16,>=1.5.4 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (1.15.1)\n",
      "Collecting scikit-learn<1.5.3,>=1.4.0 (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: networkx<4,>=3.0 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (3.4.2)\n",
      "Requirement already satisfied: pandas<2.3.0,>=2.0.0 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2.2.3)\n",
      "Requirement already satisfied: tqdm<5,>=4.38 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (4.67.1)\n",
      "Requirement already satisfied: requests in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2.32.3)\n",
      "Requirement already satisfied: matplotlib<3.11,>=3.7.0 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (3.10.0)\n",
      "Collecting boto3<2,>=1.10 (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading boto3-1.36.2-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting autogluon.common==1.2 (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading autogluon.common-1.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting ray<2.40,>=2.10.0 (from ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading ray-2.39.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (17 kB)\n",
      "Collecting pyarrow>=15.0.0 (from autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading pyarrow-19.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting hyperopt<0.2.8,>=0.2.7 (from autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: Pillow<12,>=10.0.1 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from autogluon.multimodal==1.2->autogluon) (11.1.0)\n",
      "Requirement already satisfied: torch<2.6,>=2.2 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from autogluon.multimodal==1.2->autogluon) (2.5.1)\n",
      "Collecting lightning<2.6,>=2.2 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading lightning-2.5.0.post0-py3-none-any.whl.metadata (40 kB)\n",
      "Collecting transformers<5,>=4.38.0 (from transformers[sentencepiece]<5,>=4.38.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading transformers-4.48.0-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting accelerate<1.0,>=0.34.0 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading accelerate-0.34.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting jsonschema<4.22,>=4.18 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading jsonschema-4.21.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting evaluate<0.5.0,>=0.4.0 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting timm<1.0.7,>=0.9.5 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading timm-1.0.3-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting torchvision<0.21.0,>=0.16.0 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting scikit-image<0.25.0,>=0.19.1 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading scikit_image-0.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Collecting text-unidecode<1.4,>=1.3 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting torchmetrics<1.3.0,>=1.2.0 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading torchmetrics-1.2.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting omegaconf<2.3.0,>=2.1.1 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting pytorch-metric-learning<2.4,>=1.3.0 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading pytorch_metric_learning-2.3.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting nltk<3.9,>=3.4.5 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting defusedxml<0.7.2,>=0.7.1 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: jinja2<3.2,>=3.0.3 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from autogluon.multimodal==1.2->autogluon) (3.1.5)\n",
      "Collecting tensorboard<3,>=2.9 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting pytesseract<0.3.11,>=0.3.9 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading pytesseract-0.3.10-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting nvidia-ml-py3==7.352.0 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pdf2image<1.19,>=1.17.0 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting catboost<1.3,>=1.2 (from autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
      "Collecting numpy<2.1.4,>=1.25.0 (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting spacy<3.8 (from autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading spacy-3.7.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
      "Collecting lightgbm<4.6,>=4.0 (from autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading lightgbm-4.5.0-py3-none-manylinux_2_28_x86_64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: einops<0.9,>=0.7 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from autogluon.tabular[all]==1.2->autogluon) (0.8.0)\n",
      "Requirement already satisfied: xgboost<2.2,>=1.6 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from autogluon.tabular[all]==1.2->autogluon) (2.1.3)\n",
      "Collecting fastai<2.8,>=2.3.1 (from autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading fastai-2.7.18-py3-none-any.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: huggingface-hub[torch] in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from autogluon.tabular[all]==1.2->autogluon) (0.27.1)\n",
      "Requirement already satisfied: joblib<2,>=1.1 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (1.4.2)\n",
      "Collecting pytorch-lightning (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading pytorch_lightning-2.5.0.post0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting gluonts<0.17,>=0.15.0 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading gluonts-0.16.0-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting statsforecast<1.8,>=1.7.0 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading statsforecast-1.7.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (28 kB)\n",
      "Collecting mlforecast==0.13.4 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading mlforecast-0.13.4-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting utilsforecast<0.2.5,>=0.2.3 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading utilsforecast-0.2.4-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting coreforecast==0.0.12 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading coreforecast-0.0.12-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting fugue>=0.9.0 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading fugue-0.9.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting orjson~=3.9 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading orjson-3.10.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: psutil<7.0.0,>=5.7.3 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from autogluon.common==1.2->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (6.1.1)\n",
      "Collecting cloudpickle (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: fsspec in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (2024.12.0)\n",
      "Collecting numba (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading numba-0.60.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: optuna in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (4.1.0)\n",
      "Requirement already satisfied: packaging in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (24.2)\n",
      "Collecting window-ops (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading window_ops-0.0.15-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: pyyaml in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from accelerate<1.0,>=0.34.0->autogluon.multimodal==1.2->autogluon) (6.0.2)\n",
      "Collecting safetensors>=0.4.3 (from accelerate<1.0,>=0.34.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting botocore<1.37.0,>=1.36.2 (from boto3<2,>=1.10->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading botocore-1.36.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3<2,>=1.10->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading s3transfer-0.11.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting graphviz (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: plotly in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.2->autogluon) (5.24.1)\n",
      "Requirement already satisfied: six in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.2->autogluon) (1.17.0)\n",
      "Collecting datasets>=2.0.0 (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting dill (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting xxhash (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading multiprocess-0.70.17-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: pip in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.2->autogluon) (24.2)\n",
      "Collecting fastdownload<2,>=0.0.5 (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading fastdownload-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting fastcore<1.8,>=1.5.29 (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading fastcore-1.7.28-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting fastprogress>=0.2.4 (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading fastprogress-1.0.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting triad>=0.9.7 (from fugue>=0.9.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading triad-0.9.8-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting adagio>=0.2.4 (from fugue>=0.9.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading adagio-0.2.6-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting pydantic<3,>=1.7 (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading pydantic-2.10.5-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting toolz~=0.10 (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (4.12.2)\n",
      "Collecting future (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting py4j (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading py4j-0.10.9.9-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.2->autogluon) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.2->autogluon) (24.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.2->autogluon) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.2->autogluon) (0.36.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.2->autogluon) (0.22.3)\n",
      "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning<2.6,>=2.2->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2.9.0.post0)\n",
      "Collecting gdown>=4.0.0 (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting click (from nltk<3.9,>=3.4.5->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk<3.9,>=3.4.5->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<2.3.0,>=2.1.1->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting colorama (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting rich (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting tabulate (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2024.2)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (3.16.1)\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Collecting protobuf!=3.19.5,>=3.15.3 (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Using cached protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting aiosignal (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting frozenlist (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting aiohttp>=3.7 (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading aiohttp-3.11.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting aiohttp-cors (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting colorful (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting py-spy>=0.2.0 (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (16 kB)\n",
      "Collecting opencensus (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting prometheus-client>=0.7.1 (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading prometheus_client-0.21.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting smart-open (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading virtualenv-20.29.1-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting grpcio>=1.42.0 (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading grpcio-1.69.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting memray (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading memray-1.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting tensorboardX>=1.9 (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from requests->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from requests->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from requests->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from requests->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2024.12.14)\n",
      "Collecting imageio>=2.33 (from scikit-image<0.25.0,>=0.19.1->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached imageio-2.36.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image<0.25.0,>=0.19.1->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading tifffile-2025.1.10-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image<0.25.0,>=0.19.1->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from scikit-learn<1.5.3,>=1.4.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (3.5.0)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading murmurhash-1.0.12-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading cymem-2.0.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.5 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading preshed-3.0.9-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.3.0,>=8.2.2 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading thinc-8.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading srsly-2.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading typer-0.15.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (75.1.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting statsmodels>=0.13.2 (from statsforecast<1.8,>=1.7.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading statsmodels-0.14.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting absl-py>=0.4 (from tensorboard<3,>=2.9->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<3,>=2.9->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<3,>=2.9->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<3,>=2.9->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from sympy==1.13.1->torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon) (1.3.0)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5,>=4.38.0->transformers[sentencepiece]<5,>=4.38.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece]<5,>=4.38.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading propcache-0.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
      "Collecting dill (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting multiprocess (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting beautifulsoup4 (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading llvmlite-0.43.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting patsy>=0.5.6 (from statsmodels>=0.13.2->statsforecast<1.8,>=1.7.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Using cached patsy-1.0.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading blis-0.7.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.2.2->spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting fs (from triad>=0.9.7->fugue>=0.9.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading fs-2.4.16-py2.py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (2.19.1)\n",
      "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (4.3.6)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading cloudpathlib-0.20.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting wrapt (from smart-open->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting textual>=0.41.0 (from memray->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading textual-1.0.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting ordered-set (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-api-core<3.0.0,>=1.0.0 (from opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading google_api_core-2.24.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting pycryptodome (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading openxlab-0.1.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from optuna->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (1.14.0)\n",
      "Requirement already satisfied: colorlog in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from optuna->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (6.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from optuna->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (2.0.37)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from plotly->catboost<1.3,>=1.2->autogluon.tabular[all]==1.2->autogluon) (9.0.0)\n",
      "Requirement already satisfied: Mako in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from alembic>=1.5.0->optuna->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (1.3.8)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading proto_plus-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth<3.0.dev0,>=2.14.1 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading google_auth-2.37.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading marisa_trie-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages (from sqlalchemy>=1.4.2->optuna->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (3.1.1)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting appdirs~=1.4.3 (from fs->triad>=0.9.7->fugue>=0.9.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting filelock (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading oss2-2.17.0.tar.gz (259 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pytz>=2020.1 (from pandas<2.3.0,>=2.0.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading pytz-2023.4-py2.py3-none-any.whl.metadata (22 kB)\n",
      "INFO: pip is looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading openxlab-0.1.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.38-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.37-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.36-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.35-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.34-py3-none-any.whl.metadata (3.8 kB)\n",
      "INFO: pip is still looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading openxlab-0.0.33-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.32-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.31-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.30-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.29-py3-none-any.whl.metadata (3.8 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading openxlab-0.0.28-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.27-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.26-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.25-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.24-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.23-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.22-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.21-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.20-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.19-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.18-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.17-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.16-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.15-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.14-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.13-py3-none-any.whl.metadata (4.5 kB)\n",
      "  Downloading openxlab-0.0.12-py3-none-any.whl.metadata (4.5 kB)\n",
      "  Downloading openxlab-0.0.11-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.2->autogluon)\n",
      "  Using cached PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting linkify-it-py<3,>=1 (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading linkify_it_py-2.0.3-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting mdit-py-plugins (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading mdit_py_plugins-0.4.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting uc-micro-py (from linkify-it-py<3,>=1->markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading uc_micro_py-1.0.3-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Downloading autogluon-1.2-py3-none-any.whl (9.6 kB)\n",
      "Downloading autogluon.core-1.2-py3-none-any.whl (266 kB)\n",
      "Downloading autogluon.features-1.2-py3-none-any.whl (64 kB)\n",
      "Downloading autogluon.multimodal-1.2-py3-none-any.whl (429 kB)\n",
      "Downloading autogluon.tabular-1.2-py3-none-any.whl (352 kB)\n",
      "Downloading autogluon.timeseries-1.2-py3-none-any.whl (174 kB)\n",
      "Downloading autogluon.common-1.2-py3-none-any.whl (68 kB)\n",
      "Downloading coreforecast-0.0.12-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (196 kB)\n",
      "Downloading mlforecast-0.13.4-py3-none-any.whl (70 kB)\n",
      "Downloading accelerate-0.34.2-py3-none-any.whl (324 kB)\n",
      "Downloading boto3-1.36.2-py3-none-any.whl (139 kB)\n",
      "Downloading catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl (98.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "Downloading fastai-2.7.18-py3-none-any.whl (234 kB)\n",
      "Downloading fugue-0.9.1-py3-none-any.whl (278 kB)\n",
      "Downloading gluonts-0.16.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonschema-4.21.1-py3-none-any.whl (85 kB)\n",
      "Downloading lightgbm-4.5.0-py3-none-manylinux_2_28_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lightning-2.5.0.post0-py3-none-any.whl (815 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
      "Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n",
      "Downloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
      "Downloading orjson-3.10.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Downloading pyarrow-19.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (42.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
      "Downloading pytorch_metric_learning-2.3.0-py3-none-any.whl (115 kB)\n",
      "Downloading ray-2.39.0-cp311-cp311-manylinux2014_x86_64.whl (66.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_image-0.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading spacy-3.7.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading statsforecast-1.7.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (315 kB)\n",
      "Using cached tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Downloading timm-1.0.3-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchmetrics-1.2.1-py3-none-any.whl (806 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.48.0-py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading utilsforecast-0.2.4-py3-none-any.whl (40 kB)\n",
      "Downloading pytorch_lightning-2.5.0.post0-py3-none-any.whl (819 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.3/819.3 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading adagio-0.2.6-py3-none-any.whl (19 kB)\n",
      "Downloading aiohttp-3.11.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading botocore-1.36.2-py3-none-any.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Downloading cymem-2.0.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (218 kB)\n",
      "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fastcore-1.7.28-py3-none-any.whl (84 kB)\n",
      "Downloading fastdownload-0.0.7-py3-none-any.whl (12 kB)\n",
      "Downloading fastprogress-1.0.3-py3-none-any.whl (12 kB)\n",
      "Downloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (274 kB)\n",
      "Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Using cached gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Downloading grpcio-1.69.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached imageio-2.36.1-py3-none-any.whl (315 kB)\n",
      "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
      "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (403 kB)\n",
      "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Downloading murmurhash-1.0.12-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (134 kB)\n",
      "Downloading numba-0.60.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading preshed-3.0.9-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (157 kB)\n",
      "Downloading prometheus_client-0.21.1-py3-none-any.whl (54 kB)\n",
      "Using cached protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Downloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.10.5-py3-none-any.whl (431 kB)\n",
      "Downloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.7/792.7 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading s3transfer-0.11.1-py3-none-any.whl (84 kB)\n",
      "Downloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (461 kB)\n",
      "Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading statsmodels-0.14.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "Downloading thinc-8.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (920 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m920.2/920.2 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tifffile-2025.1.10-py3-none-any.whl (227 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "Downloading triad-0.9.8-py3-none-any.whl (62 kB)\n",
      "Downloading typer-0.15.1-py3-none-any.whl (44 kB)\n",
      "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading virtualenv-20.29.1-py3-none-any.whl (4.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading colorful-0.5.6-py2.py3-none-any.whl (201 kB)\n",
      "Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "Downloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
      "Downloading memray-1.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
      "Downloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
      "Downloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\n",
      "Downloading py4j-0.10.9.9-py2.py3-none-any.whl (203 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading window_ops-0.0.15-py3-none-any.whl (15 kB)\n",
      "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading blis-0.7.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cloudpathlib-0.20.0-py3-none-any.whl (52 kB)\n",
      "Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
      "Downloading google_api_core-2.24.0-py3-none-any.whl (158 kB)\n",
      "Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.43.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
      "Using cached patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n",
      "Downloading propcache-0.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (231 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading textual-1.0.0-py3-none-any.whl (660 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m660.5/660.5 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (344 kB)\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Downloading fs-2.4.16-py2.py3-none-any.whl (135 kB)\n",
      "Downloading openxlab-0.0.11-py3-none-any.whl (55 kB)\n",
      "Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
      "Downloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
      "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading google_auth-2.37.0-py2.py3-none-any.whl (209 kB)\n",
      "Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)\n",
      "Downloading marisa_trie-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading proto_plus-1.25.0-py3-none-any.whl (50 kB)\n",
      "Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Using cached soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Downloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading linkify_it_py-2.0.3-py3-none-any.whl (19 kB)\n",
      "Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading mdit_py_plugins-0.4.2-py3-none-any.whl (55 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading uc_micro_py-1.0.3-py3-none-any.whl (6.2 kB)\n",
      "Building wheels for collected packages: nvidia-ml-py3, antlr4-python3-runtime, seqeval\n",
      "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19173 sha256=39374bae9a85889e49a7dbb66493f447f3e8db3a6fb00914718ddff281a5c4b0\n",
      "  Stored in directory: /home/pawel/.cache/pip/wheels/47/50/9e/29dc79037d74c3c1bb4a8661fb608e8674b7e4260d6a3f8f51\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=9ba3712fe3e53b474c0ba03ba2fc8d0f3b39edcf2759f9d7707d21bb2f7903f4\n",
      "  Stored in directory: /home/pawel/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=cbd29e774a82caec46f1ecf7fec702b3c3afa0c906ca153e434227de26482829\n",
      "  Stored in directory: /home/pawel/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\n",
      "Successfully built nvidia-ml-py3 antlr4-python3-runtime seqeval\n",
      "Installing collected packages: text-unidecode, sentencepiece, py4j, py-spy, opencensus-context, nvidia-ml-py3, distlib, cymem, colorful, appdirs, antlr4-python3-runtime, xxhash, wrapt, werkzeug, wasabi, virtualenv, uc-micro-py, toolz, tensorboard-data-server, tabulate, spacy-loggers, spacy-legacy, soupsieve, shellingham, safetensors, regex, pytesseract, PySocks, pydantic-core, pycryptodome, pyasn1, pyarrow, protobuf, propcache, prometheus-client, pdf2image, orjson, ordered-set, openxlab, omegaconf, numpy, murmurhash, multidict, msgpack, mdurl, markdown, marisa-trie, llvmlite, lightning-utilities, lazy-loader, jmespath, grpcio, graphviz, future, fsspec, fs, frozenlist, fastprogress, fastcore, dill, defusedxml, colorama, cloudpickle, cloudpathlib, click, catalogue, cachetools, annotated-types, aiohappyeyeballs, absl-py, yarl, tifffile, tensorboardX, tensorboard, srsly, smart-open, rsa, pydantic, pyasn1-modules, proto-plus, preshed, patsy, numba, nltk, multiprocess, model-index, markdown-it-py, linkify-it-py, language-data, imageio, googleapis-common-protos, fastdownload, coreforecast, botocore, blis, beautifulsoup4, aiosignal, window-ops, utilsforecast, triad, tokenizers, statsmodels, scikit-learn, scikit-image, s3transfer, rich, mdit-py-plugins, lightgbm, langcodes, jsonschema, hyperopt, google-auth, gluonts, gdown, confection, aiohttp, typer, transformers, torchvision, torchmetrics, thinc, seqeval, ray, pytorch-metric-learning, opendatalab, nlpaug, mlforecast, google-api-core, catboost, boto3, aiohttp-cors, adagio, accelerate, weasel, timm, textual, pytorch-lightning, openmim, opencensus, fugue, datasets, autogluon.common, statsforecast, spacy, memray, lightning, evaluate, autogluon.features, autogluon.core, fastai, autogluon.tabular, autogluon.timeseries, autogluon.multimodal, autogluon\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.1\n",
      "    Uninstalling numpy-2.2.1:\n",
      "      Successfully uninstalled numpy-2.2.1\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.12.0\n",
      "    Uninstalling fsspec-2024.12.0:\n",
      "      Successfully uninstalled fsspec-2024.12.0\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.6.1\n",
      "    Uninstalling scikit-learn-1.6.1:\n",
      "      Successfully uninstalled scikit-learn-1.6.1\n",
      "  Attempting uninstall: jsonschema\n",
      "    Found existing installation: jsonschema 4.23.0\n",
      "    Uninstalling jsonschema-4.23.0:\n",
      "      Successfully uninstalled jsonschema-4.23.0\n",
      "Successfully installed PySocks-1.7.1 absl-py-2.1.0 accelerate-0.34.2 adagio-0.2.6 aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiohttp-cors-0.7.0 aiosignal-1.3.2 annotated-types-0.7.0 antlr4-python3-runtime-4.9.3 appdirs-1.4.4 autogluon-1.2 autogluon.common-1.2 autogluon.core-1.2 autogluon.features-1.2 autogluon.multimodal-1.2 autogluon.tabular-1.2 autogluon.timeseries-1.2 beautifulsoup4-4.12.3 blis-0.7.11 boto3-1.36.2 botocore-1.36.2 cachetools-5.5.0 catalogue-2.0.10 catboost-1.2.7 click-8.1.8 cloudpathlib-0.20.0 cloudpickle-3.1.1 colorama-0.4.6 colorful-0.5.6 confection-0.1.5 coreforecast-0.0.12 cymem-2.0.11 datasets-3.2.0 defusedxml-0.7.1 dill-0.3.8 distlib-0.3.9 evaluate-0.4.3 fastai-2.7.18 fastcore-1.7.28 fastdownload-0.0.7 fastprogress-1.0.3 frozenlist-1.5.0 fs-2.4.16 fsspec-2024.9.0 fugue-0.9.1 future-1.0.0 gdown-5.2.0 gluonts-0.16.0 google-api-core-2.24.0 google-auth-2.37.0 googleapis-common-protos-1.66.0 graphviz-0.20.3 grpcio-1.69.0 hyperopt-0.2.7 imageio-2.36.1 jmespath-1.0.1 jsonschema-4.21.1 langcodes-3.5.0 language-data-1.3.0 lazy-loader-0.4 lightgbm-4.5.0 lightning-2.5.0.post0 lightning-utilities-0.11.9 linkify-it-py-2.0.3 llvmlite-0.43.0 marisa-trie-1.2.1 markdown-3.7 markdown-it-py-3.0.0 mdit-py-plugins-0.4.2 mdurl-0.1.2 memray-1.15.0 mlforecast-0.13.4 model-index-0.1.11 msgpack-1.1.0 multidict-6.1.0 multiprocess-0.70.16 murmurhash-1.0.12 nlpaug-1.1.11 nltk-3.8.1 numba-0.60.0 numpy-1.26.4 nvidia-ml-py3-7.352.0 omegaconf-2.2.3 opencensus-0.11.4 opencensus-context-0.1.3 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.11 ordered-set-4.1.0 orjson-3.10.14 patsy-1.0.1 pdf2image-1.17.0 preshed-3.0.9 prometheus-client-0.21.1 propcache-0.2.1 proto-plus-1.25.0 protobuf-5.29.3 py-spy-0.4.0 py4j-0.10.9.9 pyarrow-19.0.0 pyasn1-0.6.1 pyasn1-modules-0.4.1 pycryptodome-3.21.0 pydantic-2.10.5 pydantic-core-2.27.2 pytesseract-0.3.10 pytorch-lightning-2.5.0.post0 pytorch-metric-learning-2.3.0 ray-2.39.0 regex-2024.11.6 rich-13.9.4 rsa-4.9 s3transfer-0.11.1 safetensors-0.5.2 scikit-image-0.24.0 scikit-learn-1.5.2 sentencepiece-0.2.0 seqeval-1.2.2 shellingham-1.5.4 smart-open-7.1.0 soupsieve-2.6 spacy-3.7.5 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 statsforecast-1.7.8 statsmodels-0.14.4 tabulate-0.9.0 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorboardX-2.6.2.2 text-unidecode-1.3 textual-1.0.0 thinc-8.2.5 tifffile-2025.1.10 timm-1.0.3 tokenizers-0.21.0 toolz-0.12.1 torchmetrics-1.2.1 torchvision-0.20.1 transformers-4.48.0 triad-0.9.8 typer-0.15.1 uc-micro-py-1.0.3 utilsforecast-0.2.4 virtualenv-20.29.1 wasabi-1.1.3 weasel-0.4.1 werkzeug-3.1.3 window-ops-0.0.15 wrapt-1.17.2 xxhash-3.5.0 yarl-1.18.3\n"
     ]
    }
   ],
   "source": [
    "!pip install autogluon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some problems with the recent versions of sklearn, on which depends API of AutoGluon models. The solution that worked for me was downgrading version of sklearn, and then upgrading version of numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y scikit-learn\n",
    "!pip install scikit-learn==1.5.2\n",
    "!pip install numpy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250118_141030\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP PREEMPT_DYNAMIC Fri, 10 Jan 2025 00:39:41 +0000\n",
      "CPU Count:          12\n",
      "Memory Avail:       10.23 GB / 31.29 GB (32.7%)\n",
      "Disk Space Avail:   235.17 GB / 456.39 GB (51.5%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "\t\tContext path: \"/home/pawel/repos/university/sml/hw2/AutogluonModels/ag-20250118_141030/ds_sub_fit/sub_fit_ho\"\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                          model  score_holdout  score_val              eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0   NeuralNetFastAI_r145_BAG_L2      -0.325500  -0.311793  root_mean_squared_error        1.067434       1.696038   92.271441                 0.085047                0.106487           8.716729            2       True         60\n",
      "1        NeuralNetFastAI_BAG_L2      -0.327388  -0.313593  root_mean_squared_error        1.045180       1.662607   88.216502                 0.062792                0.073057           4.661789            2       True         46\n",
      "2    NeuralNetFastAI_r95_BAG_L1      -0.327666  -0.324718  root_mean_squared_error        0.087360       0.103050    9.349756                 0.087360                0.103050           9.349756            1       True         36\n",
      "3    NeuralNetFastAI_r11_BAG_L1      -0.328922  -0.308910  root_mean_squared_error        0.088990       0.142145   14.213099                 0.088990                0.142145          14.213099            1       True         26\n",
      "4   NeuralNetFastAI_r103_BAG_L2      -0.329053  -0.315671  root_mean_squared_error        1.044943       1.660214   89.905957                 0.062555                0.070663           6.351245            2       True         68\n",
      "5           WeightedEnsemble_L2      -0.329260  -0.295388  root_mean_squared_error        0.499549       0.689928   69.878594                 0.001853                0.000240           0.013808            2       True         41\n",
      "6           WeightedEnsemble_L3      -0.329671  -0.298487  root_mean_squared_error        1.436442       2.172996  126.230663                 0.002790                0.000235           0.014148            3       True         75\n",
      "7    NeuralNetFastAI_r11_BAG_L2      -0.329873  -0.306598  root_mean_squared_error        1.071658       1.720022   97.436439                 0.089270                0.130471          13.881727            2       True         65\n",
      "8          LightGBM_r130_BAG_L2      -0.329966  -0.304782  root_mean_squared_error        1.008532       1.620434   85.405132                 0.026145                0.030884           1.850419            2       True         63\n",
      "9             LightGBMXT_BAG_L2      -0.330156  -0.302976  root_mean_squared_error        1.048690       1.612699   85.236760                 0.066302                0.023149           1.682047            2       True         42\n",
      "10          LightGBM_r96_BAG_L2      -0.330290  -0.301637  root_mean_squared_error        1.008869       1.641548   84.574735                 0.026481                0.051997           1.020022            2       True         53\n",
      "11         LightGBM_r188_BAG_L2      -0.330513  -0.306161  root_mean_squared_error        1.019203       1.635525   87.303802                 0.036815                0.045974           3.749089            2       True         59\n",
      "12         LightGBM_r196_BAG_L2      -0.330876  -0.304673  root_mean_squared_error        1.251710       1.856741   90.221270                 0.269323                0.267190           6.666557            2       True         73\n",
      "13  NeuralNetFastAI_r191_BAG_L2      -0.330897  -0.318436  root_mean_squared_error        1.051223       1.693181   95.283315                 0.068835                0.103630          11.728602            2       True         52\n",
      "14       ExtraTrees_r172_BAG_L2      -0.331251  -0.300491  root_mean_squared_error        1.026321       1.705479   84.217310                 0.043934                0.115928           0.662598            2       True         67\n",
      "15         LightGBM_r161_BAG_L2      -0.331334  -0.307744  root_mean_squared_error        1.151935       1.785897   95.300825                 0.169547                0.196346          11.746113            2       True         70\n",
      "16         LightGBM_r131_BAG_L2      -0.331902  -0.307361  root_mean_squared_error        1.035998       1.673019   88.403732                 0.053611                0.083468           4.849019            2       True         51\n",
      "17        ExtraTrees_r42_BAG_L2      -0.332105  -0.303007  root_mean_squared_error        1.057278       1.728897   84.252413                 0.074891                0.139346           0.697701            2       True         56\n",
      "18  NeuralNetFastAI_r145_BAG_L1      -0.332192  -0.315854  root_mean_squared_error        0.087629       0.108191    9.194399                 0.087629                0.108191           9.194399            1       True         21\n",
      "19    NeuralNetTorch_r30_BAG_L1      -0.332234  -0.312370  root_mean_squared_error        0.061907       0.068103   30.625528                 0.061907                0.068103          30.625528            1       True         23\n",
      "20      RandomForest_r39_BAG_L2      -0.332548  -0.303880  root_mean_squared_error        1.030901       1.715631   86.980634                 0.048514                0.126080           3.425921            2       True         74\n",
      "21  NeuralNetFastAI_r143_BAG_L2      -0.332734  -0.303725  root_mean_squared_error        1.032715       1.651410   87.224777                 0.050328                0.061859           3.670064            2       True         71\n",
      "22    NeuralNetTorch_r79_BAG_L2      -0.332787  -0.310337  root_mean_squared_error        1.040928       1.643888   91.265988                 0.058540                0.054338           7.711275            2       True         50\n",
      "23         LightGBMLarge_BAG_L2      -0.332811  -0.315166  root_mean_squared_error        1.030990       1.639268   93.080960                 0.048603                0.049717           9.526247            2       True         49\n",
      "24     RandomForest_r195_BAG_L2      -0.332964  -0.305240  root_mean_squared_error        1.055692       1.718272   87.148126                 0.073305                0.128722           3.593414            2       True         58\n",
      "25           XGBoost_r89_BAG_L2      -0.333242  -0.308287  root_mean_squared_error        1.026140       1.618294   86.194509                 0.043752                0.028744           2.639796            2       True         61\n",
      "26              LightGBM_BAG_L2      -0.333465  -0.307269  root_mean_squared_error        0.994729       1.610344   86.097053                 0.012341                0.020794           2.542340            2       True         43\n",
      "27         ExtraTreesMSE_BAG_L2      -0.333972  -0.302292  root_mean_squared_error        1.060028       1.722291   84.306693                 0.077641                0.132740           0.751980            2       True         45\n",
      "28    NeuralNetTorch_r86_BAG_L2      -0.334596  -0.315562  root_mean_squared_error        1.032473       1.655332   91.173949                 0.050085                0.065781           7.619236            2       True         64\n",
      "29       RandomForestMSE_BAG_L2      -0.334634  -0.306190  root_mean_squared_error        1.048873       1.719194   88.189020                 0.066486                0.129644           4.634308            2       True         44\n",
      "30               XGBoost_BAG_L2      -0.335221  -0.311468  root_mean_squared_error        1.035392       1.618550   88.893734                 0.053004                0.028999           5.339022            2       True         47\n",
      "31          XGBoost_r194_BAG_L2      -0.335229  -0.314987  root_mean_squared_error        1.067640       1.675803   93.074953                 0.085253                0.086253           9.520240            2       True         66\n",
      "32    NeuralNetTorch_r79_BAG_L1      -0.335395  -0.314772  root_mean_squared_error        0.055942       0.053753   20.828249                 0.055942                0.053753          20.828249            1       True         11\n",
      "33           XGBoost_r33_BAG_L2      -0.336464  -0.311208  root_mean_squared_error        1.140590       1.799665  141.975614                 0.158203                0.210115          58.420902            2       True         55\n",
      "34    NeuralNetTorch_r41_BAG_L1      -0.336640  -0.310498  root_mean_squared_error        0.055237       0.050906   13.156539                 0.055237                0.050906          13.156539            1       True         37\n",
      "35    NeuralNetTorch_r30_BAG_L2      -0.336820  -0.310342  root_mean_squared_error        1.047637       1.654275   97.856825                 0.065249                0.064725          14.302112            2       True         62\n",
      "36        NeuralNetTorch_BAG_L2      -0.337052  -0.318405  root_mean_squared_error        1.028814       1.642544   92.871754                 0.046427                0.052993           9.317041            2       True         48\n",
      "37    NeuralNetTorch_r14_BAG_L2      -0.337562  -0.318697  root_mean_squared_error        1.022895       1.637235   89.165123                 0.040508                0.047684           5.610410            2       True         69\n",
      "38  NeuralNetFastAI_r103_BAG_L1      -0.338071  -0.320934  root_mean_squared_error        0.077072       0.073601    7.651313                 0.077072                0.073601           7.651313            1       True         29\n",
      "39    NeuralNetTorch_r86_BAG_L1      -0.338154  -0.319447  root_mean_squared_error        0.048167       0.053389   10.077398                 0.048167                0.053389          10.077398            1       True         25\n",
      "40       NeuralNetFastAI_BAG_L1      -0.338560  -0.321618  root_mean_squared_error        1.296864       0.063448    4.845515                 1.296864                0.063448           4.845515            1       True          7\n",
      "41    NeuralNetTorch_r22_BAG_L1      -0.339417  -0.317502  root_mean_squared_error        0.049411       0.071756   18.216491                 0.049411                0.071756          18.216491            1       True         15\n",
      "42    NeuralNetTorch_r22_BAG_L2      -0.339887  -0.314499  root_mean_squared_error        1.034398       1.656212   92.317749                 0.052011                0.066661           8.763036            2       True         54\n",
      "43  NeuralNetFastAI_r156_BAG_L2      -0.340460  -0.325842  root_mean_squared_error        1.026370       1.650017   87.594292                 0.043982                0.060467           4.039579            2       True         72\n",
      "44  NeuralNetFastAI_r143_BAG_L1      -0.340536  -0.314444  root_mean_squared_error        0.048742       0.054631    3.822361                 0.048742                0.054631           3.822361            1       True         32\n",
      "45  NeuralNetFastAI_r102_BAG_L1      -0.340940  -0.329690  root_mean_squared_error        0.044112       0.054873    3.405282                 0.044112                0.054873           3.405282            1       True         18\n",
      "46       ExtraTrees_r172_BAG_L1      -0.341153  -0.306514  root_mean_squared_error        0.051637       0.113852    0.566836                 0.051637                0.113852           0.566836            1       True         28\n",
      "47            LightGBMXT_BAG_L1      -0.342172  -0.313020  root_mean_squared_error        0.096764       0.043222    1.527094                 0.096764                0.043222           1.527094            1       True          3\n",
      "48        ExtraTrees_r42_BAG_L1      -0.342634  -0.306545  root_mean_squared_error        0.082332       0.129123    0.684031                 0.082332                0.129123           0.684031            1       True         17\n",
      "49   NeuralNetTorch_r158_BAG_L1      -0.343278  -0.318414  root_mean_squared_error        0.061548       0.052719   17.315869                 0.061548                0.052719          17.315869            1       True         40\n",
      "50         ExtraTreesMSE_BAG_L1      -0.343383  -0.306739  root_mean_squared_error        0.059625       0.134219    0.677452                 0.059625                0.134219           0.677452            1       True          6\n",
      "51        NeuralNetTorch_BAG_L1      -0.343506  -0.321844  root_mean_squared_error        0.050141       0.049520   20.932987                 0.050141                0.049520          20.932987            1       True          9\n",
      "52  NeuralNetFastAI_r191_BAG_L1      -0.344269  -0.325847  root_mean_squared_error        0.074818       0.095666   12.882157                 0.074818                0.095666          12.882157            1       True         13\n",
      "53      RandomForest_r39_BAG_L1      -0.345687  -0.310738  root_mean_squared_error        0.054688       0.121138    2.696987                 0.054688                0.121138           2.696987            1       True         35\n",
      "54     RandomForest_r195_BAG_L1      -0.345743  -0.310876  root_mean_squared_error        0.055694       0.130731    3.006132                 0.055694                0.130731           3.006132            1       True         19\n",
      "55          LightGBM_r96_BAG_L1      -0.347132  -0.313800  root_mean_squared_error        0.141971       0.402561    3.485118                 0.141971                0.402561           3.485118            1       True         14\n",
      "56         LightGBM_r188_BAG_L1      -0.347291  -0.317375  root_mean_squared_error        0.064745       0.090837    4.363169                 0.064745                0.090837           4.363169            1       True         20\n",
      "57           XGBoost_r89_BAG_L1      -0.347321  -0.317328  root_mean_squared_error        0.044431       0.027926    2.147793                 0.044431                0.027926           2.147793            1       True         22\n",
      "58          XGBoost_r194_BAG_L1      -0.347992  -0.320771  root_mean_squared_error        0.101900       0.054827    7.612620                 0.101900                0.054827           7.612620            1       True         27\n",
      "59         LightGBM_r131_BAG_L1      -0.348633  -0.315091  root_mean_squared_error        0.116602       0.140227    5.088720                 0.116602                0.140227           5.088720            1       True         12\n",
      "60          LightGBM_r15_BAG_L1      -0.349077  -0.316168  root_mean_squared_error        0.126890       0.073128    2.196461                 0.126890                0.073128           2.196461            1       True         39\n",
      "61         LightGBMLarge_BAG_L1      -0.350020  -0.323663  root_mean_squared_error        0.102743       0.092551   13.440708                 0.102743                0.092551          13.440708            1       True         10\n",
      "62              LightGBM_BAG_L1      -0.350449  -0.317430  root_mean_squared_error        0.011739       0.022214    1.960125                 0.011739                0.022214           1.960125            1       True          4\n",
      "63        KNeighborsUnif_BAG_L1      -0.350898  -0.329237  root_mean_squared_error        0.091437       0.227353    0.005559                 0.091437                0.227353           0.005559            1       True          1\n",
      "64        KNeighborsDist_BAG_L1      -0.350929  -0.328647  root_mean_squared_error        0.006660       0.023032    0.005015                 0.006660                0.023032           0.005015            1       True          2\n",
      "65           XGBoost_r33_BAG_L1      -0.350937  -0.320941  root_mean_squared_error        0.202374       0.453792   50.753330                 0.202374                0.453792          50.753330            1       True         16\n",
      "66         LightGBM_r161_BAG_L1      -0.351445  -0.317233  root_mean_squared_error        1.061913       3.066743   98.063084                 1.061913                3.066743          98.063084            1       True         31\n",
      "67         LightGBM_r130_BAG_L1      -0.351525  -0.316829  root_mean_squared_error        0.025771       0.049967    1.711475                 0.025771                0.049967           1.711475            1       True         24\n",
      "68    NeuralNetTorch_r14_BAG_L1      -0.352210  -0.327761  root_mean_squared_error        0.042877       0.046006    6.722159                 0.042877                0.046006           6.722159            1       True         30\n",
      "69         LightGBM_r196_BAG_L1      -0.352899  -0.321786  root_mean_squared_error        0.787688       2.431150   25.623285                 0.787688                2.431150          25.623285            1       True         34\n",
      "70       RandomForestMSE_BAG_L1      -0.354422  -0.319147  root_mean_squared_error        0.098116       0.140968    4.059011                 0.098116                0.140968           4.059011            1       True          5\n",
      "71               XGBoost_BAG_L1      -0.355253  -0.322542  root_mean_squared_error        0.080554       0.040040    6.987010                 0.080554                0.040040           6.987010            1       True          8\n",
      "72           XGBoost_r98_BAG_L1      -0.355774  -0.321918  root_mean_squared_error        0.420845       0.517721   87.691595                 0.420845                0.517721          87.691595            1       True         38\n",
      "73  NeuralNetFastAI_r102_BAG_L2      -0.358690  -0.345531  root_mean_squared_error        1.027839       1.646854   86.799792                 0.045452                0.057303           3.245079            2       True         57\n",
      "74  NeuralNetFastAI_r156_BAG_L1      -0.364718  -0.341480  root_mean_squared_error        0.039820       0.056451    4.057051                 0.039820                0.056451           4.057051            1       True         33\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t901s\t = DyStack   runtime |\t2699s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 2699s\n",
      "AutoGluon will save models to \"/home/pawel/repos/university/sml/hw2/AutogluonModels/ag-20250118_141030\"\n",
      "Train Data Rows:    3794\n",
      "Train Data Columns: 38\n",
      "Label Column:       target\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9685.26 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.10 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 38 | ['0', '1', '2', '3', '4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 38 | ['0', '1', '2', '3', '4', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t38 features in original data used to generate 38 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.10 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 1798.84s of the 2698.93s of remaining time.\n",
      "\t-0.3302\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 1798.78s of the 2698.87s of remaining time.\n",
      "\t-0.3297\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1798.73s of the 2698.82s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.14%)\n",
      "\t-0.3158\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.11s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1795.23s of the 2695.32s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.14%)\n",
      "\t-0.3165\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.23s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 1792.02s of the 2692.10s of remaining time.\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning:\n",
      "\n",
      "`BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\n",
      "\t-0.3202\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.52s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1787.28s of the 2687.36s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.21%)\n",
      "\tWarning: Exception caused CatBoost_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=466708, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=466708, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 1786.08s of the 2686.16s of remaining time.\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning:\n",
      "\n",
      "`BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\n",
      "\t-0.3097\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.64s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1785.22s of the 2685.31s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "2025-01-18 15:25:49,294\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:25:49,295\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:25:49,296\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:25:49,296\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:25:49,297\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:25:49,298\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:25:49,298\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.3216\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.01s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1779.14s of the 2679.23s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.32%)\n",
      "\t-0.3226\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.88s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1772.77s of the 2672.85s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\t-0.3246\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.02s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1760.81s of the 2660.90s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.40%)\n",
      "\t-0.3179\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.28s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 1751.35s of the 2651.44s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.21%)\n",
      "\tWarning: Exception caused CatBoost_r177_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=469050, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=469050, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 1750.03s of the 2650.12s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "2025-01-18 15:26:25,311\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:26:25,312\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:26:25,312\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:26:25,313\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:26:25,314\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:26:26,311\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:26:26,313\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.3164\t = Validation score   (-root_mean_squared_error)\n",
      "\t16.14s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 1732.81s of the 2632.90s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.19%)\n",
      "\t-0.3161\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.31s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 1725.15s of the 2625.24s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\t-0.3267\t = Validation score   (-root_mean_squared_error)\n",
      "\t13.21s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 1710.96s of the 2611.05s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.72%)\n",
      "\tWarning: Exception caused CatBoost_r9_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=470956, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=470956, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 1709.61s of the 2609.70s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.11%)\n",
      "\t-0.317\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.89s\t = Training   runtime\n",
      "\t0.46s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 1704.46s of the 2604.55s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "2025-01-18 15:27:06,327\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:27:06,328\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:27:06,329\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:27:06,330\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:27:06,331\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:27:06,331\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:27:06,333\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.3196\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.82s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 1688.54s of the 2588.63s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.23%)\n",
      "\t-0.3227\t = Validation score   (-root_mean_squared_error)\n",
      "\t50.22s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 1637.23s of the 2537.32s of remaining time.\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning:\n",
      "\n",
      "`BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\n",
      "\t-0.3117\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.56s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 1636.44s of the 2536.53s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\tWarning: Exception caused CatBoost_r137_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=472972, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=472972, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 1635.22s of the 2535.30s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
      "\t-0.3273\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.51s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 1630.76s of the 2530.84s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.88%)\n",
      "2025-01-18 15:28:20,381\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:28:20,382\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:28:20,383\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:28:20,383\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:28:20,384\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:28:20,384\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:28:20,386\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\tWarning: Exception caused CatBoost_r13_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=474152, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=474152, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: RandomForest_r195_BAG_L1 ... Training model for up to 1629.23s of the 2529.32s of remaining time.\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning:\n",
      "\n",
      "`BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\n",
      "\t-0.315\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.42s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 1625.59s of the 2525.68s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.35%)\n",
      "2025-01-18 15:28:26,384\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:28:26,385\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:28:26,386\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:28:26,386\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:28:26,387\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:28:26,387\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:28:26,388\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.3212\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.56s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 1619.80s of the 2519.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
      "\t-0.3162\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.47s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: XGBoost_r89_BAG_L1 ... Training model for up to 1609.32s of the 2509.40s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.26%)\n",
      "\t-0.3199\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.85s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 1605.30s of the 2505.39s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\t-0.3139\t = Validation score   (-root_mean_squared_error)\n",
      "\t24.78s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBM_r130_BAG_L1 ... Training model for up to 1579.56s of the 2479.64s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.27%)\n",
      "\t-0.3186\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.16s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r86_BAG_L1 ... Training model for up to 1576.37s of the 2476.46s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\t-0.3214\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.75s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost_r50_BAG_L1 ... Training model for up to 1566.33s of the 2466.41s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.11%)\n",
      "\tWarning: Exception caused CatBoost_r50_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=477588, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=477588, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: NeuralNetFastAI_r11_BAG_L1 ... Training model for up to 1564.93s of the 2465.02s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "2025-01-18 15:29:30,412\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:29:30,413\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:29:30,415\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:29:30,415\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:29:30,416\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:29:30,417\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:29:30,417\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.3129\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.71s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: XGBoost_r194_BAG_L1 ... Training model for up to 1549.06s of the 2449.15s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.41%)\n",
      "\t-0.3216\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.74s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r172_BAG_L1 ... Training model for up to 1540.97s of the 2441.05s of remaining time.\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning:\n",
      "\n",
      "`BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\n",
      "\t-0.31\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.53s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: CatBoost_r69_BAG_L1 ... Training model for up to 1540.27s of the 2440.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.14%)\n",
      "\tWarning: Exception caused CatBoost_r69_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=479113, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=479113, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: NeuralNetFastAI_r103_BAG_L1 ... Training model for up to 1539.16s of the 2439.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "2025-01-18 15:29:56,423\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:29:56,424\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:29:56,425\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:29:56,426\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:29:56,427\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:29:56,428\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:29:56,428\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.3229\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.54s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r14_BAG_L1 ... Training model for up to 1530.63s of the 2430.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "\t-0.3313\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.05s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_r161_BAG_L1 ... Training model for up to 1524.44s of the 2424.53s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.75%)\n",
      "\t-0.3188\t = Validation score   (-root_mean_squared_error)\n",
      "\t106.39s\t = Training   runtime\n",
      "\t3.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r143_BAG_L1 ... Training model for up to 1407.37s of the 2307.46s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
      "\t-0.3143\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.32s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_r70_BAG_L1 ... Training model for up to 1401.98s of the 2302.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.30%)\n",
      "\tWarning: Exception caused CatBoost_r70_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=482238, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=482238, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: NeuralNetFastAI_r156_BAG_L1 ... Training model for up to 1400.26s of the 2300.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\t-0.3451\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.21s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_r196_BAG_L1 ... Training model for up to 1395.08s of the 2295.17s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.51%)\n",
      "2025-01-18 15:32:15,470\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:32:15,471\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:32:15,473\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:32:15,474\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:32:15,475\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:32:15,475\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:32:15,476\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.325\t = Validation score   (-root_mean_squared_error)\n",
      "\t38.81s\t = Training   runtime\n",
      "\t3.31s\t = Validation runtime\n",
      "Fitting model: RandomForest_r39_BAG_L1 ... Training model for up to 1349.85s of the 2249.94s of remaining time.\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning:\n",
      "\n",
      "`BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\n",
      "\t-0.3145\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.05s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: CatBoost_r167_BAG_L1 ... Training model for up to 1346.62s of the 2246.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.35%)\n",
      "\tWarning: Exception caused CatBoost_r167_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=483663, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=483663, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: NeuralNetFastAI_r95_BAG_L1 ... Training model for up to 1345.26s of the 2245.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "2025-01-18 15:33:10,490\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:33:10,491\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:33:10,492\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:33:10,492\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:33:10,493\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:33:10,493\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:33:10,494\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.3253\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.5s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r41_BAG_L1 ... Training model for up to 1334.79s of the 2234.88s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\t-0.3156\t = Validation score   (-root_mean_squared_error)\n",
      "\t13.52s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: XGBoost_r98_BAG_L1 ... Training model for up to 1320.12s of the 2220.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.67%)\n",
      "\t-0.326\t = Validation score   (-root_mean_squared_error)\n",
      "\t61.75s\t = Training   runtime\n",
      "\t0.49s\t = Validation runtime\n",
      "Fitting model: LightGBM_r15_BAG_L1 ... Training model for up to 1257.15s of the 2157.24s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\t-0.3169\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.98s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r158_BAG_L1 ... Training model for up to 1253.09s of the 2153.17s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\t-0.3201\t = Validation score   (-root_mean_squared_error)\n",
      "\t17.07s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost_r86_BAG_L1 ... Training model for up to 1234.98s of the 2135.06s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.64%)\n",
      "\tWarning: Exception caused CatBoost_r86_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=487334, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=487334, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: NeuralNetFastAI_r37_BAG_L1 ... Training model for up to 1233.70s of the 2133.79s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
      "2025-01-18 15:35:02,558\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:35:02,560\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:35:02,561\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:35:02,561\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:35:02,563\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:35:02,564\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:35:02,565\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.3081\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.85s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r197_BAG_L1 ... Training model for up to 1225.85s of the 2125.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "\t-0.3422\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.91s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_r49_BAG_L1 ... Training model for up to 1217.82s of the 2117.91s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.11%)\n",
      "\tWarning: Exception caused CatBoost_r49_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=488914, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=488914, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: ExtraTrees_r49_BAG_L1 ... Training model for up to 1216.52s of the 2116.61s of remaining time.\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning:\n",
      "\n",
      "`BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\n",
      "\t-0.3243\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: LightGBM_r143_BAG_L1 ... Training model for up to 1215.89s of the 2115.97s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.47%)\n",
      "2025-01-18 15:35:19,565\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:35:19,566\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:35:19,567\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:35:19,567\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:35:19,568\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:35:19,568\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:35:19,569\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.3178\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.79s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: RandomForest_r127_BAG_L1 ... Training model for up to 1204.73s of the 2104.82s of remaining time.\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning:\n",
      "\n",
      "`BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\n",
      "\t-0.3203\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.49s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r134_BAG_L1 ... Training model for up to 1201.07s of the 2101.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\t-0.3206\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.21s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: RandomForest_r34_BAG_L1 ... Training model for up to 1190.78s of the 2090.86s of remaining time.\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning:\n",
      "\n",
      "`BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\n",
      "\t-0.3301\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.92s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: LightGBM_r94_BAG_L1 ... Training model for up to 1188.71s of the 2088.80s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\t-0.3218\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.98s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r143_BAG_L1 ... Training model for up to 1185.67s of the 2085.75s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\t-0.3148\t = Validation score   (-root_mean_squared_error)\n",
      "\t48.06s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost_r128_BAG_L1 ... Training model for up to 1136.70s of the 2036.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.63%)\n",
      "\tWarning: Exception caused CatBoost_r128_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=491363, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=491363, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: NeuralNetFastAI_r111_BAG_L1 ... Training model for up to 1135.49s of the 2035.58s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\t-0.3993\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.75s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r31_BAG_L1 ... Training model for up to 1130.65s of the 2030.74s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "2025-01-18 15:36:40,599\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:36:40,600\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:36:40,602\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:36:40,603\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:36:40,605\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:36:40,607\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:36:40,609\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.3192\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.71s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r4_BAG_L1 ... Training model for up to 1120.62s of the 2020.71s of remaining time.\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning:\n",
      "\n",
      "`BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\n",
      "\t-0.3195\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.49s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r65_BAG_L1 ... Training model for up to 1119.98s of the 2020.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\t-0.3657\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.51s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r88_BAG_L1 ... Training model for up to 1114.54s of the 2014.63s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.16%)\n",
      "\t-0.3154\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.21s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_r30_BAG_L1 ... Training model for up to 1108.11s of the 2008.20s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.41%)\n",
      "\t-0.313\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.87s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: XGBoost_r49_BAG_L1 ... Training model for up to 1100.61s of the 2000.69s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.38%)\n",
      "\t-0.3194\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.68s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_r5_BAG_L1 ... Training model for up to 1091.91s of the 1992.00s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.11%)\n",
      "\tWarning: Exception caused CatBoost_r5_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=495155, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=495155, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: NeuralNetTorch_r87_BAG_L1 ... Training model for up to 1090.50s of the 1990.59s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "2025-01-18 15:37:25,624\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:37:25,625\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:37:25,627\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:37:25,627\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:37:25,628\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:37:25,628\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:37:25,629\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.3153\t = Validation score   (-root_mean_squared_error)\n",
      "\t13.07s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r71_BAG_L1 ... Training model for up to 1076.56s of the 1976.65s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\t-0.3565\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.75s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_r143_BAG_L1 ... Training model for up to 1070.64s of the 1970.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.45%)\n",
      "\tWarning: Exception caused CatBoost_r143_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=496619, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=496619, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: ExtraTrees_r178_BAG_L1 ... Training model for up to 1068.98s of the 1969.07s of remaining time.\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning:\n",
      "\n",
      "`BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\n",
      "\t-0.3105\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.44s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: RandomForest_r166_BAG_L1 ... Training model for up to 1068.38s of the 1968.47s of remaining time.\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning:\n",
      "\n",
      "`BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\n",
      "\t-0.3225\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.76s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: XGBoost_r31_BAG_L1 ... Training model for up to 1067.40s of the 1967.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.24%)\n",
      "2025-01-18 15:37:46,634\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:37:46,635\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:37:46,636\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:37:46,636\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:37:46,637\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:37:46,638\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:37:46,638\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.3187\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.5s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r185_BAG_L1 ... Training model for up to 1058.83s of the 1958.92s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\t-0.3219\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.52s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r160_BAG_L1 ... Training model for up to 1046.24s of the 1946.33s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
      "\t-0.307\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.12s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: CatBoost_r60_BAG_L1 ... Training model for up to 1038.06s of the 1938.15s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.17%)\n",
      "\tWarning: Exception caused CatBoost_r60_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=498664, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=498664, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: RandomForest_r15_BAG_L1 ... Training model for up to 1036.77s of the 1936.85s of remaining time.\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning:\n",
      "\n",
      "`BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\n",
      "\t-0.3138\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.82s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: LightGBM_r135_BAG_L1 ... Training model for up to 1033.77s of the 1933.85s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.53%)\n",
      "2025-01-18 15:38:18,646\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:38:18,647\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:38:18,647\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:38:18,648\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:38:18,649\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:38:18,650\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:38:18,650\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.3154\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.12s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: XGBoost_r22_BAG_L1 ... Training model for up to 1029.43s of the 1929.52s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.24%)\n",
      "\t-0.3209\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.02s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r69_BAG_L1 ... Training model for up to 1024.33s of the 1924.42s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
      "\t-0.3112\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.35s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost_r6_BAG_L1 ... Training model for up to 1016.97s of the 1917.06s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\tWarning: Exception caused CatBoost_r6_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=500476, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=500476, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: NeuralNetFastAI_r138_BAG_L1 ... Training model for up to 1015.65s of the 1915.73s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "2025-01-18 15:38:40,660\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:38:40,661\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:38:40,663\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:38:40,664\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:38:40,664\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:38:40,665\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:38:40,666\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.3255\t = Validation score   (-root_mean_squared_error)\n",
      "\t18.58s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: LightGBM_r121_BAG_L1 ... Training model for up to 996.12s of the 1896.20s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.66%)\n",
      "\t-0.318\t = Validation score   (-root_mean_squared_error)\n",
      "\t41.9s\t = Training   runtime\n",
      "\t1.25s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r172_BAG_L1 ... Training model for up to 950.73s of the 1850.81s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\t-0.3281\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.15s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_r180_BAG_L1 ... Training model for up to 945.43s of the 1845.52s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.50%)\n",
      "\tWarning: Exception caused CatBoost_r180_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=502763, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=502763, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: NeuralNetTorch_r76_BAG_L1 ... Training model for up to 943.94s of the 1844.03s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "2025-01-18 15:39:51,689\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:39:51,690\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:39:51,691\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:39:51,692\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:39:51,692\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:39:51,692\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:39:51,693\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.3256\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.31s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r197_BAG_L1 ... Training model for up to 936.65s of the 1836.74s of remaining time.\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning:\n",
      "\n",
      "`BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\n",
      "\t-0.3097\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.71s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r121_BAG_L1 ... Training model for up to 935.72s of the 1835.81s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\t-0.3175\t = Validation score   (-root_mean_squared_error)\n",
      "\t16.33s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r127_BAG_L1 ... Training model for up to 918.36s of the 1818.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\t-0.3174\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.5s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForest_r16_BAG_L1 ... Training model for up to 913.84s of the 1813.93s of remaining time.\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning:\n",
      "\n",
      "`BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\n",
      "\t-0.3202\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.71s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r194_BAG_L1 ... Training model for up to 908.90s of the 1808.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\t-0.3086\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.39s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost_r12_BAG_L1 ... Training model for up to 902.52s of the 1802.60s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.49%)\n",
      "\tWarning: Exception caused CatBoost_r12_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=505384, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=505384, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: NeuralNetTorch_r135_BAG_L1 ... Training model for up to 900.85s of the 1800.94s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "2025-01-18 15:40:34,715\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:40:34,716\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:40:34,716\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:40:34,717\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:40:34,718\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:40:34,718\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:40:34,719\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.3179\t = Validation score   (-root_mean_squared_error)\n",
      "\t22.0s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r4_BAG_L1 ... Training model for up to 877.82s of the 1777.91s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\t-0.3121\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.16s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r126_BAG_L1 ... Training model for up to 871.54s of the 1771.63s of remaining time.\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning:\n",
      "\n",
      "`BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\n",
      "\t-0.3293\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.61s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r36_BAG_L1 ... Training model for up to 870.72s of the 1770.80s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\t-0.3158\t = Validation score   (-root_mean_squared_error)\n",
      "\t17.86s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r100_BAG_L1 ... Training model for up to 851.80s of the 1751.88s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\t-0.3707\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.27s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost_r163_BAG_L1 ... Training model for up to 842.52s of the 1742.61s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.20%)\n",
      "\tWarning: Exception caused CatBoost_r163_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=508188, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=508188, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: CatBoost_r198_BAG_L1 ... Training model for up to 840.87s of the 1740.95s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.21%)\n",
      "\tWarning: Exception caused CatBoost_r198_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=508747, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=508747, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "2025-01-18 15:41:30,759\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:41:30,760\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:41:30,761\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:41:30,763\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:41:30,764\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:41:30,764\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:41:30,766\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "Fitting model: NeuralNetFastAI_r187_BAG_L1 ... Training model for up to 839.73s of the 1739.81s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "2025-01-18 15:41:35,737\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:41:35,738\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:41:35,739\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:41:35,740\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:41:35,740\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:41:35,740\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:41:35,741\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.3062\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.51s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r19_BAG_L1 ... Training model for up to 834.13s of the 1734.22s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "\t-0.3264\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.21s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: XGBoost_r95_BAG_L1 ... Training model for up to 826.56s of the 1726.65s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.24%)\n",
      "\t-0.3177\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.13s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost_r34_BAG_L1 ... Training model for up to 822.41s of the 1722.49s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.32%)\n",
      "\t-0.3259\t = Validation score   (-root_mean_squared_error)\n",
      "\t29.12s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: LightGBM_r42_BAG_L1 ... Training model for up to 792.09s of the 1692.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.50%)\n",
      "\t-0.3342\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.67s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r1_BAG_L1 ... Training model for up to 788.28s of the 1688.37s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\t-0.3186\t = Validation score   (-root_mean_squared_error)\n",
      "\t19.24s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r89_BAG_L1 ... Training model for up to 768.01s of the 1668.10s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\t-0.3201\t = Validation score   (-root_mean_squared_error)\n",
      "\t18.36s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 1648.64s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_r30_BAG_L1': 0.227, 'NeuralNetFastAI_r187_BAG_L1': 0.227, 'NeuralNetTorch_r143_BAG_L1': 0.136, 'LightGBM_r135_BAG_L1': 0.136, 'ExtraTreesMSE_BAG_L1': 0.091, 'NeuralNetFastAI_r160_BAG_L1': 0.091, 'KNeighborsDist_BAG_L1': 0.045, 'XGBoost_r95_BAG_L1': 0.045}\n",
      "\t-0.2988\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 1648.61s of the 1648.51s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.38%)\n",
      "\t-0.3052\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.73s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 1645.76s of the 1645.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.41%)\n",
      "\t-0.3112\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.45s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 1642.23s of the 1642.13s of remaining time.\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning:\n",
      "\n",
      "`BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\n",
      "\t-0.306\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.5s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 1636.49s of the 1636.39s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.60%)\n",
      "\tWarning: Exception caused CatBoost_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=513725, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=513725, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 1635.30s of the 1635.21s of remaining time.\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning:\n",
      "\n",
      "`BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\n",
      "\t-0.3038\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.78s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 1634.29s of the 1634.20s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.26%)\n",
      "2025-01-18 15:43:20,803\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:43:20,804\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:43:20,805\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:43:20,805\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:43:20,806\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:43:20,806\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:43:20,807\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.3178\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.06s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 1628.19s of the 1628.10s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.89%)\n",
      "\t-0.3133\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.48s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 1621.31s of the 1621.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
      "\t-0.3208\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.47s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 1611.71s of the 1611.61s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.16%)\n",
      "\t-0.3145\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.73s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 1599.78s of the 1599.68s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.63%)\n",
      "\tWarning: Exception caused CatBoost_r177_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=516148, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=516148, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 1598.39s of the 1598.30s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
      "2025-01-18 15:43:57,818\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:43:57,819\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:43:57,820\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:43:57,820\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:43:57,821\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:43:57,821\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:43:57,822\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.3158\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.59s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 1586.83s of the 1586.74s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.54%)\n",
      "\t-0.3106\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.58s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L2 ... Training model for up to 1581.03s of the 1580.94s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.26%)\n",
      "\t-0.3208\t = Validation score   (-root_mean_squared_error)\n",
      "\t13.22s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L2 ... Training model for up to 1566.80s of the 1566.70s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.03%)\n",
      "\tWarning: Exception caused CatBoost_r9_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=518006, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=518006, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: LightGBM_r96_BAG_L2 ... Training model for up to 1565.52s of the 1565.43s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.27%)\n",
      "\t-0.3044\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.63s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L2 ... Training model for up to 1562.70s of the 1562.61s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
      "2025-01-18 15:44:29,043\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:44:29,044\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:44:29,044\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:44:29,045\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:44:29,045\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:44:29,046\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:44:29,047\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.3181\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.38s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L2 ... Training model for up to 1549.28s of the 1549.19s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=4.02%)\n",
      "\t-0.3133\t = Validation score   (-root_mean_squared_error)\n",
      "\t56.1s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L2 ... Training model for up to 1492.07s of the 1491.98s of remaining time.\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning:\n",
      "\n",
      "`BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\n",
      "\t-0.3037\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.64s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L2 ... Training model for up to 1491.14s of the 1491.05s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.26%)\n",
      "\tWarning: Exception caused CatBoost_r137_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=520037, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=520037, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L2 ... Training model for up to 1489.95s of the 1489.86s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.27%)\n",
      "\t-0.3422\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.3s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L2 ... Training model for up to 1485.59s of the 1485.49s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.85%)\n",
      "2025-01-18 15:45:46,108\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:45:46,109\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:45:46,110\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:45:46,111\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:45:46,112\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:45:46,116\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:45:46,116\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\tWarning: Exception caused CatBoost_r13_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=521242, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=521242, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: RandomForest_r195_BAG_L2 ... Training model for up to 1483.97s of the 1483.88s of remaining time.\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning:\n",
      "\n",
      "`BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\n",
      "\t-0.3065\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.49s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L2 ... Training model for up to 1479.26s of the 1479.17s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.07%)\n",
      "2025-01-18 15:45:52,113\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:45:52,114\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:45:52,115\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:45:52,115\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:45:52,116\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:45:52,116\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:45:52,117\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.3073\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.92s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L2 ... Training model for up to 1473.27s of the 1473.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.27%)\n",
      "\t-0.3141\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.35s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: XGBoost_r89_BAG_L2 ... Training model for up to 1462.81s of the 1462.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.67%)\n",
      "\t-0.3081\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.95s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L2 ... Training model for up to 1458.91s of the 1458.82s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
      "\t-0.314\t = Validation score   (-root_mean_squared_error)\n",
      "\t28.09s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBM_r130_BAG_L2 ... Training model for up to 1429.68s of the 1429.59s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.81%)\n",
      "\t-0.3072\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.36s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r86_BAG_L2 ... Training model for up to 1426.31s of the 1426.22s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.16%)\n",
      "\t-0.3199\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.23s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost_r50_BAG_L2 ... Training model for up to 1416.81s of the 1416.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.30%)\n",
      "\tWarning: Exception caused CatBoost_r50_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=524742, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=524742, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: NeuralNetFastAI_r11_BAG_L2 ... Training model for up to 1415.36s of the 1415.27s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.27%)\n",
      "2025-01-18 15:47:00,142\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:47:00,143\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:47:00,144\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:47:00,145\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:47:00,146\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:47:00,148\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:47:00,150\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.3096\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.79s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: XGBoost_r194_BAG_L2 ... Training model for up to 1399.48s of the 1399.38s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.29%)\n",
      "\t-0.3138\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.51s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r172_BAG_L2 ... Training model for up to 1389.75s of the 1389.66s of remaining time.\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning:\n",
      "\n",
      "`BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\n",
      "\t-0.3022\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.51s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: CatBoost_r69_BAG_L2 ... Training model for up to 1389.06s of the 1388.96s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.37%)\n",
      "\tWarning: Exception caused CatBoost_r69_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=526300, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=526300, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: NeuralNetFastAI_r103_BAG_L2 ... Training model for up to 1387.88s of the 1387.79s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.27%)\n",
      "2025-01-18 15:47:28,158\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:47:28,159\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:47:28,160\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:47:28,160\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:47:28,161\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:47:28,162\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:47:28,163\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.3195\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.92s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r14_BAG_L2 ... Training model for up to 1379.00s of the 1378.90s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
      "\t-0.3218\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.4s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_r161_BAG_L2 ... Training model for up to 1371.63s of the 1371.54s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.05%)\n",
      "\t-0.3089\t = Validation score   (-root_mean_squared_error)\n",
      "\t31.76s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r143_BAG_L2 ... Training model for up to 1337.39s of the 1337.30s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.26%)\n",
      "\t-0.306\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.27s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost_r70_BAG_L2 ... Training model for up to 1331.88s of the 1331.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.86%)\n",
      "\tWarning: Exception caused CatBoost_r70_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=528932, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=528932, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: NeuralNetFastAI_r156_BAG_L2 ... Training model for up to 1330.29s of the 1330.19s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.27%)\n",
      "\t-0.325\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.19s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBM_r196_BAG_L2 ... Training model for up to 1325.04s of the 1324.95s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.61%)\n",
      "2025-01-18 15:48:26,181\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:48:26,187\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:48:26,195\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:48:26,197\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:48:26,200\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:48:26,203\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:48:26,206\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.3073\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.18s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: RandomForest_r39_BAG_L2 ... Training model for up to 1313.57s of the 1313.48s of remaining time.\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning:\n",
      "\n",
      "`BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\n",
      "\t-0.3063\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.77s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: CatBoost_r167_BAG_L2 ... Training model for up to 1309.61s of the 1309.51s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.07%)\n",
      "\tWarning: Exception caused CatBoost_r167_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=530353, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=530353, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: NeuralNetFastAI_r95_BAG_L2 ... Training model for up to 1308.40s of the 1308.31s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.27%)\n",
      "2025-01-18 15:48:47,188\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:48:47,190\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:48:47,191\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:48:47,191\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:48:47,192\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:48:47,193\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:48:47,194\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.3189\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.46s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r41_BAG_L2 ... Training model for up to 1297.85s of the 1297.76s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
      "\t-0.3143\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.24s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: XGBoost_r98_BAG_L2 ... Training model for up to 1286.58s of the 1286.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.11%)\n",
      "\t-0.31\t = Validation score   (-root_mean_squared_error)\n",
      "\t77.71s\t = Training   runtime\n",
      "\t0.4s\t = Validation runtime\n",
      "Fitting model: LightGBM_r15_BAG_L2 ... Training model for up to 1207.66s of the 1207.57s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.31%)\n",
      "\t-0.3071\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.43s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r158_BAG_L2 ... Training model for up to 1204.07s of the 1203.98s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
      "\t-0.3045\t = Validation score   (-root_mean_squared_error)\n",
      "\t28.33s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost_r86_BAG_L2 ... Training model for up to 1174.57s of the 1174.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.04%)\n",
      "\tWarning: Exception caused CatBoost_r86_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=533833, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=533833, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: NeuralNetFastAI_r37_BAG_L2 ... Training model for up to 1173.23s of the 1173.14s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.27%)\n",
      "2025-01-18 15:51:03,278\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:51:03,279\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:51:03,279\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:51:03,280\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:51:03,281\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:51:03,281\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:51:03,282\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.3084\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.52s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r197_BAG_L2 ... Training model for up to 1165.77s of the 1165.68s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.18%)\n",
      "\t-0.3229\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.52s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_r49_BAG_L2 ... Training model for up to 1159.81s of the 1159.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.36%)\n",
      "\tWarning: Exception caused CatBoost_r49_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=535480, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=535480, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: ExtraTrees_r49_BAG_L2 ... Training model for up to 1158.07s of the 1157.97s of remaining time.\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning:\n",
      "\n",
      "`BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\n",
      "\t-0.3036\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: LightGBM_r143_BAG_L2 ... Training model for up to 1157.43s of the 1157.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.44%)\n",
      "2025-01-18 15:51:18,286\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:51:18,287\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:51:18,287\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:51:18,288\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:51:18,289\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:51:18,289\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:51:18,290\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.3137\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.64s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: RandomForest_r127_BAG_L2 ... Training model for up to 1146.44s of the 1146.35s of remaining time.\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning:\n",
      "\n",
      "`BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\n",
      "\t-0.3043\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.33s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r134_BAG_L2 ... Training model for up to 1141.94s of the 1141.84s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.26%)\n",
      "\t-0.3143\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.97s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: RandomForest_r34_BAG_L2 ... Training model for up to 1131.07s of the 1130.98s of remaining time.\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning:\n",
      "\n",
      "`BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\n",
      "\t-0.3017\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.06s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBM_r94_BAG_L2 ... Training model for up to 1128.86s of the 1128.77s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.26%)\n",
      "\t-0.3048\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.06s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r143_BAG_L2 ... Training model for up to 1126.85s of the 1126.75s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.16%)\n",
      "\t-0.3138\t = Validation score   (-root_mean_squared_error)\n",
      "\t17.62s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost_r128_BAG_L2 ... Training model for up to 1107.84s of the 1107.75s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.03%)\n",
      "\tWarning: Exception caused CatBoost_r128_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=537966, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=537966, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: NeuralNetFastAI_r111_BAG_L2 ... Training model for up to 1106.62s of the 1106.52s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.26%)\n",
      "\t-0.3726\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.84s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r31_BAG_L2 ... Training model for up to 1101.69s of the 1101.59s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.19%)\n",
      "2025-01-18 15:52:09,309\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:52:09,316\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:52:09,317\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:52:09,317\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:52:09,318\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:52:09,318\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:52:09,319\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.3175\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.27s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r4_BAG_L2 ... Training model for up to 1092.92s of the 1092.83s of remaining time.\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning:\n",
      "\n",
      "`BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\n",
      "\t-0.3015\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r65_BAG_L2 ... Training model for up to 1092.36s of the 1092.27s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.27%)\n",
      "\t-0.3309\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.48s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r88_BAG_L2 ... Training model for up to 1086.86s of the 1086.77s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.36%)\n",
      "\t-0.3136\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.86s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBM_r30_BAG_L2 ... Training model for up to 1080.47s of the 1080.38s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.36%)\n",
      "\t-0.3063\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.8s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: XGBoost_r49_BAG_L2 ... Training model for up to 1072.77s of the 1072.68s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.15%)\n",
      "\t-0.3127\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.9s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_r5_BAG_L2 ... Training model for up to 1061.82s of the 1061.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.27%)\n",
      "\tWarning: Exception caused CatBoost_r5_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=541639, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=541639, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: NeuralNetTorch_r87_BAG_L2 ... Training model for up to 1060.60s of the 1060.51s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
      "2025-01-18 15:52:55,333\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:52:55,335\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:52:55,335\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:52:55,336\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:52:55,337\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:52:55,337\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:52:55,338\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.3123\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.09s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r71_BAG_L2 ... Training model for up to 1052.52s of the 1052.43s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.17%)\n",
      "\t-0.3277\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.51s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_r143_BAG_L2 ... Training model for up to 1046.76s of the 1046.67s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.34%)\n",
      "\tWarning: Exception caused CatBoost_r143_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=543060, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=543060, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: ExtraTrees_r178_BAG_L2 ... Training model for up to 1045.09s of the 1044.99s of remaining time.\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning:\n",
      "\n",
      "`BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\n",
      "\t-0.3021\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.46s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: RandomForest_r166_BAG_L2 ... Training model for up to 1044.44s of the 1044.35s of remaining time.\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning:\n",
      "\n",
      "`BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\n",
      "\t-0.3039\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.77s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: XGBoost_r31_BAG_L2 ... Training model for up to 1043.45s of the 1043.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.68%)\n",
      "2025-01-18 15:53:11,342\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:53:11,343\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:53:11,343\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:53:11,344\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:53:11,344\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:53:11,344\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:53:11,345\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.3052\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.3s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r185_BAG_L2 ... Training model for up to 1038.18s of the 1038.08s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
      "\t-0.3157\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.76s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r160_BAG_L2 ... Training model for up to 1027.45s of the 1027.36s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.27%)\n",
      "\t-0.3059\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.31s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: CatBoost_r60_BAG_L2 ... Training model for up to 1019.01s of the 1018.92s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.55%)\n",
      "\tWarning: Exception caused CatBoost_r60_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=545067, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=545067, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: RandomForest_r15_BAG_L2 ... Training model for up to 1017.29s of the 1017.20s of remaining time.\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning:\n",
      "\n",
      "`BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\n",
      "\t-0.3051\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.48s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: LightGBM_r135_BAG_L2 ... Training model for up to 1013.63s of the 1013.53s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.69%)\n",
      "2025-01-18 15:53:38,353\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:53:38,355\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:53:38,356\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:53:38,357\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:53:38,358\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:53:38,359\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:53:38,359\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.308\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.43s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: XGBoost_r22_BAG_L2 ... Training model for up to 1009.28s of the 1009.19s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.69%)\n",
      "\t-0.3114\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.12s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r69_BAG_L2 ... Training model for up to 1004.03s of the 1003.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.29%)\n",
      "\t-0.3105\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.14s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: CatBoost_r6_BAG_L2 ... Training model for up to 996.61s of the 996.52s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.36%)\n",
      "\tWarning: Exception caused CatBoost_r6_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=546907, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=546907, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: NeuralNetFastAI_r138_BAG_L2 ... Training model for up to 995.28s of the 995.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.27%)\n",
      "2025-01-18 15:54:00,362\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:54:00,363\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:54:00,364\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:54:00,364\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:54:00,365\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:54:00,366\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:54:00,366\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.317\t = Validation score   (-root_mean_squared_error)\n",
      "\t17.17s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: LightGBM_r121_BAG_L2 ... Training model for up to 977.11s of the 977.02s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.74%)\n",
      "\t-0.3087\t = Validation score   (-root_mean_squared_error)\n",
      "\t22.12s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r172_BAG_L2 ... Training model for up to 953.12s of the 953.03s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.26%)\n",
      "\t-0.3252\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.24s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost_r180_BAG_L2 ... Training model for up to 947.84s of the 947.75s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.53%)\n",
      "\tWarning: Exception caused CatBoost_r180_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=549031, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=549031, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: NeuralNetTorch_r76_BAG_L2 ... Training model for up to 946.20s of the 946.10s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
      "2025-01-18 15:54:49,387\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:54:49,388\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:54:49,388\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:54:49,390\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:54:49,391\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:54:49,393\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:54:49,394\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.3209\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.89s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r197_BAG_L2 ... Training model for up to 939.30s of the 939.21s of remaining time.\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning:\n",
      "\n",
      "`BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\n",
      "\t-0.3038\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.01s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r121_BAG_L2 ... Training model for up to 938.06s of the 937.97s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.14%)\n",
      "\t-0.3179\t = Validation score   (-root_mean_squared_error)\n",
      "\t21.26s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r127_BAG_L2 ... Training model for up to 915.85s of the 915.76s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.26%)\n",
      "\t-0.3135\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.69s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForest_r16_BAG_L2 ... Training model for up to 911.06s of the 910.97s of remaining time.\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning:\n",
      "\n",
      "`BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\n",
      "\t-0.306\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.04s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r194_BAG_L2 ... Training model for up to 904.75s of the 904.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.26%)\n",
      "\t-0.3102\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.52s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost_r12_BAG_L2 ... Training model for up to 898.03s of the 897.94s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.33%)\n",
      "\tWarning: Exception caused CatBoost_r12_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=551755, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=551755, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: NeuralNetTorch_r135_BAG_L2 ... Training model for up to 896.51s of the 896.41s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
      "2025-01-18 15:55:39,408\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:55:39,409\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:55:39,410\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:55:39,410\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:55:39,411\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:55:39,412\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:55:39,413\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.316\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.72s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r4_BAG_L2 ... Training model for up to 882.69s of the 882.60s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.27%)\n",
      "\t-0.3052\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.26s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r126_BAG_L2 ... Training model for up to 876.43s of the 876.34s of remaining time.\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning:\n",
      "\n",
      "`BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\n",
      "\t-0.3026\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r36_BAG_L2 ... Training model for up to 875.56s of the 875.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.16%)\n",
      "\t-0.3143\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.69s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r100_BAG_L2 ... Training model for up to 862.89s of the 862.80s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.26%)\n",
      "\t-0.33\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.19s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost_r163_BAG_L2 ... Training model for up to 853.66s of the 853.56s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.55%)\n",
      "\tWarning: Exception caused CatBoost_r163_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=554442, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=554442, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: CatBoost_r198_BAG_L2 ... Training model for up to 852.13s of the 852.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.63%)\n",
      "\tWarning: Exception caused CatBoost_r198_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=554984, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/__init__.py\", line 1, in <module>\n",
      "    from .core import (\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/core.py\", line 45, in <module>\n",
      "    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/catboost/plot_helpers.py\", line 5, in <module>\n",
      "    from . import _catboost\n",
      "  File \"_catboost.pyx\", line 1, in init _catboost\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=554984, ip=192.168.1.19)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 106, in _fit\n",
      "    try_import_catboost()\n",
      "  File \"/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 84, in try_import_catboost\n",
      "    raise ImportError(\n",
      "ImportError: Import catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "2025-01-18 15:56:19,694\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:56:19,695\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:56:19,696\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:56:19,697\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:56:19,697\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:56:19,700\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:56:19,700\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "Fitting model: NeuralNetFastAI_r187_BAG_L2 ... Training model for up to 850.97s of the 850.88s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.27%)\n",
      "\t-0.3082\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.71s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r19_BAG_L2 ... Training model for up to 845.27s of the 845.17s of remaining time.\n",
      "2025-01-18 15:56:25,426\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:56:25,430\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:56:25,431\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:56:25,434\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:56:25,435\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:56:25,436\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-01-18 15:56:25,443\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.19%)\n",
      "\t-0.3239\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.54s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: XGBoost_r95_BAG_L2 ... Training model for up to 839.11s of the 839.01s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.96%)\n",
      "\t-0.309\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.51s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost_r34_BAG_L2 ... Training model for up to 834.08s of the 833.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=4.06%)\n",
      "\t-0.3121\t = Validation score   (-root_mean_squared_error)\n",
      "\t33.52s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: LightGBM_r42_BAG_L2 ... Training model for up to 799.55s of the 799.46s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.60%)\n",
      "\t-0.31\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.07s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r1_BAG_L2 ... Training model for up to 796.38s of the 796.29s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.16%)\n",
      "\t-0.3133\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.67s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r89_BAG_L2 ... Training model for up to 783.49s of the 783.40s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
      "\t-0.3159\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.3s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 770.98s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_r158_BAG_L2': 0.28, 'RandomForest_r34_BAG_L2': 0.28, 'ExtraTrees_r178_BAG_L2': 0.12, 'NeuralNetTorch_r87_BAG_L2': 0.08, 'RandomForest_r166_BAG_L2': 0.08, 'NeuralNetFastAI_r160_BAG_L2': 0.08, 'ExtraTrees_r4_BAG_L2': 0.04, 'NeuralNetFastAI_r4_BAG_L2': 0.04}\n",
      "\t-0.2998\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1928.04s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1134.2 rows/s (475 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/pawel/repos/university/sml/hw2/AutogluonModels/ag-20250118_141030\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-0.298785</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.564973</td>\n",
       "      <td>91.362215</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.014076</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>-0.299827</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>2.245214</td>\n",
       "      <td>162.989067</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.014762</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTrees_r4_BAG_L2</td>\n",
       "      <td>-0.301492</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.583227</td>\n",
       "      <td>111.699247</td>\n",
       "      <td>0.123801</td>\n",
       "      <td>0.396816</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest_r34_BAG_L2</td>\n",
       "      <td>-0.301662</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.572302</td>\n",
       "      <td>113.363566</td>\n",
       "      <td>0.112876</td>\n",
       "      <td>2.061135</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTrees_r178_BAG_L2</td>\n",
       "      <td>-0.302116</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.588558</td>\n",
       "      <td>111.766038</td>\n",
       "      <td>0.129132</td>\n",
       "      <td>0.463607</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>NeuralNetTorch_r71_BAG_L1</td>\n",
       "      <td>-0.356503</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.045153</td>\n",
       "      <td>4.750429</td>\n",
       "      <td>0.045153</td>\n",
       "      <td>4.750429</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>NeuralNetFastAI_r65_BAG_L1</td>\n",
       "      <td>-0.365655</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.045725</td>\n",
       "      <td>4.505763</td>\n",
       "      <td>0.045725</td>\n",
       "      <td>4.505763</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>NeuralNetFastAI_r100_BAG_L1</td>\n",
       "      <td>-0.370739</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.097837</td>\n",
       "      <td>8.271466</td>\n",
       "      <td>0.097837</td>\n",
       "      <td>8.271466</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>NeuralNetFastAI_r111_BAG_L2</td>\n",
       "      <td>-0.372595</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.530956</td>\n",
       "      <td>115.139796</td>\n",
       "      <td>0.071530</td>\n",
       "      <td>3.837365</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>NeuralNetFastAI_r111_BAG_L1</td>\n",
       "      <td>-0.399335</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.063022</td>\n",
       "      <td>3.748435</td>\n",
       "      <td>0.063022</td>\n",
       "      <td>3.748435</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           model  score_val              eval_metric  \\\n",
       "0            WeightedEnsemble_L2  -0.298785  root_mean_squared_error   \n",
       "1            WeightedEnsemble_L3  -0.299827  root_mean_squared_error   \n",
       "2           ExtraTrees_r4_BAG_L2  -0.301492  root_mean_squared_error   \n",
       "3        RandomForest_r34_BAG_L2  -0.301662  root_mean_squared_error   \n",
       "4         ExtraTrees_r178_BAG_L2  -0.302116  root_mean_squared_error   \n",
       "..                           ...        ...                      ...   \n",
       "171    NeuralNetTorch_r71_BAG_L1  -0.356503  root_mean_squared_error   \n",
       "172   NeuralNetFastAI_r65_BAG_L1  -0.365655  root_mean_squared_error   \n",
       "173  NeuralNetFastAI_r100_BAG_L1  -0.370739  root_mean_squared_error   \n",
       "174  NeuralNetFastAI_r111_BAG_L2  -0.372595  root_mean_squared_error   \n",
       "175  NeuralNetFastAI_r111_BAG_L1  -0.399335  root_mean_squared_error   \n",
       "\n",
       "     pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  \\\n",
       "0         0.564973   91.362215                0.000226           0.014076   \n",
       "1         2.245214  162.989067                0.000242           0.014762   \n",
       "2         1.583227  111.699247                0.123801           0.396816   \n",
       "3         1.572302  113.363566                0.112876           2.061135   \n",
       "4         1.588558  111.766038                0.129132           0.463607   \n",
       "..             ...         ...                     ...                ...   \n",
       "171       0.045153    4.750429                0.045153           4.750429   \n",
       "172       0.045725    4.505763                0.045725           4.505763   \n",
       "173       0.097837    8.271466                0.097837           8.271466   \n",
       "174       1.530956  115.139796                0.071530           3.837365   \n",
       "175       0.063022    3.748435                0.063022           3.748435   \n",
       "\n",
       "     stack_level  can_infer  fit_order  \n",
       "0              2       True         89  \n",
       "1              3       True        176  \n",
       "2              2       True        139  \n",
       "3              2       True        134  \n",
       "4              2       True        146  \n",
       "..           ...        ...        ...  \n",
       "171            1       True         58  \n",
       "172            1       True         53  \n",
       "173            1       True         81  \n",
       "174            2       True        137  \n",
       "175            1       True         50  \n",
       "\n",
       "[176 rows x 10 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "X_final_ag = TabularDataset(X_final)\n",
    "X_final_ag.columns = X_final_ag.columns.astype(str)\n",
    "X_final_ag[\"target\"] = y\n",
    "\n",
    "model = TabularPredictor(\n",
    "    label=\"target\", eval_metric=\"root_mean_squared_error\", problem_type=\"regression\"\n",
    ")\n",
    "\n",
    "model.fit(X_final_ag, presets=\"best_quality\", time_limit=3600)\n",
    "\n",
    "model.leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are significantly better than any of the previously obtained. Even though I'm a little afraid that the AutoGluon model may have been overfitted to the training data I decide to stick with it to get the final predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator ExtraTreeRegressor from version 1.6.1 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator ExtraTreesRegressor from version 1.6.1 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/sml_hw2/lib/python3.11/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator KNeighborsRegressor from version 1.6.1 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_test = pd.read_csv(\"X_test.csv\")\n",
    "\n",
    "X_test_sel = boruta.transform(X_test.values)\n",
    "X_test_final = pca.transform(scaler.transform(X_test_sel))\n",
    "\n",
    "X_test_final_ag = TabularDataset(X_test_final)\n",
    "X_test_final_ag.columns = X_test_final_ag.columns.astype(str)\n",
    "\n",
    "y_test = model.predict(X_test_final_ag)\n",
    "\n",
    "output_df = pd.DataFrame({\"Id\": y_test.index, \"Expected\": y_test})\n",
    "\n",
    "output_df.to_csv(\"469506_prediction.csv\", sep=\";\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sml_hw2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
